---
title: "Computer Visions"
permalink: /vision/
toc_sticky: true
toc_ads : true
layout: single
---
  

---

#### π“’ CS231n κ°•μ λ…ΈνΈ

μ¤νƒ ν¬λ“ λ€ν•™κµμ λ”¥λ¬λ‹ κ°•μμΈ cs231nμ„ μ”μ•½ν• λ‚΄μ©μ…λ‹λ‹¤.

1 - [Introduction to Convolutional Neural Networks for Visual Recognition](https://happy-jihye.github.io/cs231n/cs231n-1/)

2 - [Image Classfication pipeline](https://happy-jihye.github.io/cs231n/cs231n-2/)

3 - [Loss Functions and Optimization](https://happy-jihye.github.io/cs231n/cs231n-3/)

4 - [Backpropagation and Neural Networks](https://happy-jihye.github.io/cs231n/cs231n-4/)
  
5 - [Convolutional Neural Networks](https://happy-jihye.github.io/cs231n/cs231n-5/)

6 - [Training Neural Networks (1)](https://happy-jihye.github.io/cs231n/cs231n-6/)

---

#### π–Ό **Generative Adversarial Networks : Paper Review** ([Github](https://github.com/happy-jihye/GAN-Papers))
   

<span style='background-color: #E5EBF7;'> **GAN Basics** </span>

- [GAN: Generative Adversarial Networks](https://happy-jihye.github.io/gan/gan-1/) (2014) : [Paper](https://arxiv.org/abs/1406.2661)

- [DCGAN: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://happy-jihye.github.io/gan/gan-2/) (2015) : [Paper](https://arxiv.org/abs/1511.06434)

<span style='background-color: #E5EBF7;'> **Conditional GAN** </span>

- [CGAN: Conditional Generative Adversarial Nets](https://happy-jihye.github.io/gan/gan-3/) (2014) : [Paper](https://arxiv.org/abs/1411.1784)

- [ACGAN: Conditional Image Synthesis With Auxiliary Classifier GANs](https://happy-jihye.github.io/gan/gan-13/) (ICML 2017) : [Paper](https://arxiv.org/abs/1610.09585)

- **Pair Dataset** 

  - [Pix2Pix: Image-to-Image Translation with Conditional Adversarial Networks](https://happy-jihye.github.io/gan/gan-8/) (CVPR 2017) : [Paper](https://arxiv.org/abs/1611.07004)

  - [SPADE: Semantic Image Synthesis with Spatially Adaptive Normalization](https://happy-jihye.github.io/gan/gan-9/) (CVPR 2019) : [Paper](https://arxiv.org/abs/1903.07291)

- **Unpair Dataset** 

  - [CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://happy-jihye.github.io/gan/gan-10/) (ICCV 2017) : [Paper](https://arxiv.org/abs/1703.10593)

- **Multi Domain**
  - [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://happy-jihye.github.io/gan/gan-12/) (CVPR 2018) : [Paper](https://arxiv.org/abs/1711.09020)

  - [MUNIT : Multi-Modal Unsupervised Image-to-Image Translation](https://happy-jihye.github.io/gan/gan-14/) (ECCV 2018) : [Paper](https://arxiv.org/abs/1804.04732)


<span style='background-color: #E5EBF7;'> **GAN Architecture** </span>

- [Progressive GAN: Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://happy-jihye.github.io/gan/gan-5/) (2018) : [Paper](https://arxiv.org/abs/1710.10196)

- [StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks](https://happy-jihye.github.io/gan/gan-6/) (2019) : [Paper](https://arxiv.org/abs/1812.04948)

  - [StyleGAN2: Analyzing and Improving the Image Quality of StyleGAN](https://happy-jihye.github.io/gan/gan-7/) (2020) : [Paper](https://arxiv.org/abs/1912.04958)
  
  - Training Generative Adversarial Networks with Limited Data [#01](https://happy-jihye.github.io/gan/gan-19/), [#02](https://happy-jihye.github.io/gan/gan-20/) (NeurlPS 2020) : [Paper](https://arxiv.org/abs/2006.06676)

<span style='background-color: #E5EBF7;'> **Text-to-Image** </span>

- [Generative Adversarial Text to Image Synthesis](https://happy-jihye.github.io/gan/gan-4/) (2016) : [Paper](https://arxiv.org/abs/1605.05396)

- [StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery](https://happy-jihye.github.io/gan/gan-15/) (arXiv 2021) : [Paper](https://arxiv.org/abs/2103.17249)

<span style='background-color: #E5EBF7;'> **Improved Training Techniques** </span>

- [SS-GAN: Self-Supervised GANs via Auxiliary Rotation Loss](https://happy-jihye.github.io/gan/gan-16/) (CVPR 2019) : [Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Self-Supervised_GANs_via_Auxiliary_Rotation_Loss_CVPR_2019_paper.pdf)

- [CR-GAN: Consistency Regularization for Generative Adversarial Networks](https://happy-jihye.github.io/gan/gan-17/) (ICLR 2020) : [Paper](https://arxiv.org/abs/1910.12027)

- [ICR-GAN: Improved Consistency Regularization for GANs](https://happy-jihye.github.io/gan/gan-18/) (AAAI 2021) : [Paper](https://arxiv.org/abs/2002.04724)

<span style='background-color: #E5EBF7;'> **Talking Head** </span>

- [Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](https://happy-jihye.github.io/gan/gan-22/) (arxiv 2019) : [Paper](https://arxiv.org/abs/1905.08233)