---
date: 2021-03-06
title: "[CS231n] 02. Image Classfication pipeline"

excerpt: "(1) Image classfication(nn/k-nn) (2) Linear Classification"

categories: 
  - cs231n
tags: 
  - cs231n
  - vision
# 목차
toc: true  
toc_sticky: true 
---

---

**Reference**

- [CS231n 강의노트 Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)

- Lecture 02 - [( Slide Link,](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf) [,Youtube Link )](https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=2)

- [🌺 Happy-Jihye / CS 231n 강의 노트](https://happy-jihye.github.io/cs231n/cs231n-0/)

---



## Image Classification

> ### Difficults
>
> (1)  Semantic Gap (컴퓨터는 이미지를 픽셀들로 인식하기 때문에 사물인식이 어려움)
>
> (2) Viewpoint variation (카메라가 움직일때마다 픽셀값이 변화)
>
> (3) Illumination (조명)
>
> (4) Deformation (다양한 자세나 형태에 따라 이미지 분류가 어려울 수도 있음)
>
> (5) Occlusion (가려짐)
>
> (6) Background Clutter (배경이랑 사물이 비슷할 경우)
>
> (7) Intraclass variation (다양성 ex. 다양한 종의 고양이들)



- image classifier

```python
def classify_image(images):
    # ...
    return class_label
```

- Data-Driven Approach

  수많은 image와 labels들을 모은 후, training을 하고, 이 모델을 평가하기 

```python
def train(images, labels):
    # machine learning !!
    return model

def predict(model, test_images):
    # ...
    return test_labels
```

  
  
---

## 1. Nearest Neighbor

- training : data와 label들을 기억하기만! (별다른 일을 하지는 X)
- Predicting : 새로운 image 중 기존의 image와 비슷한게 있는지를 찾은 후 labeling

- Example Dataset : *CIFAR10* 

  - 10 classes/ 50,000 training images/ 10,000 testing images
    <p align="center"><img title = "image" src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210303173804674.png?raw=1" width = "500" ></p>
- 정확하지 않게 분류되는 것도 많음



### L1 Distance

- 이미지를 Pixel-wise 로 비교
  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210303175236169.png?raw=1" width = "500" ></p>


**Code**

```python
import numpy as np

class NearestNeighbor:
    def __init__(self):
        pass
    
    # Memorize training data (just remembers all the training data)
    def training(self, X, y):
        self.xtr = X 	# X : matrix (N x D)
        self.ytr = y	# y : matrix (1 x N)
	
    def predict(self, X):
        num_test = X.shape[0]
        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
        
        for i in xrange(num_test):
            # using the L1 distance
            # -> for each test image, find closet train image
            distances = np.sum(np.abs(self.xtr - X[i,:]), axis = 1)
            min_index = np.argmin(distances)
            Ypred[i] = self.ytr[min_index]
        
        return Ypred 
    
```

- N examples -> Train O(1), Predict O(n)

- 보통 Training이 오래걸리는 건 괜찮지만, test는 빠르게 해야함. but NearestNeighbor 는 반대임.

  (CNN은 Training이 오래 Test는 빨리)

    
  
> #### *NN알고리즘을 실제로 적용하면?* 
>
> <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305172021148.png?raw=1" width = "300" ></p>
>
> - 점은 학습 데이터, 점의 색깔을 class label
> - 각 좌표가 어떤 학습 데이터와 가장 가까운지를 계산한 후에 그 학습데이터의 label을 반환
> - NN분류기는 space에 따라 데이터를 분류
> - *문제점*
>   - ex) 위의 예제의 초록색 label 사이에 노란색 label(noise)
>   - 유사한 애들끼리 묶으려고 하다보니 위와 같은 noise들이 생김..


---

## 2. K-Nearest Neighbors

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305190849027.png?raw=1" width = "450" ></p>

- Distance metric을 이용하여 가까운 이웃을 K개 만큼 찾고 투표
- 고립된 점이 없어지고, 경계들은 부드러워짐
- 흰색 영역 : k-nn이 결정할 수 없는 영역(어떤식으로도 추론을 하거나 임의로 정할 수 있음)

* *K-nn 은 그닥 성능이 좋지는 않음*
  

### Distance Metric

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305191436399.png?raw=1" width = "500" ></p>

- L1은 어떤 좌표계를 사용하냐에 따라 값이 바뀌지만,
- L2는 원점을 기준으로 모든 거리가 같기 때문에 좌표계에 따라 값이 바뀌지 않음.

- 만약 input feature가 개별적인 의미를 가지고 있다면(ex, 키 / 몸무게) L1이 좋지만
-  input feature가 일반적인 벡터이고 실질적인 의미를 가지고 있지 않다면 L2가 좋을 것

### K-nn : Distance Metric

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305191932390.png?raw=1" width = "500" ></p>

- L1은 좌표축의 영향을 받기 때문에 boundary가 부자연스러움
- L2은 좌표축과 무관하기 때문에 경계가 조금더 부드러움
- [이 링크](http://vision.stanford.edu/teaching/cs231n-demos/knn/) 를 통해 실험 가능


---
  
## 3. Hyperparameters

- Train time에 학습시키지 않는 파라미터
- 학습 전에 반드시 선택을 해야함 !!
- ex) What is the best value of k to use? What is the best distance to use?

- 직접 실험을 하면서 가장 좋은 파라미터를 찾는 수밖에 없음. (내 실험에 맞는 파라미터)
    
  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305194252917.png?raw=1" width = "550" ></p> 
  
- 다양한 파라미터로 training을 한 후 validation set에서 가장 좋았던 classifier를 선택 -> 이를 가지고 test를 하기 !!

- 논문을 쓸 때 test set은 마지막에 한번만 사용하기 !(그래야 공정한 평가가 가능)

- **idea 4 : Cross-Validation**
    
    <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305194555149.png?raw=1" width = "500" ></p>
  -  training data를 여러 partition으로 나눈 후 validation set을 계속 바꿔가면서 최적의 하이퍼파라미터 찾는 방법
  - dataset이 작다면 쓰지만, 딥러닝은 데이터양 자체가 방대하기 때문에 위의 방법을 사용하지 않음



> #### image에서는 k-NN을 사용하지 않음 
>
> - k-nn이 너무 느림,,
> - L1/L2가 이미지간 거리를 측정하기에 적절하지 않음
> - **Curse of dimensionality**
>   - k-nn은 training data를 이용해서 공간을 분할했었음. 즉, k-nn이 잘 동작하려면 전체 공간을 조밀하게 커버할만큼의 데이터가 필요함..
>   - 즉, 충분한 양의 학습데이터가 필요한데 이 학습데이터는 차원이 증가함에따라 기하급수적으로 증가함.
>     <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305200123067.png?raw=1" width = "500" ></p>
>   - 위의 그림들에서 점 하나하나가 training sample.
>   - 1차원에서는 4개의 데이터만 있으면 되지만, 3차원에서는 많은 데이터가 필요하게 됨.



## ⭐ Summary 

- In Image classification we start with a training set of images and labels, and must predict labels on the test set 
- The K-Nearest Neighbors classifier predicts labels based on nearest training examples 
- Distance metric and K are hyperparameters
- Choose hyperparameters using the validation set; only run on the test set once at the very end!



---



## Linear Classfication

- NN은 레고블럭과 같고, Linear Classification은 기본 블럭과 같음
- CNN을 통해 이미지를 처리한 후에, RNN을 통해 이미지에 대한 설명을 뽑아냄

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305201007375.png?raw=1" width = "500" ></p>



## Parametric Appoach

#### CIFAR 10 

- k-nn은 파라미터가 없었음. 모든 트레이닝셋을 test time에 사용했었음(-> test time이 오래 걸림)
- parametric approach에서는 training data의 정보를 요약한 후 이를 파라미터 가중치에 저장 -> test time이 적게 걸림
- 딥러닝은 test를 빠르게 해야하기 때문에 이 함수를 잘 설계해야함 !!





<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305201202039.png?raw=1" width = "500" ></p>

- 데이터셋이 불균형한 경우(ex, 개보다 고양이 데이터가 많을 때) 고양이 클래스에 해당하는 바이어스가 커지게 됨.
  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210305201807926.png?raw=1" width = "500" ></p>
- score : 이미지의 픽셀값과 가중치 행렬을 내적한 값에 bias term을 더한 것
  - 내적 : 클래스간 템플릿의 유사도를 측정하는 것과 유사
  - bias : 데이터 독립적으로 각 클래스에 scailing offset을 더함
- linear classification = 템플릿 매칭과 비슷

- 가중치 벡터를 시각화한것

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210306095327199.png?raw=1" width = "500" ></p>

- Linear classifier : 고차원 공간에 선형적인 경계를 그어 이미지를 분류하는 것

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210306095626711.png?raw=1" width = "500" ></p>




> 다음과 같은 경우에는 linear classification으로 문제를 해결하기가 어려움
>
> - Parity problem
> - Multimodal problem(맨 오른쪽)
>   - multimodal data라면 하나의 클래스가 여러 공간에 분포할 수 있음
>
> <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images/lec2/image-20210306095757349.png?raw=1" width = "500" ></p>

