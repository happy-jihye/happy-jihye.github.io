---
date: 2021-03-29
title: "[CS231n] 4. Backpropagation and Neural Networks"

excerpt: "ì´ í¬ìŠ¤íŒ…ì€ CS231nì˜ 4ê°•ì„ ìš”ì•½í•œ ê¸€ì…ë‹ˆë‹¤ ğŸ˜Š"

categories: 
  - cs231n
tags: 
  - cs231n
  - vision
# ëª©ì°¨
toc: true  
toc_sticky: true 
---


**Reference**

- [CS231n ê°•ì˜ë…¸íŠ¸ Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)

- Lecture 04 - [( Slide Link,](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf) [,Youtube Link )](https://www.youtube.com/watch?v=h7iBpEHGVNc&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=5)

- [ğŸŒº Happy-Jihye / CS 231n ê°•ì˜ ë…¸íŠ¸](https://happy-jihye.github.io/cs231n/cs231n-0/)

---



ì´ í¬ìŠ¤íŒ…ì€ CS231nì˜ 4ê°•ì„ ìš”ì•½í•œ ê¸€ì…ë‹ˆë‹¤ ğŸ˜Š

   

![image-20210326141409066](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210326141409066.png?raw=1)
  

[ì§€ë‚œ 3ê°•](https://happy-jihye.github.io/cs231n/cs231n-3/) ì—ì„œëŠ” Loss functionê³¼ Optimizationì— ëŒ€í•´ ë°°ì› ìŠµë‹ˆë‹¤. 

ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•˜ìë©´, <u><b>Loss function</b>ì€  <b>data loss</b>ê°’ê³¼ <b>regularization</b>ì˜ í•©ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë©° ì •ê·œí™”í•­ì€ ìš°ë¦¬ì˜ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì •ê·œí™”ëœ ëª¨ë¸ì¸ì§€ë¥¼ í‘œí˜„í•´ì¤ë‹ˆë‹¤.</u> **SVM(Support Vector Machine)** functionì€ ìœ„ ìŠ¬ë¼ì´ë“œì˜ 2ë²ˆì§¸ ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë©°  ìì„¸í•œ ì„¤ëª…ì€ [3ê°•](https://happy-jihye.github.io/cs231n/cs231n-3/)ì„ ì°¸ê³ í•´ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ :)

ìš°ë¦¬ëŠ” **ìµœì ì˜ Lossë¥¼ ê°€ì§€ëŠ” íŒŒë¼ë¯¸í„° weight**ë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë©° ê·¸ëŸ¬ê¸° ìœ„í•´ì„œëŠ” **loss functionì˜ weightì— ê´€í•œ gradient**ë¥¼ êµ¬í•´ì•¼í•©ë‹ˆë‹¤.
  

  
![image-20210326142246732](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210326142246732.png?raw=1)
  
  
optimizationì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ gradientë¥¼ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œëŠ” **GD(Gradient Discent)**ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì¦‰ ê²½ì‚¬ê°€ í•˜ê°•í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°˜ë³µí•´ì„œ gradientë¥¼ êµ¬í•˜ë‹¤ë³´ë©´ ìµœì ì˜ ê¸°ìš¸ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ìˆê²Œë  ê²ƒì…ë‹ˆë‹¤.
  

![image-20210326142443271](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210326142443271.png?raw=1)
  

ìœ„ì™€ ê°™ì€ **Numerical Gradient**ì„ ì´ìš©í•˜ì—¬ gradientë¥¼ êµ¬í•  ìˆ˜ë„ ìˆì§€ë§Œ  ê³„ì‚°í•˜ê¸°ì— ì˜¤ëœ ì‹œê°„ì´  ê±¸ë¦½ë‹ˆë‹¤.
  



## 1. Back-propagation



> **Analytic Gradient**
>
> - ìˆ˜ì¹˜ì ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ êµ¬í•˜ì§€ ì•Šê³ , í•´ì„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì—¬ gradientë¥¼ êµ¬í•˜ëŠ” ë°©ì‹



### Computational Graphs

![image-20210326142805879](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210326142805879.png?raw=1)
  
  
- Computational graphë¥¼ ì‚¬ìš©í•´ì„œ í•¨ìˆ˜ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆê²Œ ë˜ì **backpropagation**ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤.
- **Back-propagation**ì€ gradientë¥¼ ì–»ê¸° ìœ„í•´ computational graph ë‚´ë¶€ì˜ ëª¨ë“  ë³€ìˆ˜ì— ëŒ€í•´ **Chain rule**ì„ ì ìš©í•©ë‹ˆë‹¤.
  


![image-20210328173324255](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328173324255.png?raw=1)

![image-20210328173339688](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328173339688.png?raw=1)
  

ë‹¤ìŒê³¼ ê°™ì€ ë³µì¡í•œ layerë“¤ì„ ê°€ì§„ networkì—ì„œë„ computational graphë¥¼ ì‚¬ìš©í•˜ë©´ backpropagationì„ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.
  

![image-20210328173626818](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328173626818.png?raw=1)

![image-20210328173648982](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328173648982.png?raw=1)

![image-20210328173655858](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328173655858.png?raw=1)

![image-20210328173546172](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328173546172.png?raw=1)



- ìœ„ì˜ ìŠ¬ë¼ì´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê²ƒì²˜ëŸ¼ **Back-propagation**ì€ **chain-rule**ì˜ ì¬ê·€ì ì¸ ì‘ìš©ì…ë‹ˆë‹¤.

- Chain ruleì— ì˜í•´ ìš°ë¦¬ëŠ” ë’¤ì—ì„œë¶€í„° ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤.
  

![image-20210328174142451](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328174142451.png?raw=1)
  

- chain ruleì„ ì‚¬ìš©í•˜ë©´ local gradient ê°’ë“¤ì„ ì‚¬ìš©í•´ì„œ gradientë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- chain ruleì—ì„œëŠ” í•­ìƒ ë’¤ìª½ìœ¼ë¡œ gradientê°€ ì „íŒŒë©ë‹ˆë‹¤.
  
  
  
  
### Chain Rule Example

![image-20210328175132413](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175132413.png?raw=1)
  

f(w,x)ë¼ê³  ì í˜€ìˆëŠ” ë³µì¡í•œ exponential ì‹ì„ ë¨¼ì € computational graphë¡œ ë‚˜íƒ€ë‚´ë©´, ìœ„ì˜ ê·¸ë˜í”„ì™€ ê°™ì€ nodeë“¤ì´ ê·¸ë ¤ì§‘ë‹ˆë‹¤.
  
  
  

![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328174928503.png?raw=1)

![image-20210328175432332](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175432332.png?raw=1)

![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175532728.png?raw=1)

![image-20210328175621120](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175621120.png?raw=1)

![image-20210328175747097](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175747097.png?raw=1)

![image-20210328175826507](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175826507.png?raw=1)
  

**Chain Rule** : local gradientì™€ upstream gradientë¥¼ í†µí•´ ìµœì¢… gradientë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  
  
  
  
![image-20210328175917157](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328175917157.png?raw=1)
  

`sigmoid function`ê³¼ ê°™ì€ ë³µì¡í•œ í•¨ìˆ˜ë„ computational graphì™€ ì—­ì „íŒŒë¥¼ í†µí•´ gradientë¥¼ ê³„ì‚°í•˜ë©´ ì‰½ê²Œ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
  

> **Trade-off**
>
> ê° nodeë“¤ì˜ ì‹ì„ ì¡°ê¸ˆ ë” ë³µì¡í•˜ê²Œ ë§Œë“¤ë©´ nodeì˜ ê°œìˆ˜ë¥¼ ê°„ì†Œí™”í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ê·¸ë ‡ê²Œ ë˜ë©´ nodeë‹¹ ë” ë§ì€ ê³„ì‚°ì´ í•„ìš”í•´ì ¸ì„œ ì—°ì‚°ì— ì¢‹ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  
  
---

![image-20210328223023566](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328223023566.png?raw=1)



**Patterns in backward flow**

1. `add gate` : gradient distributor
2. `max gate` : gradient router
   - í•˜ë‚˜ì—ëŠ” ì „ì²´ ê°’, ë‚˜ë¨¸ì§€ í•˜ë‚˜ì—ëŠ” 0ì´ ë“¤ì–´ê°
3. `mul gate` : gradient switcher
   - upstream gradientë¥¼ ë°›ì•„ ë‹¤ë¥¸ branchì˜ ê°’ìœ¼ë¡œ scalingí•¨
  


![image-20210328223515435](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328223515435.png?raw=1)
  

ì—¬ëŸ¬ ê°œì˜ ë…¸ë“œì™€ ì—°ê²°ë˜ì–´ìˆëŠ” í•˜ë‚˜ì˜ ë…¸ë“œê°€ ìˆì„ ë•Œ back-propagationì—ì„œëŠ” upstream gradientë¥¼ í•©ì³ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš°ì—ëŠ” forward-propagationê³¼ back-propagationì´ ì„œë¡œ ì˜í–¥ì„ ì¤ë‹ˆë‹¤.
  
  
  

### Gradients for vectorized code
  
![image-20210328231202843](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328231202843.png?raw=1)
  
---

ê·¸ë™ì•ˆì€ scalarê°’ì— ëŒ€í•œ  gradientì— ëŒ€í•´ ì‚´í´ë´¤ë‹¤ë©´, ì´ì œë¶€í„°ëŠ” vectorì— ëŒ€í•œ gradientë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

ëª¨ë“  ê²ƒì€ ë™ì¼í•˜ì§€ë§Œ, ì´ì œëŠ” <u>gradientê°€ <b>Jacobian</b> í–‰ë ¬ì´ ë©ë‹ˆë‹¤.</u>
  
  
![image-20210328231458350](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328231458350.png?raw=1)



- ì…ë ¥ê³¼ ì¶œë ¥ ëª¨ë‘ 4096ì°¨ì›ì¸ ë‹¤ìŒì˜ ì˜ˆì œì—ì„œ Jacobian matrixì˜ í¬ê¸°ëŠ” 4096^2 ê°€ ë©ë‹ˆë‹¤. 

  mini-batchë¥¼ ê°€ì§€ê³  í›ˆë ¨ì„ í•œë‹¤ë©´ ì°¨ì›ì„ í›¨ì”¬ ë” ì»¤ì§‘ë‹ˆë‹¤.

  - ex) 100ê°œì˜ mini-batch -> Jacobian ì€ [409600 x 409600]ì˜ matrix

- ì‹¤ì œë¡œëŠ” ì´ ëª¨ë“  ê±°ëŒ€í•œ Jacobian í–‰ë ¬ì— ëŒ€í•´ ì—°ì‚°ì„ í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. 

  <u>ìœ„ì˜ ì—°ì‚°ì€ element-wiseì´ê¸° ë•Œë¬¸ì— ì…ë ¥ ë²¡í„°ì˜ ëŒ€ê°ì„  ìš”ì†Œë§Œì´ ì¶œë ¥ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤. ì¦‰, Jacobian matrixëŠ” ëŒ€ê°í–‰ë ¬ì´ ë©ë‹ˆë‹¤.</u>


---

**Example**

![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328232513853.png?raw=1)

![image-20210328232830299](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328232830299.png?raw=1)
  

- **Forward propagation**ì„ í•œ í›„, **L2-norm**ì„ í†µí•´ ìµœì¢… qê°’ì„ êµ¬í•˜ë©´ `0.116`ì´ ë©ë‹ˆë‹¤.
  
  
  
![image-20210328233047243](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210328233047243.png?raw=1)

![image-20210329011306358](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329011306358.png?raw=1)
  
   


**Back-Propagation**

- 2ì°¨ì› vector `q`ì— ëŒ€í•´ ë¯¸ë¶„ì„ í•˜ë©´ `2q`ê°€ ë©ë‹ˆë‹¤.
- Wì˜ gradientë¥¼ êµ¬í•˜ê¸° ìœ„í•´ chain-ruleì„ ì ìš©í•©ë‹ˆë‹¤.
  - `2*q_i*x_j` : [[ 0.44 * 0.2, 0.44 * 0.4 ], [0.52 * 0.2, 0.52 * 0.4]]



![image-20210329011610041](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329011610041.png?raw=1)
  
  
ë‹¤ìŒì€ computational graphë¥¼ ëª¨ë“ˆí™”í•˜ì—¬ ì½”ë“œë¡œ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤. ê° ë…¸ë“œë¥¼ localí•˜ê²Œ ë³´ì•˜ê³ , upstream gradientë“¤ë¡œ chain ruleì„ ì´ìš©í•˜ì—¬ local gradientë¥¼ ê³„ì‚°í•˜ì˜€ìŠµë‹ˆë‹¤.

ìœ„ì˜ ì½”ë“œì˜

- **forward pass**ì—ì„œëŠ” ë…¸ë“œì˜ ì¶œë ¥ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ê³ 
- **backward pass**ì—ì„œëŠ” gradientë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.



![image-20210329011629470](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329011629470.png?raw=1)

![image-20210329011638860](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329011638860.png?raw=1)
  
  

**Example : Caffe layers**

- https://github.com/BVLC/caffe

|                                                              |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![image-20210329012222314](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329012222314.png?raw=1) | ![image-20210329012226463](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329012226463.png?raw=1) |



### â­ Summary

- Neural Netsì€ ë„ˆë¬´ë‚˜ë„ í¬ê¸° ë•Œë¬¸ì— ëª¨ë“  parameterë“¤ì˜ gradientë¥¼ ì§ì ‘ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
- ê·¸ë˜ì„œ <u> <b>backpropagation</b>ê°€  ì œì•ˆë˜ì—ˆê³ , ì—­ì „íŒŒì—ì„œëŠ” inputs, parameters, intermediatesì˜ ëª¨ë“  gradientë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ <b>computational graphì˜ chain rule</b>ì„ ì¬ê·€ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.</u>
- êµ¬í˜„(implementation)ì€ graph structureë¥¼ ë”°ë¥´ë©°, ê° nodeë“¤ì€ `forward()` / `backward()` APIë¥¼ ë”°ë¦…ë‹ˆë‹¤.
- **forward** : gradient ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³  ê·¸ ê³¼ì •ì—ì„œ ìƒì„±ë˜ëŠ” intermediatesë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
  - ì´ ê°’ì„ ì €ì¥í•´ì•¼ì§€ back-propagationì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.
- **backward** : chain ruleì„ ì ìš©í•˜ì—¬ inputì— ëŒ€í•´ì„œ gradientì˜ lossê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
  
  
  
  


## 2. Neural Networks

![image-20210329013148505](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329013148505.png?raw=1)
  
  

ê·¸ë™ì•ˆì€ ì„ í˜•ì˜ í•˜ë‚˜ì˜ ë ˆì´ì–´ë§Œì„ ë‹¤ë¤˜ë‹¤ë©´, ì´ì œëŠ” ë‹¤ì–‘í•œ ì¸µì˜ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•´ ê³µë¶€í•  ì˜ˆì •ì…ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ ë§í•˜ìë©´, ì‹ ê²½ë§ì€ í•¨ìˆ˜ë“¤ì˜ ì§‘í•©(class)ìœ¼ë¡œ ë¹„ì„ í˜•ì˜ ë³µì¡í•œ í•¨ìˆ˜ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜ë“¤ì„ ê³„ì¸µì ìœ¼ë¡œ ì—¬ëŸ¬ê°œ ìŒ“ì•„ì˜¬ë ¤ì•¼ í•©ë‹ˆë‹¤.
  


![image-20210329013924249](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329013924249.png?raw=1)

![image-20210329014606089](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329014606089.png?raw=1)
  


ìš°ë¦¬ê°€ ì§€ê¸ˆê¹Œì§€ ë°°ì› ë˜ ê° Computation nodeëŠ” ì‹¤ì œ ë‰´ëŸ°ì´ ì‘ë™í•˜ëŠ” ë°©ì‹ê³¼ ë¹„ìŠ·í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.

ë§ˆì§€ë§‰ì— ìˆëŠ” **activation function**ì€ ì…ë ¥ì„ ë°›ì€ í›„ ë‚˜ì¤‘ì— ì¶œë ¥ì´ ë  í•˜ë‚˜ì˜ ìˆ«ìë¥¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. 
  


![image-20210329014635788](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329014635788.png?raw=1)
  


ì—¬ì§€ê» ë°°ì› ë˜ layerë“¤ì€ **Fully-connected**ë˜ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, í•œ layerì˜ ëª¨ë“  ë‰´ëŸ°ì´ ë‹¤ìŒ layerì˜ ëª¨ë“  ë‰´ëŸ°ë“¤ê³¼ ì—°ê²°ë˜ì–´ìˆëŠ” ìƒíƒœì…ë‹ˆë‹¤.
  


![image-20210329014835495](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329014835495.png?raw=1)

![image-20210329014843238](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/cs231n/images//lec4/image-20210329014843238.png?raw=1)

  
  
  

## Summary 

ì‹ ê²½ë§ì´ ë¬´ì—‡ì¸ì§€ì™€ ì–´ë–»ê²Œ ë‰´ëŸ°ë“¤ì„ ì„ í˜• layerì™€ fully-connectedë¡œ ì¬ë°°ì—´í•˜ëŠ”ì§€ì— ëŒ€í•´ ë°°ì› ìŠµë‹ˆë‹¤.	

- ê°€ì¤‘ì¹˜ê³±, activation function, max ... ë“±ë“±
  
  
  
  
---
ìœ„ì˜ ë‚´ìš© ì¤‘ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë‹¤ë©´ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš” :)

ê°ì‚¬í•©ë‹ˆë‹¤.