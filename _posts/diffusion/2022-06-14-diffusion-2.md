---
title: "[Paper Review] DDIM: Denoising Diffusion Implicit Models 논문 리뷰" 
excerpt: ""

categories:
 - diffusion
tags:
  - deeplearning
  - ai
  - pytorch
  - vision
search: true

# 목차
toc: true  
toc_sticky: true 

use_math: true
---

- Paper: Denoising Diffusion Implicit Models (ICLR 2021): [arxiv](https://arxiv.org/abs/2010.02502), [code](https://github.com/ermongroup/ddim)


> DDPM은 adversarial training 없이도 image generation이 잘됨을 증명하였다. 그러나 markov chain을 이용하여 모델을 학습하고 추론하기 때문에 sample을 생성하려면 많은 step(거의 수천 step)을 거쳐야한다는 문제가 있다.
>
> DDIM에서는 좀 더 빠르게 sample을 생성하기 위해 non-markovian diffusion process로 DDPM을 일반화한다. non-Markovian process를 통해 좀더 deterministic한 generative process를 학습시킬 수 있으며, high quality의 sample을 보다 빠르게 생성할 수 있게 되었다.


DDPM은 forward *diffusion process* (from data to noise)의 역과정, generative process (from noise to data)를 학습한다. 이 생성 과정은 markov chain을 통해 이뤄지기 때문에 single sample을 만드는데에는 수천 step을 거쳐야하며, GAN과 비교하면 속도가 매우 느리다.

DDIM에서는 diffusion model의 속도를 빠르게 하게 위해 implicit probabilistic model을 제안하였다. (DDPM과 objective function은 동일)

---

## 1. Background

**DDPM**

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled.png?raw=1' width = '800' ></p>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%201.png?raw=1' width = '800' ></p>

 

**Simplified Loss function of DDPM**

<p align="center"><img src="https://latex.codecogs.com/svg.image?L_{\gamma}\left(\epsilon_{\theta}\right):=\sum_{t=1}^{T} \gamma_{t} \mathbb{E}_{\boldsymbol{x}_{0} \sim q\left(\boldsymbol{x}_{0}\right), \epsilon_{t} \sim \mathcal{N}(\mathbf{0}, I)}\left[\left\|\epsilon_{\theta}^{(t)}\left(\sqrt{\alpha_{t}} \boldsymbol{x}_{0}+\sqrt{1-\alpha_{t}} \epsilon_{t}\right)-\epsilon_{t}\right\|_{2}^{2}\right]" /></p>

---

## 2. Variational Inference For Non-Markovian Forward Processes

### 2.1 Non-Markovian Forward Process

DDIM에서는 DDPM과 동일하게 marginal distribution을 구성하지만, inference 과정에 사용되는 joint distribution의 경우는 약간 다르게 distribution을 구성하였다.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%202.png?raw=1' width = '550' ></p>

- DDPM은 <img src="https://latex.codecogs.com/svg.image?x_t" /> 가 바로 이전 step 값 <img src="https://latex.codecogs.com/svg.image?x_{t-1}" /> 에 의해 결정되는 `markovian chain`이지만
- DDIM은 <img src="https://latex.codecogs.com/svg.image?x_t" /> 가 바로 이전 step 값 <img src="https://latex.codecogs.com/svg.image?x_{t-1}" /> 과 <img src="https://latex.codecogs.com/svg.image?x_0" /> 에 의해 결정되는 `non-markovian chain`이다.
    
    

또한, DDPM에 따르면 posterior distribution은 아래의 두 식을 만족하는데, (애초에 define을 이렇게 하였음)

<p align="center"><img src="https://latex.codecogs.com/svg.image?q_{\sigma}\left(\boldsymbol{x}_{T} \mid \boldsymbol{x}_{0}\right)=\mathcal{N}\left(\sqrt{\alpha_{T}} \boldsymbol{x}_{0},\left(1-\alpha_{T}\right) \boldsymbol{I}\right)" /></p>

<p align="center"><img src="https://latex.codecogs.com/svg.image?q_{\sigma}\left(\boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)=\mathcal{N}\left(\sqrt{\alpha_{t}} \boldsymbol{x}_{0},\left(1-\alpha_{t}\right) \boldsymbol{I}\right)" /></p>

이 식들을 만족하려면 reverse conditional distribution의 mean값이 다음과 같아야 된다고 한다.

<p align="center"><img src="https://latex.codecogs.com/svg.image?q_{\sigma}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}, \boldsymbol{x}_{0}\right)=\mathcal{N}\left(\sqrt{\alpha_{t-1}} \boldsymbol{x}_{0}+\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}} \cdot \frac{\boldsymbol{x}_{t}-\sqrt{\alpha_{t}} \boldsymbol{x}_{0}}{\sqrt{1-\alpha_{t}}}, \sigma_{t}^{2} \boldsymbol{I}\right)" /></p>

- 이 식 유도가 안되는데.. 어떻게 나온 건지 잘 모르겠다 (DDPM의 식이랑은 완전 대응되지는 않는 듯?)
- 아마 `reverse conditional distribution`식을 위와 같이 정의하면.. 대충 unit variance가 1로 유지되면서, 차후에 전개되는 식들이 DDPM의 식들과 잘 대응이 돼서 이렇게 정의한 것 같다.

**Forward Process**

bayes’ rule에 따라 forward process 식을 정리하면 다음과 같으며, 이 역시 gaussian distribution을 따른다.

<p align="center"><img src="https://latex.codecogs.com/svg.image?q_{\sigma}\left(\boldsymbol{x}_{t} \mid \boldsymbol{x}_{t-1}, \boldsymbol{x}_{0}\right)=\frac{q_{\sigma}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}, \boldsymbol{x}_{0}\right) q_{\sigma}\left(\boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}{q_{\sigma}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{0}\right)}" /></p>

- DDIM의 Forward Process는 DDPM과는 다르게 더이상 markovian이 아니다. ⭐️
- <img src="https://latex.codecogs.com/svg.image?\sigma" /> : forward process가 얼마나 stochastic 한지를 결정하며, 이 값이 0에 가까워질수록 deterministic 해짐
    - <img src="https://latex.codecogs.com/svg.image?x_{t-1}" /> 가 <img src="https://latex.codecogs.com/svg.image?x_0, x_t" /> 에 의해 결정됨

---

### 2.2 Generative Process and Unified Variational Inference Objective

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%203.png?raw=1' width = '800' ></p>

**Variational Inference Objective**

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%204.png?raw=1' width = '600' ></p>

- 중요한건 아니지만.. 논문 수식 (11)번에서 log 가 빠져있는 것 같습니다.. 오타인 듯 해용 😂
- <img src="https://latex.codecogs.com/svg.image?\sigma" /> 를 어떤 값으로 선택하냐에 따라 다른 모델이 된다.
    - 만약 <img src="https://latex.codecogs.com/svg.image?\sigma=0" /> 으로 둔다면, 이 함수는 DDIM의 objective function이 되며
    - <img src="https://latex.codecogs.com/svg.image?\sigma=" /> 로 둔다면, 이 함수는 DDPM의 objective function이 된다.

**DDPM의 Variational objective, <img src="https://latex.codecogs.com/svg.image?L_r" />**

<p align="center"><img src="https://latex.codecogs.com/svg.image?L_{\gamma}\left(\epsilon_{\theta}\right):=\sum_{t=1}^{T} \gamma_{t} \mathbb{E}_{\boldsymbol{x}_{0} \sim q\left(\boldsymbol{x}_{0}\right), \epsilon_{t} \sim \mathcal{N}(\mathbf{0}, I)}\left[\left\|\epsilon_{\theta}^{(t)}\left(\sqrt{\alpha_{t}} \boldsymbol{x}_{0}+\sqrt{1-\alpha_{t}} \epsilon_{t}\right)-\epsilon_{t}\right\|_{2}^{2}\right]" /></p>

- <img src="https://latex.codecogs.com/svg.image?\epsilon_{\theta}^t" /> 는 서로 다른 t에 대해서 parameter <img src="https://latex.codecogs.com/svg.image?\theta" /> 를 공유하지 않는다. → <img src="https://latex.codecogs.com/svg.image?\epsilon_{\theta}" /> 은 오직 weight <img src="https://latex.codecogs.com/svg.image?\gamma" /> 에 의해 최적화됨
- 만약  
<img src="https://latex.codecogs.com/svg.image?\gamma=1" /> 이라면, objective function은 DDPM의 variational lower bound와 같다.
    - <img src="https://latex.codecogs.com/svg.image?L_1 = J_{\sigma}" />
- 또한 Theorem 1 에 따르면 <img src="https://latex.codecogs.com/svg.image?J_{\sigma}" /> 은 <img src="https://latex.codecogs.com/svg.image?L_{\gamma}" /> 의 일종인데, <img src="https://latex.codecogs.com/svg.image?J_{\sigma}" /> 는  
<img src="https://latex.codecogs.com/svg.image?\gamma=1" /> 일때 (<img src="https://latex.codecogs.com/svg.image?L_1" />) 최적의 값을 가진다.

<p align="center"><img src="https://latex.codecogs.com/svg.image?\text { For all } \sigma>\mathbf{0} \text {, there exists } \gamma \in \mathbb{R}_{>0}^{T} \text { and } C \in \mathbb{R} \text {, such that } J_{\sigma}=L_{\gamma}+C \text {. }" /></p>

---

## 3. Sampling From Generalized Generative Processes

Theorem 1 에 따르면,  
<img src="https://latex.codecogs.com/svg.image?\gamma=1" /> 로 두었을 때 optimal solution을 구할 수 있었다. 따라서 <img src="https://latex.codecogs.com/svg.image?L_1" />을 objective function으로써 사용한다고 해보자. 

우리는 <img src="https://latex.codecogs.com/svg.image?\sigma" /> 을 어떻게 설정하냐에 따라서 forward process를 markovian process로 학습시킬 수도 있고, non-markovian process로 학습시킬 수도 있다. 이때 주의할 점은  <img src="https://latex.codecogs.com/svg.image?\sigma" /> 를 어떤 값으로 두냐와 상관없이 우리가 학습해야하는 parameter는 <img src="https://latex.codecogs.com/svg.image?\theta" /> 라는 점이다.

> - 즉, markovian process로 학습시킨 pretrained DDPM model의 parameter <img src="https://latex.codecogs.com/svg.image?\theta" /> 를 DDIM의 generative process에도 이용할 수 있게 된다는 것이다.
> - 여기서 짚고 넘어갈 게 있는데, DDIM은 새로운 훈련 방법을 제시했다기 보다는 diffusion process의 objective function을 non-markovian chain으로 generalize하고, 좀 더 빠르게 이미지 생성이 가능하도록 새로운 sampling 방법을 제시했다는 점에 있다. 
> - 요즘 트렌드는 DDPM으로 학습시킨 모델을 DDIM의 generation 방식으로 sampling 하는 방식이다. 이렇게 하면 좋은 성능의 모델(DDPM)을 사용하면서, 이미지를 빠르게 sampling할 수 있다.


### 3.1 Denoising Diffusion Implicit Models

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%205.png?raw=1' width = '800' ></p>

### 3.2 Accelerated Generation Process

generative process는 reverse process 와 매우 유사하다. 따라서 만약 forward process가 T step을 거친다면 일반적으로 generative process도 T step을 가지곤 하는데, DDIM에서는 이를 빠르게 수행할 수 있다.

<img src="https://latex.codecogs.com/svg.image?q_{\sigma}\left(\boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)" /> 이 fix 되어 있는 한, denoising objective <img src="https://latex.codecogs.com/svg.image?L_1" /> 은 특별한 forward procedure에 의존하지 않으며, forward process도 T 보다 짧은 step으로 줄일 수 있기 때문에 generative process도 더 가속화가 가능하다.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%206.png?raw=1' width = '800' ></p>

**Appendix C.1**

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%207.png?raw=1' width = '600' ></p>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%208.png?raw=1' width = '600' ></p>

위와 같이 sampling을 하면 빠르게 이미지를 추출할 수 있지만, forward step에서 임의의 step에 대해서만 모델을 학습했기 때문에, generative process에서도 일부만 sampling할 수 있다. 따라서 더 많은 step에 대해 학습을 할 필요가 있다.

- `DDIM`의 이 방식처럼 임의의 step의 forward step에서만 모델을 훈련시키는 것보다 `DDPM`처럼 수많은 step에 대해서 모델을 학습시키는게 더 효과적이다.
- 그래서 요즘 `DDPM`으로 학습시키고 `DDIM`으로 sampling하는 듯?

### 3.3 Relevance to Neural ODEs

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%209.png?raw=1' width = '700' ></p>

## 4. Experiments

- DDIM은 DDPM보다 훨씬 더 적은 iteration으로 이미지 생성이 가능하다 (10~100배 더 빠름)
- DDPM과 다르게 한번 initial latent variables <img src="https://latex.codecogs.com/svg.image?x_T" /> 가 fix 되면, generation trajectory와 상관없이 항상 high-level의 이미지를 생성할 수 있으며 latent space 상에서의 interpolation도 가능하다
- latent code에서의 이미지 recon도 가능 (DDPM은 stochastic sampling process로 이미지를 생성했기 때문에 불가능했음)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%2010.png?raw=1' width = '600' ></p>

### 4.1 Sample Quality and Efficiency

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%2011.png?raw=1' width = '800' ></p>

- <img src="https://latex.codecogs.com/svg.image?\eta=0.0" /> 이면 `DDIM`, <img src="https://latex.codecogs.com/svg.image?\eta=1.0" /> 이면 `DDPM`
    - 
- <img src="https://latex.codecogs.com/svg.image?\operatorname{dim}(\tau)" /> 을 키울수록 sample quality가 좋아짐: sample quality와 computational costs는 trande-off 관계
- DDIM이 DDPM보다 훨씬 결과가 좋음

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%2012.png?raw=1' width = '600' ></p>

- 기존에 DDPM으로는 1000 step 정도 거쳐야 얻을 수 있었던 결과를 DDIM에서는 20~100 step 안에 얻을 수 있게됨
    - DDPM 대비 10~50배 빨라짐

### 4.2 Sample Consistency in DDIMs

DDIM은 generative process가 deterministic하다. <img src="https://latex.codecogs.com/svg.image?x_0" /> 는 오직 initial state <img src="https://latex.codecogs.com/svg.image?x_T" /> 에 의존

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%2013.png?raw=1' width = '600' ></p>

더 많은 time step을 밟을수록(sample trajetories를 길게 잡을수록) high-quality의 정보가 생성되지만, 본질적으로 같은 <img src="https://latex.codecogs.com/svg.image?x_T" /> 를 사용했다면 sample의 결과는 동일하다.

- 즉, <img src="https://latex.codecogs.com/svg.image?x_T" /> 가 image의 informative latent encoding 역할을 한다고 볼 수 있다.

### 4.3 Interpolation in Deterministic Generative Processes

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%2014.png?raw=1' width = '600' ></p>

- high-level feature는 <img src="https://latex.codecogs.com/svg.image?x_T" /> 에 의해 encoding 된다. 따라서 마치 GAN 처럼 latent variable인 <img src="https://latex.codecogs.com/svg.image?x_T" /> 를 interpolation하면 이미지 역시 interpolation이 가능해진다.
- DDPM에서는 이것이 불가능

### 4.4 Reconstruction From Latent Spcae

DDIM에서는 ODE로 Euler intergration을 하기 때문에 이미지 <img src="https://latex.codecogs.com/svg.image?x_0" /> 을 <img src="https://latex.codecogs.com/svg.image?x_T" /> 로 encoding하는 것이 가능하다. 이후 다시 <img src="https://latex.codecogs.com/svg.image?x_0" /> 으로도 reconstruction 할수도 있다.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/ddim/Untitled%2015.png?raw=1' width = '600' ></p>

- S가 커질수록 reconstruction이 잘됨
