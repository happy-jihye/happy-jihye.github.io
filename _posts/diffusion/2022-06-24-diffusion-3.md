---
title: "[Paper Review] I-DDPM: Improved Denoising Diffusion Probabilistic Models 논문 리뷰" 
excerpt: ""

categories:
 - diffusion
tags:
  - deeplearning
  - ai
  - pytorch
  - vision
search: true

# 목차
toc: true  
toc_sticky: true 

use_math: true
---

- Paper: Improved Denoising Diffusion Probabilistic Models (PMLR 2021): [arxiv](https://arxiv.org/abs/2102.09672), [code](https://github.com/openai/improved-diffusion)


## 1. Improving the Log-Likelihood

- DDPM 모델은 FID나 Inception Score 에서는 좋은 score를 냈지만, log-likelihood score는 좋지 않았음
- 논문에서는 비교 지표로 `NLL (Negative log-likelihood)` 를 사용
    - NLL: <img src="https://latex.codecogs.com/svg.image?\min -\log \left(p\left(y \mid f_{\theta}(x)\right)\right)" />
    - generative model이 얼마나 data distribution의 mode에 대한 정보를 잘 담고 있는지를 측정해주는 metric이다. 만약 mode coverage가 안 좋은 모델이라면(mode collapse), 이 score가 안좋게 나온다.
    - 최근 연구에 따르면 log-likelihood score에서의 향상이 sample quality나 learnt feature representation의 발전도 나타낸다고 한다.

> 본 논문은 DDPM에서 왜 log-likelihood score가 안좋은지를 분석하고 이를 개선하고자 한다. (이 metric score가 안좋다는건 DDPM의 mode coverage 성능이 안좋다는 것) 저자들은 이를 위해 ImageNet이나 CIFAR-10과 같은 diversity가 큰 데이터셋을 가지고 실험을 해보았으며, DDPM의 모델을 수정하여 diversity와 resolution 모두를 잡은 모델을 만들고자 하였다.


### 1.1 Learning <img src="https://latex.codecogs.com/svg.image?\Sigma_{\theta}\left(x_{t}, t\right)" />

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled.png?raw=1' width = '600' ></p>

- (복습) DDPM
    - DDPM의 저자들은 <img src="https://latex.codecogs.com/svg.image?\Sigma_{\theta}\left(x_{t}, t\right)" /> 을 <img src="https://latex.codecogs.com/svg.image?\sigma_{t}^{2} \mathbf{I}" /> 로 정의하고, <img src="https://latex.codecogs.com/svg.image?\sigma_{t}^{2}" />  를 학습하지 않는 fixed variable로 두었다.
    - 본래  <img src="https://latex.codecogs.com/svg.image?\sigma_{t}^{2}" />  는 <img src="https://latex.codecogs.com/svg.image?\tilde{\beta}_{t}:=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t}} \beta_{t}" /> 로 정의하는 것이 이론적으로 옳지만,
    - 저자들은 실험을 하다보니 <img src="https://latex.codecogs.com/svg.image?\sigma_{t}^{2}" />  를 <img src="https://latex.codecogs.com/svg.image?\beta_{t}" /> 로 단순하게 정의한 후 모델을 학습해도 sample quality 측면에서 <img src="https://latex.codecogs.com/svg.image?\tilde{\beta}_{t}" /> 를 사용할 때와 비슷하다는 것을 밝혀내었고, 실제 실험에서는 <img src="https://latex.codecogs.com/svg.image?\beta_{t}" /> 를 사용하였다.
- (Figure 1) diffusion step 이 커지면 <img src="https://latex.codecogs.com/svg.image?\beta_{t}" /> 와 <img src="https://latex.codecogs.com/svg.image?\tilde{\beta}_{t}" /> 는 거의 유사해진다.
    - 즉, model distribution을 추정하는데에는 variance 보다 mean 값이 훨씬 중요함을 알 수 있다.

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%201.png?raw=1' width = '600' ></p>

- (복습) DDPM
    - DDPM의 loss: `variational lower bound(vlb)`
    
    <p align="center"><img src="https://latex.codecogs.com/svg.image?\begin{aligned}L_{\mathrm{vlb}} &:=L_{0}+L_{1}+\ldots+L_{T-1}+L_{T} \\L_{0} &:=-\log p_{\theta}\left(x_{0} \mid x_{1}\right) \\L_{t-1} &:=D_{K L}\left(q\left(x_{t-1} \mid x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t-1} \mid x_{t}\right)\right) \\L_{T} &:=D_{K L}\left(q\left(x_{T} \mid x_{0}\right) \| p\left(x_{T}\right)\right)\end{aligned}" /></p>
    
- (Figure2)는 diffusion process에서 처음 몇 step이 variational lower bound를 결정하는데 매우 중요한 역할을 함을 보여준다. 저자들은 이 원인이 variance 때문이라고 생각하였고, model의 variance인 <img src="https://latex.codecogs.com/svg.image?\Sigma_{\theta}\left(x_{t}, t\right)" /> 을 학습시키면 좀 더 좋은 결과를 낼 수 있을 것이라고 판단하였다.
    - `Figure2`의 결과는 훈련이 다 된 모델에 대해서 t diffusion step의 <img src="https://latex.codecogs.com/svg.image?L_t" /> 를 계산해본 것이다. 결과를 보면 초기 step에서의 loss가 유독 큰 것을 확인할 수 있는데, 이렇게 되면 이들의 summation인 최종 loss, <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 가 제대로 학습되지 않을 수도 있다.
        - 이미지가 어느정도 나왔을 때에 대해서만 (few steps of diffusion process) denoising network가 잘 학습될 수 있음
        - 따라서 처음 몇 step에서의 loss 값을 조정해줄 필요가 있다. 저자들은 이러한 현상의 원인이 variance 때문이라고 판단하였고 이 값을 학습하고자 하였다.
- 저자들은 <img src="https://latex.codecogs.com/svg.image?\Sigma_{\theta}\left(x_{t}, t\right)" /> 을 neural network를 통해 학습시켰으며, 이 variance 값을 <img src="https://latex.codecogs.com/svg.image?\beta_{t}" /> 와 <img src="https://latex.codecogs.com/svg.image?\tilde{\beta}_{t}" /> 를 interpolation 한 값으로 굉장히 rough하게 정의내렸다.
    
    <p align="center"><img src="https://latex.codecogs.com/svg.image?\Sigma_{\theta}\left(x_{t}, t\right)=\exp \left(v \log \beta_{t}+(1-v) \log \tilde{\beta}_{t}\right)" /></p>
    
    - step이 커지면 <img src="https://latex.codecogs.com/svg.image?\beta_{t}" /> 와 <img src="https://latex.codecogs.com/svg.image?\tilde{\beta}_{t}" /> 중 어떤 걸 사용하더라도 학습이 잘 되니까.. 대략 이 값들과 유사한 값으로 간단하게 정의를 내리고, 처음 몇 step 에서만 detail 하게 값을 잡아주려고 interpolation 기법을 사용한 것 같다
    - 이때, <img src="https://latex.codecogs.com/svg.image?\beta" /> 의 값이 너무 작아서 log scale을 사용했다고 하며, <img src="https://latex.codecogs.com/svg.image?v" /> 는 모델에서 예측하고자 하는 output 값으로, variance를 예측해주는 역할을 한다.
    - 학습하는 variable은 <img src="https://latex.codecogs.com/svg.image?v" /> vector
- 최종 objective function으로는 `hybrid objective`를 사용한다.
    
    <p align="center"><img src="https://latex.codecogs.com/svg.image?L_{\text {hybrid }}=L_{\text {simple }}+\lambda L_{\mathrm{vlb}}" /></p>
    
    - <img src="https://latex.codecogs.com/svg.image?L_{\text {simple }}" />: variance에 관계없는 loss term으로, DDPM에서 단순화한 objective function이다.
        
        <p align="center"><img src="https://latex.codecogs.com/svg.image?L_{\text {simple }}(\theta):=\mathbb{E}_{t, \mathbf{x}_{0}, \boldsymbol{\epsilon}}\left[\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\theta}\left(\sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}} \boldsymbol{\epsilon}, t\right)\right\|^{2}\right]" /></p>
        
        - <img src="https://latex.codecogs.com/svg.image?L_{\mathrm{vlb}}" /> 만 사용해서 학습을 하니까 성능이 안나와서 simplifed loss term (<img src="https://latex.codecogs.com/svg.image?\epsilon_{\theta}" />를 학습시키는 loss)을 사용했다고 함 (절 참고)
    - <img src="https://latex.codecogs.com/svg.image?L_{\mathrm{vlb}}" /> : 주의할 점은 여기서 mean 값을 예측하는 gradient는 꺼버리고, 오직 variance만 학습하도록 바꿔주었다고 한다.
        - <img src="https://latex.codecogs.com/svg.image?L_{\text {simple }}" />가 알아서 denoising 하는 쪽은 잘 학습시키니까 <img src="https://latex.codecogs.com/svg.image?L_{\mathrm{vlb}}" /> 는 variance를 어떤 값으로 정할지만 학습하도록 한 듯?

### 1.2 Improving the Nosing Schedule

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%202.png?raw=1' width = '600' ></p>

- (복습) DDPM에서는 variance schedule을 10^(-4)부터 2*10^2로 linear하게 증가시켜가며 학습했었다.
- (Figure3) 만 봐도 상단의 row는 너무나도 빠르게 noisy 해지는 걸 확인할 수 있다.
- (Figure4) linear하게 scheduling을 한 경우에는, 실제로 reverse diffusion process에서 20% 정도를 skip하고 이미지를 생성해도 비슷한 결과가 나온다 → 맨 마지막 step의 이미지들이 너무 과하게 noise하다는 것..
    - diffusion step의 마지막 20% step 정도는 전부 gaussian noise를 따른다고 해석할 수도 있다. (T step에서만 (0,1)의 gaussian distribution을 따르는게 아니라 0.8T step에서도 대략 (0,1)의 gaussian distribution을 따른다고 볼 수 있다.)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%203.png?raw=1' width = '600' ></p>

- 저자들은 이를 해결하기 위해 noise schedule을 다음과 같이 sinusoidal 함수를 이용해서 했다.
    - sinusoidal function을 이용한건 딱히 이유가 있진 않고, 그냥 수학적으로 유명한 식이기도 하고 noise schedule를 이렇게 잡으니까 variance가 잘 잡혀서 그랬다고 한다. (Figure 5 참고)
    
    <p align="center"><img src="https://latex.codecogs.com/svg.image?\bar{\alpha}_{t}=\frac{f(t)}{f(0)}, \quad f(t)=\cos \left(\frac{t / T+s}{1+s} \cdot \frac{\pi}{2}\right)^{2}" /></p>
    

### 1.3 Reducing Gradient Noise

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%204.png?raw=1' width = '600' ></p>

본래 저자들은 <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 만을 사용해도 학습이 잘될 줄 알았는데, 실제로 `ImageNet 64x64 dataset` 처럼 diversity가 큰 data에 대해 학습을 하니 <img src="https://latex.codecogs.com/svg.image?L_{\text {hybrid }}" />를 쓸 때 보다 optimize가 잘 안됐다고 한다.

- (Figure 6) <img src="https://latex.codecogs.com/svg.image?L_{\text {hybrid }}" />가 log-likelihood를 더 잘 학습시킴

저자들은 이 원인이 <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 의 gradient에 너무 noise가 많이 껴서 그렇다고 추측하였고, gradient noise를 scale한 후 이를 바탕으로 <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 의 variance를 다시 구했다.

- DDPM에서 처럼 t를 uniform 하게 sampling한 후, 임의의 t step에 대해 vlb loss를 구하면 noise가 너무 많이 껴서 loss가 널뛰기를 한다.

<p align="center"><img src="https://latex.codecogs.com/svg.image?L_{\mathrm{vlb}}=E_{t \sim p_{t}}\left[\frac{L_{t}}{p_{t}}\right] \text {, where } p_{t} \propto \sqrt{E\left[L_{t}^{2}\right]} \text { and } \sum p_{t}=1" /></p>

- 따라서 저자들은 이전의 10개의 loss 값들을 queue에 넣어둔 후 이를 바탕으로 scaling을 하도록 해서 안정적으로 loss가 학습되도록 했다고 한다. (학습 초기에는 queue가 비어있으니까 임의로 10개를 sampling해서 uniform 시켰다고 함)
    - batch training을 안정화하는 거랑 비슷한 느낌인 듯?
- (Figure 6) 그 결과 <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 를 사용했을 때의 결과가 가장 좋았다고 한다
    - <img src="https://latex.codecogs.com/svg.image?L_{hybrid }" /> 에 noise를 줄이는 이 sampling 기법을 사용해보기도 했는데, 이 경우에는 noise가 딱히 안줄었다고 함

## Results and Ablations

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%205.png?raw=1' width = '550' ></p>

- cosine schedule을 하면 NLL, FID 모두 좋아짐
- <img src="https://latex.codecogs.com/svg.image?L_{hybrid}" /> + cosine schedule: baseline보다 NLL은 좋아지지만, FID가 안좋아짐
- <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> + cosine schedule의 경우 NLL은 좋아지나, 매우매우 FID가 안좋아진다.
    - 🧐  <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 는 mean과 variance 모두를 학습하는 loss term인데, 여기서 mean에 비해 별로 중요하지 않은 variance가 비교적 강하게 학습이 되고 있어서 성능이 잘 안나오는 것 같다. mean을 좀 더 잘 학습하도록 constraint를 걸어주면 <img src="https://latex.codecogs.com/svg.image?L_{vlb}" /> 도 잘 학습될 듯?

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%206.png?raw=1' width = '600' ></p>

log likelihood를 비교해보면 Improved diffusion model이 가장 좋았다

## Improving Sampling Speed

본 모델은 4k step으로 학습되었다. 훈련때 처럼 inference 때 4k step을 모두 거쳐 denoising을 하면 sampling 속도가 너무 느리다. 저자들은 기존의 pre-trained <img src="https://latex.codecogs.com/svg.image?L_{hybrid}" /> model에 대해 좀 더 빠르게 sampling을 하기 위해 diffusion step을 줄여보았다고 한다.

- 예를 들어 모델이 <img src="https://latex.codecogs.com/svg.image?T" /> diffusion steps으로 훈련되었다고 하면,
- 여기서 임의의 subsequence <img src="https://latex.codecogs.com/svg.image?S" /> 를 뽑아서 sampling noise schedule <img src="https://latex.codecogs.com/svg.image?\bar{\alpha}_{S_t}" /> 를 계산하고 이를 바탕으로 sampling variances를 구한다.

<p align="center"><img src="https://latex.codecogs.com/svg.image?\beta_{S_{t}}=1-\frac{\bar{\alpha}_{S_{t}}}{\bar{\alpha}_{S_{t-1}}}, \quad \tilde{\beta}_{S_{t}}=\frac{1-\bar{\alpha}_{S_{t-1}}}{1-\bar{\alpha}_{S_{t}}} \beta_{S_{t}}" /></p>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%207.png?raw=1' width = '600' ></p>

- (Figure 8) 4k steps으로 훈련된 <img src="https://latex.codecogs.com/svg.image?L_{hybrid}, L_{simple}" /> model이 있을 때, 25, 50, 100, 200, 400, 1000, 4000로 sampling한 결과
    - DDIM이나 <img src="https://latex.codecogs.com/svg.image?L_{simple}" /> 과 비교했을 때 성능이 좋음

## Comparision to GANs

저자들은 GAN model과 비교했을 때 Improved-Diffusion 모델이 얼마나 mode-coverage가 좋은지를 비교하기 위해 `precision and recall` metric을 사용해봤다고 한다. 

- `GAN`: class conditional model 이용
    - BigGAN-deep with 100M param
- `Improved-diffusion`: timestep embedding <img src="https://latex.codecogs.com/svg.image?e_t" /> 에 class embedding <img src="https://latex.codecogs.com/svg.image?v_i" /> 를 추가한 후, 이 embedding vector를 residual block에 넣어 model에 추가
    - small model with 100M param for 1.7 M training steps
    - larger model with 270M param for 250K training steps

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%208.png?raw=1' width = '600' ></p>

결과는 Table4 참고

- **Precision** (quality) & **Recall** (diversity)

GAN은 unsupervised 하게 model의 distribution을 real data의 distribution에 fitting하나, diffusion model은 직접적으로 모델이 real data의 distribution을 따르도록 학습하기 때문에 좀 더 diversity 적인 면에서 장점이 있다.

## Scaling Model Size

최근 연구들은 model size를 키우고, 더 많이 학습시킬 수록 모델의 성능이 좋아짐을 밝혔다. 

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/diffusion/iddpm/Untitled%209.png?raw=1' width = '550' ></p>

저자들은 DDPM에서의 model scale과 training compute의 영향을 조사하기 위해 실험을 해보았고, 그결  `Figure 10`처럼 이 둘을 키울수록 FID와 NLL이 좋아짐을 확인할 수 있었다고 한다.