---
title: "[Paper Review] BicycleGAN : Toward Multimodal Image-to-Image Translation 논문 분석"
excerpt: " "


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# 목차
toc: true  
toc_sticky: true 

use_math: true
---

> ✍🏻 이번 포스팅에서는 unpaired dataset에 대해서도 Image-to-Image translation을 하는 **CycleGAN model**에 대해 살펴본다.


- Paper : [[BicycleGAN] Toward Multimodal Image-to-Image Translation](https://arxiv.org/abs/1711.11586) (NeurIPS 2018 / Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman)

- [GAN-Zoos! (GAN 포스팅 모음집)](https://happy-jihye.github.io/gan/)

---

기존의 image-to-image translation 연구들은 여러개의 latent code에서 하나의 output으로 many-to-one mapping 되는 **mode collapse** 문제가 있었다. 본 논문에서는 이를 해결하기 위해 다양한 objection function과 network architecture, latent code들을 제시하였다. 또한, latent encoding과 output 가 mapping될 수 있도록 하여 bijective consistency를 가지도록 하였고, 이로써 다양하고 현실적인 이미지를 생성할 수 있게 되었다.


## 1. Introduction

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan1.PNG?raw=1' width = '800' ></p>

그동안의 생성모델은 하나의 이미지를 생성했다면, 본 논문은 **하나의 input으로 부터 여러 개의 이미지를 생성하는 Multimodal Image-to-Image Translation에 관한 연구**이다. BicycleGAN은 (1) 현실적이고 (2) 다양한 이미지 생성을 목표로 한다.

multimodality한 이미지를 만드려면 low-dimensional latent code의 확률분포를 잘 활용해서 input에 포함되지 않은 정보들을 output으로 생성할 수 있어야한다. 즉, mode-collapse가 생기지 않도록 아주 작은 수의 input을 output과 mapping 해야한다.

---

**Pix2Pix**

본 논문은 paired dataset에 대해 고해상도의 이미지를 생성한 **pix2pix framework**를 기반으로 하였다.
- [[Paper Review] Pix2pix : Image-to-Image Translation with Conditional Adversarial Networks 논문 분석](https://happy-jihye.github.io/gan/gan-8/)

pix2pix의 loss function은 latent code와 실제 input image를 모두 입력으로 받아 학습을 한다. 이때, 문제는 이 latent code가 이미지의 다양성을 늘려주지 않는다는 것이다. (latent code를 넣었을 때나 뺐을 때 모두 비슷하게 학습이 됨) 따라서 본 논문은 latent code가 생성 이미지를 다양하게 만들어주도록 latent space와 output이 bijetion한 관계를 갖도록 장려하였다.

**CycleGAN**

또한, BicycleGAN은 CycleGAN처럼 (1) latent code를 output으로 mapping하고 (2) output 이미지를 latent space로 다시 복구하는 encoder를 학습하여 여러개의 latent code가 하나의 image를 생성하지 않도록 한다.
- [[Paper Review] CycleGAN : Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks 논문 분석](https://happy-jihye.github.io/gan/gan-10/)

## 2. Related Work

**Generative modeling**

다양한 생성 모델이 있지만 GAN이 효과적이다.

---

**Conditional Image Generation**

- conditional VAEs
- autoregressive models
- image-to-image conditional GANs
  - (좋은 성능) 고해상도의 이미지를 생성할 수 있다
  - 다만, Generator가 random noise를 무시하고 conditional information만을 이용하여 이미지를 생성하기 때문에 다양성이 떨어진다. (noise를 무시하면 학습이 더 안정적으로 됨)

---

**Explicitly-encoded multimodality**

latent와 image space가 tight하게 연결되도록 이 둘을 encoding한 후, generator에 넣어 학습을 시킨다.

## 3. Multimodal Image-to-Image Translation




