---
title: "[Paper Review] Pix2pix : Image-to-Image Translation with Conditional Adversarial Networks ë…¼ë¬¸ ë¶„ì„"
excerpt: "image-to-image translationì— convolutional GANì˜ networkë¥¼ ì ìš©í•œ pix2pix modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."

categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” image to imageì˜ ì´ˆì°½ê¸° ëª¨ë¸ë¡œ ìœ ëª…í•œ **Pix2Pix model**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.

2021.04.13 ê¸°ì¤€ìœ¼ë¡œ 8621íšŒ ì¸ìš©ë˜ì—ˆë„¤ìš”...ğŸ˜®

- Paper : [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004) (CVPR 2017 / Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros)
- [Image-to-Image Demo](https://affinelayer.com/pixsrv/)
- [Image-to-Image Translation with Conditional Adversarial Nets Site](https://phillipi.github.io/pix2pix/)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---


> â­**Pix2pix** : Image-to-Image Translation with Conditional Adversarial Networks

**Key Point**
- inputì—ì„œ output imageë¡œ mappingí•˜ëŠ” Conditional Adversarial Networks
- mapping network í›ˆë ¨ì— ì‚¬ìš©ë˜ëŠ” loss function


---
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix1.PNG?raw=1' width = '700' ></p>

paired datasetì— ëŒ€í•´ image-to-image taskë¥¼ ìˆ˜í–‰í•œë‹¤.

## 1. Introduction

ê¸°ì¡´ì—ëŠ” CNNì„ ì´ìš©í•˜ì—¬ image-to-image taskë¥¼ ìˆ˜í–‰í•˜ë ¤ëŠ” ë…¸ë ¥ì´ ë§ì•˜ì—ˆë‹¤. 

ë‹¤ë§Œ, CNNì€ loss ê°’ì„ ìµœì†Œí™”í•˜ë„ë¡ ìµœì í™”ëœ networkì´ê¸° ë•Œë¬¸ì— loss functionì„ ì˜ ë””ìì¸í•´ì•¼ ì¢‹ì€ performanceë¥¼ ë‚¸ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.
ë˜í•œ, CNNì€ predictedì™€ ground truthì˜ pixelë“¤ê°„ì˜ Euclidean distanceë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í›ˆë ¨ì´ ë˜ëŠ”ë° ì´ ê²½ìš°ì—ëŠ” blurryí•œ ê²°ê³¼ê°€ ìƒê¸´ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.

> â­ **General-purposed image to image translation framework**
> 
> ë”°ë¼ì„œ ì§„ì§œì™€ ê°™ì€ ì´ë¯¸ì§€ë¥¼ ë§Œë“œë ¤ë©´ ëª©ì ì— ë§ê²Œ loss functionì„ ìë™ì ìœ¼ë¡œ ë°°ìš°ëŠ” networkê°€ í•„ìš”í–ˆê³  ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë¥¼ ìœ„í•´ GANì„ ì‚¬ìš©í•˜ì˜€ë‹¤. **conditional GANì€ image-to-image translationì— ì í•©í•˜ë©° íŠ¹ì • applicationì´ ì•„ë‹ˆë¼ ì „ë°˜ì ì¸ image-to-image ë¶„ì•¼ì— ì ìš©í•  ìˆ˜ ìˆë‹¤.**

## 2. Related work

### 2.1 Structured losses for image modeling

ê¸°ì¡´ì—ëŠ” image-to-image taskì— per-pixel classificationì´ë‚˜ regressionë“±ì´ ì‚¬ìš©ë˜ì—ˆë‹¤. ì´ ê²½ìš°ì—ëŠ” output spaceê°€ **unstructed**ë˜ì–´ ìˆì–´ ê° output pixelë“¤ì´ input ì´ë¯¸ì§€ì— ë…ë¦½ì ì¸ ê²ƒì²˜ëŸ¼ ë‹¤ë¤„ì¡Œë‹¤. <span style='background-color: #FFF2CC;'> cGANì—ì„œëŠ” **structed loss**ë¥¼ ì‚¬ìš©í•œë‹¤. </span>

### 2.2 Conditional GANs

- [[Paper Review] CGAN : Conditional Generative Adversarial Nets ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-3/)

ì§€ë‚œ ì—°êµ¬ë“¤ì€ image-to-imageì— GANì„ unconditionalí•˜ê²Œ ì ìš©í•˜ì˜€ë‹¤ë©´, pix2pixì—ì„œëŠ” Conditional GANì„ ì‚¬ìš©í•œë‹¤.

## 3. Method

> â­ Pix2pixì—ì„œëŠ” Generatorë¡œëŠ” **U-Net** êµ¬ì¡°ë¥¼, Discriminatorë¡œëŠ” **PatchGAN**ì„ ì‚¬ìš©í•œë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix2.PNG?raw=1' width = '500' ></p>

cGANì˜ Generatorì—ì„œëŠ” ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ real image $x$ì™€ random noise vector $z$ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. 
$$G:\{x, z\} \rightarrow y$$

### 3.1 Objective

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix3.PNG?raw=1' width = '700' ></p>

#### **cGAN Loss**
object functionìœ¼ë¡œëŠ” <span style='background-color: #E5EBF7;'> conditional GANì„ ì‚¬ìš©í•˜ì—¬ input imageì™€ output imageê°€ ì˜ matchingë˜ëŠ”ì§€ë„ í•™ìŠµ </span>í•˜ë„ë¡ í•˜ì˜€ë‹¤. (unconditionalë„ ì‹¤í—˜ì„ í•´ë´¤ì§€ë§Œ, cGANì˜ ì„±ëŠ¥ì´ ë” ì¢‹ì•˜ìŒ)

$$\begin{aligned}
\mathcal{L}_{c G A N}(G, D)=& \mathbb{E}_{x, y}[\log D(x, y)]+\mathbb{E}_{x, z}[\log (1-D(x, G(x, z))]
\end{aligned}$$

---

#### **L1 Loss** 
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix5.PNG?raw=1' width = '700' ></p>

ë˜í•œ, pix2pixëŠ” ì¶”ê°€ì ì¸ loss termì„ ì¶”ê°€í•œë‹¤. cGAN lossë¥¼ ì‚¬ìš©í•˜ë©´ Gê°€ Dë¥¼ ì˜ ì†ì´ë„ë¡ í•™ìŠµì´ ë˜ì§€ë§Œ, GëŠ” Dë¥¼ ì†ì´ëŠ” ê²ƒë§Œì´ ëª©ì ì´ê¸° ë•Œë¬¸ì— ground truth outputê³¼ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ë„ ìˆë‹¤. 

ë”°ë¼ì„œ <span style='background-color: #E5EBF7;'> ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ëŒ€ì‘ë˜ëŠ” ì§„ì§œ ì´ë¯¸ì§€ì™€ì˜ ê±°ë¦¬ë¥¼ lossì— ì¶”ê°€í•˜ì—¬ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì§„ì§œ ì´ë¯¸ì§€ì™€ ë¹„ìŠ·í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµí•˜ì˜€ë‹¤. </span> (ì´ë•Œ, ë…¼ë¬¸ì—ì„œëŠ” L2ë³´ë‹¤ L1ì„ ì‚¬ìš©í–ˆì„ ë•Œ blurring í˜„ìƒì´ ë” ì¤„ì—ˆë‹¤ê³  í•œë‹¤.)

$$\mathcal{L}_{L 1}(G)=\mathbb{E}_{x, y, z}\left[\|y-G(x, z)\|_{1}\right]$$

---

#### **Final Loss Function**

$$G^{*}=\arg \min _{G} \max _{D} \mathcal{L}_{c G A N}(G, D)+\lambda \mathcal{L}_{L 1}(G)$$

- pix2pixì˜ ë¬¸ì œ
  `z`ê°€ ì—†ë‹¤ë©´ `x`ì—ì„œ deterministicí•œ output `y`ì´ ìƒì„±ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ noise zë¥¼ ê¼­ ì¶”ê°€í•´ì•¼í•œë‹¤. 
  
  - ì‹¤í—˜ ê²°ê³¼
    - `G`ê°€ noize `z`ë¥¼ ë¬´ì‹œí•˜ê³  í•™ìŠµì„ í•œë‹¤.(noiseë¥¼ ë¬´ì‹œí•˜ê³  í•™ìŠµí•˜ëŠ” ê²Œ í›¨ì”¬ ì•ˆì •ì ) 
    - noiseë¥¼ ì‚¬ìš©í•˜ë„ë¡ dropoutì˜ ë°©ì‹ë„ ì‚¬ìš©í•´ë´¤ì§€ë§Œ, ì—¬ì „íˆ stochasticí•œ ë³€í™”ëŠ” ë¯¸ë¯¸í–ˆë‹¤.
  
  - ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” noise `z`ë¥¼ ë¹¼ê³  ì‹¤í—˜í•˜ì˜€ë‹¤.(ìˆìœ¼ë‚˜ ë§ˆë‚˜ì—¬ì„œ)
  - Generatorê°€ í•™ìŠµì‹œì— noiseë¥¼ ë¬´ì‹œí•˜ì—¬ ìƒê¸°ëŠ” ë¬¸ì œëŠ” í–¥í›„ bicycleGANì—ì„œ ê°œì„ ëœë‹¤.

---

### 3.2 Network architectures

**Convolution-BatchNorm-ReLU**

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” [DCGAN](https://happy-jihye.github.io/gan/gan-2/)ì˜ Gì™€ Dë¥¼ baselineìœ¼ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤. 

#### 3.2.1 Generator with skips(U-Net)


image-to-image translationì—ì„œëŠ” high resolution **input** gridë¥¼ high resolution **output** gridë¡œ mappingí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. inputê³¼ outputì˜ êµ¬ì²´ì ì¸ íŠ¹ì§•ì€ ë‹¤ë¥´ì§€ë§Œ, ì „ë°˜ì ì¸ structureëŠ” ë™ì¼í•  ê²ƒì´ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix4.PNG?raw=1' width = '500' ></p>

> Generatorì˜ ê¸°ë³¸ì ì¸ architectureëŠ” Encoder-Decoderì— skip connectionì„ ì¶”ê°€í•œ **U-Net**ì„ ë”°ë¥¸ë‹¤.

- **Encoder-Decoder** : bottleneckê¹Œì§€ inputì„ downsamplingì„ í•œ í›„, decoderì—ì„œëŠ” ë‹¤ì‹œ upsamplingì„ í•œë‹¤.  
- Encoderì˜ ì •ë³´ê°€ Decoderê¹Œì§€ ì „ë‹¬ì´ ì•ˆë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ **skip-connectoin**ê¸°ë²•ì„ ì¶”ê°€í•œë‹¤. 

#### 3.2.2 Markovian discriminator (PatchGAN)

<span style='background-color: #E5EBF7;'> L1 lossëŠ” low-frequencyì—ì„œ ì§„ì§œ ì´ë¯¸ì§€ì™€ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ ë•ì§€ë§Œ, high-frequencyì— ëŒ€í•´ì„œëŠ” ì§„ì§œì™€ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ í•´ì£¼ì§€ëŠ” ëª»í•œë‹¤. ë”°ë¼ì„œ high-frequency structureë¥¼ modelingí•˜ê¸° ìœ„í•´ discriminatorë¥¼ ì‚¬ìš©í•œë‹¤. </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix6.PNG?raw=1' width = '500' ></p>

discriminatorì˜ architectureë¡œëŠ” PatchGANì„ ì‚¬ìš©í•œë‹¤. 
- PatchGANì€ [Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks](https://arxiv.org/abs/1604.04382) (2016)ë…¼ë¬¸ì—ì„œ ì²˜ìŒìœ¼ë¡œ ì œì‹œëœ ëª¨ë¸ì´ë‹¤. 
- ì‚¬ì§„ì€ [Patch-Based Image Inpainting with Generative Adversarial Networks](https://arxiv.org/abs/1803.07422) (2018) ë…¼ë¬¸ì˜ **PatchGAN discriminator**

DëŠ” ì´ë¯¸ì§€ì˜ `N x N`ì˜ patch(high frequency ì˜ì—­)ê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ë¥¼ íŒë³„í•œë‹¤. ì´ ë°©ì‹ì€ discriminatorë¥¼ ì¢€ë” ì•½í•˜ê²Œ ë§Œë“¤ì–´ì¤€ë‹¤ê³ ë„ ë³¼ ìˆ˜ ìˆë‹¤. (Dë¥¼ ì•½í•˜ê²Œ í•¨ìœ¼ë¡œì¨ í•™ìŠµì„ ì•ˆì •í™”)

### 3.3 Optimization and inference

- minibatch SGDì™€ Adam optimizerë¥¼ ì‚¬ìš©
- At inference time, we run the generator net in exactly the same manner as during the training phase. This differs from the usual protocol in that we apply dropout at test time, and we apply batch normalization using the statistics of the test batch, rather than aggregated statistics of the training batch. This approach to batch normalization, when the batch size is set to 1, has been termed â€œinstance normalizationâ€ and has been demonstrated to be effective at image generation tasks. In our experiments, we use batch sizes between 1 and 10 depending on the experiment.
- ìì„¸í•œ ë‚´ìš©ì€ ë…¼ë¬¸ ì°¸ê³ 
  
## 4. Experiments

### 4.1 Analysis of the objection function

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix7.PNG?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix8.PNG?raw=1' width = '500' ></p>

L1ë§Œì„ ì‚¬ìš©í•˜ë©´ ì§„ì§œê°™ì§€ë§Œ blurry í˜„ìƒì´ ì‹¬í•˜ê³ , cGANë§Œì„ ì‚¬ìš©í•˜ë©´ ì´ë¯¸ì§€ê°€ ì„ ëª…í•´ì§€ì§€ë§Œ í˜„ì‹¤ì„±ì´ ë–¨ì–´ì§„ë‹¤. ì´ ë‘˜ì„ ê°™ì´ ì‚¬ìš©í•œ ì´ë¯¸ì§€ì˜ ì™„ì„±ë„ê°€ ê°€ì¥ ë†’ì•˜ë‹¤.

### 4.2 Analysis of the Generator architecture

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix9.PNG?raw=1' width = '600' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix10.PNG?raw=1' width = '500' ></p>

U-netì„ ì‚¬ìš©í–ˆì„ ë•Œê°€ Encoder-Decoderë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ë³´ë‹¤ ì´ë¯¸ì§€ê°€ ì˜ ìƒì„±ëœë‹¤. (FCN-scoreê°€ ë” ë†’ìŒ)
- skip connectionì„ í†µí•´ Encoderì˜ high-resolutionì„ decoderì— ì˜ ì „ë‹¬

### 4.3 Analysis of the Discriminator architecture
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix11.PNG?raw=1' width = '800' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix12.PNG?raw=1' width = '500' ></p>

`70 x 70` PatchGANì„ ì‚¬ìš©í–ˆì„ ë•Œ ê°€ì¥ ì¢‹ì€ FCN-scoreë¥¼ ì–»ì—ˆë‹¤.

## 5. Conclusion

> **Pix2Pix** ëŠ” image-to-image translationì— convolutional GANì˜ networkë¥¼ ì ìš©í•˜ì—¬ ì¢‹ì€ ì„±ê³¼ë¥¼ ë‚¸ ëª¨ë¸ë¡œ, ë§ì€ image-to-imageì˜ baselineì´ ë˜ê³ ìˆë‹¤.

---
## 6. Images

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix13.PNG?raw=1' width = '600' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix14.PNG?raw=1' width = '600' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/pix2pix15.PNG?raw=1' width = '600' ></p>

---

**Reference**
- Naver AI LAB ìµœìœ¤ì œ ì—°êµ¬ì›ë‹˜ ë°œí‘œìë£Œ