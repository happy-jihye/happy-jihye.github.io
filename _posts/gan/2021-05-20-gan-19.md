---
title: "[Paper Review] StyleGAN2-ADA #01: Training Generative Adversarial Networks with Limited Data ë…¼ë¬¸ ë¶„ì„"
excerpt: " "


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

<p align='right'> 
 <a href='https://github.com/NVlabs/stylegan2-ada-pytorch' role='button' target='_blank'> <img class='notebook-badge-image' src='/assets/badges/github.svg' alt='View On GitHub'> </a> 
</p>


> âœğŸ» ìµœê·¼ì—ëŠ” ì´ë¯¸ ìˆëŠ” ëª¨ë¸(`pretrained model`)ì„ ì˜ `fine tuning`í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ê²°ê³¼ë¥¼ ë‚´ëŠ” ì—°êµ¬ê°€ ëŒ€ì„¸ì´ë‹¤. (FreezeD, GANSpace, StyleCLIP ë“±ë“±) 
> 
> **StyleGAN2-ADA**ë„ ì´ëŸ¬í•œ íë¦„ì—ì„œ ë‚˜ì˜¨ ì—°êµ¬ë¡œ, loss functionì´ë‚˜ networkì˜ architectureë¥¼ ê±´ë“¤ì´ì§€ ì•Šê³  ì´ë¯¸ í•™ìŠµì´ ëœ GANì„ `finetuning`í•˜ë©° í•™ìŠµì„ í•œë‹¤. ë˜í•œ, ì ì€ ë°ì´í„°ë¡œ í•™ìŠµì„ í•´ë„ discriminatorê°€ overfitting ë˜ì§€ ì•Šë„ë¡  `Adaptive Discriminator Augmentation Mechanism`ì„ ì œì•ˆí•˜ì˜€ë‹¤.


- Paper : [Training Generative Adversarial Networks with Limited Data](https://arxiv.org/abs/2006.06676) (NeurlPS 2020 /Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila)

- StyleGAN2-ADAëŠ” NvidiaíŒ€ì˜ StyleGAN, StyleGAN v2 í›„ì† ë…¼ë¬¸ì´ë‹¤. StyleGAN ê´€ë ¨ ë¦¬ë·°ëŠ” ë‹¤ìŒ ê¸€ì„ ì°¸ê³  : 
    [`StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks`](https://happy-jihye.github.io/gan/gan-6/)
    [`StyleGAN2: Analyzing and Improving the Image Quality of StyleGAN`](https://happy-jihye.github.io/gan/gan-7/)
    [`StyleGAN2-ADA #01: Training Generative Adversarial Networks with Limited Data`](https://happy-jihye.github.io/gan/gan-19/) [`StyleGAN2-ADA #02: Training Generative Adversarial Networks with Limited Data`](https://happy-jihye.github.io/gan/gan-20/)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

## 1. Introduction


<span style='background-color: #E5EBF7;'> **Prevent the augmentations from leaking** </span>

GANì€ small datasetìœ¼ë¡œ í•™ìŠµì„ í•˜ë©´ Discriminatorê°€ overfitting ëœë‹¤ëŠ” ë¬¸ì œì ì´ ìˆë‹¤.

- GANì€ Discriminatorì™€ Generatorê°€ ê²½ìŸí•˜ë©° í•™ìŠµí•˜ëŠ” ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— `D`ê°€ overfitëœë‹¤ë©´ `G`ë„ ì´ìƒí•˜ê²Œ í•™ìŠµëœë‹¤.(ë°œì‚°) 
- <font color='#2C4D88'> Overfitting ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì—°êµ¬ë¡œ <B>Dataset Augumentation</B>ê³¼ ê°™ì€ ì—°êµ¬ë„ ìˆë‹¤. (rotation, noise ë“±ì„ ì¶”ê°€í•˜ì—¬ classifierê°€ ë” ì˜ í•™ìŠµë˜ë„ë¡ í•¨) ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ í•˜ë©´, augmented distribution(leaking)ê°€ ìƒê²¨ í•™ìŠµì´ ì´ìƒí•˜ê²Œ ëœë‹¤ - ex. a noise augmentation leads to noisy results, even if there is none in the dataset </font>

StyleGAN2-ADAëŠ” augmentation rangeë¥¼ ì¡°ì ˆí•˜ì—¬ `D`ê°€ overfittingë˜ëŠ” ê²ƒì„ ë§‰ì•˜ë‹¤.

---

## 2. Overfitting in GANs

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-1.PNG?raw=1' width = '700' ></p>

ì ì€ dataë¡œ í•™ìŠµí• ìˆ˜ë¡ FID scoreë„ ë†’ê³  `D`ë„ overfittingëœë‹¤.

### 2.1 Stochastic Discriminator Augmentation

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-2.PNG?raw=1' width = '700' ></p>

[bCR-GAN](https://happy-jihye.github.io/gan/gan-18/#1-bcr-gan)ì€ `Discriminator`ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ realì™€ generated image ëª¨ë‘ì— ëŒ€í•´ consistency regularization termì„ ì¶”ê°€í•˜ì˜€ì§€ë§Œ, `Generator`ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œì—ëŠ” augmentationì„ í•˜ì§€ ì•Šì•˜ë‹¤. ì´ì™€ ê°™ì´ í•™ìŠµì„ í•œë‹¤ë©´, `G`ê°€ ì•„ë¬´ëŸ° penaltyì—†ì´ ììœ ë¡­ê²Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— augmentationì´ leaking ë  ìˆ˜ ìˆë‹¤.

- [[Paper Review] CR-GAN: Consistency Regularization for Generative Adversarial Networks ê°„ë‹¨í•œ ë…¼ë¬¸ ë¦¬ë·°](https://happy-jihye.github.io/gan/gan-17/)
- [[Paper Review] ICR-GAN: Improved Consistency Regularization for GANs ê°„ë‹¨í•œ ë…¼ë¬¸ ë¦¬ë·°](https://happy-jihye.github.io/gan/gan-18/)

<span style='background-color: #E5EBF7;'> ***stochastic discriminator augmentation*** </span>

ë”°ë¼ì„œ **StyleGAN-ADAì—ì„œëŠ” ì˜¤ì§ augmented imageë§Œì„ ì‚¬ìš©í•˜ì—¬ `Discriminator`ë¥¼ í•™ìŠµí•˜ë©°, `Generator` ì—­ì‹œ augmentí•œ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµ**ì„ í•œë‹¤. ë˜í•œ, **augmentation probability $p$**ë¥¼ í†µí•´ augmentationì˜ ì •ë„ë¥¼ ì¡°ì ˆí•œë‹¤.
- $p$ê°€ 0ì´ë©´, augmentation X
- $p$ê°€ 1ì— ê°€ê¹Œìš°ë©´, augmentationì„ ë§ì´

---

### 2.2 (Non-leaking) Invertible Augmentation

#### Ambient-GAN
- Paper : [AmbientGAN: Generative models from lossy measurements](https://openreview.net/forum?id=Hy7fDog0b) (ICLR 2018)
    
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-3.PNG?raw=1' width = '700' ></p>

AmbientGANì€ ë¬¸ì œê°€ ìˆëŠ” dataset(*corruption*)ì— ëŒ€í•´ í•™ìŠµì„ í•  ë•Œë„ ì˜¬ë°”ë¥¸ distributionì„ ì°¾ì„ ìˆ˜ ìˆìŒì„ ë°íŒ ëª¨ë¸ì´ë‹¤. 

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-4.PNG?raw=1' width = '700' ></p>

- **Generator**ê°€ ê¹¨ë—í•œ ì´ë¯¸ì§€ $X_g$ë¥¼ ë§Œë“¤ë©´ $f_Î¸$ê°€ ì´ë¥¼ corruptí•˜ëŠ” noise functionì„ í•™ìŠµí•´ì„œ $Y_g$ë¥¼ ìƒì„±í•˜ê³ , **Discriminator**ê°€ corruptëœ real data $Y_r$ì™€ $Y_g$ë¥¼ ë¹„êµí•˜ê²Œ í•˜ëŠ” êµ¬ì¡°

    $$\min _{G} \max _{D} \mathbb{E}_{Y^{r} \sim p_{y}^{r}}\left[q\left(D\left(Y^{r}\right)\right)\right]+\mathbb{E}_{Z \sim p_{z}, \Theta \sim p_{\theta}}\left[q\left(1-D\left(f_{\Theta}(G(Z))\right)\right)\right]$$

    - [[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements](http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html)

- ë‹¨, ì´ë•Œ corruption processëŠ” data spaceì˜ í™•ë¥  ë¶„í¬ì— ëŒ€í•´ **invertible transformation**ì´ ê°€ëŠ¥í•´ì•¼í•œë‹¤.
    <p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-5.jpg?raw=1' width = '300' ></p>

    - invertible transformationì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì€ ë‹¤ìŒ ê·¸ë¦¼ì²˜ëŸ¼ $T(x)$ì—ì„œ $x$ë¡œ mappingí•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.
    - ë§Œì•½ì— ìš°ë¦¬ê°€ augmentationì„ uniformí•˜ê²Œ í–ˆë‹¤ë©´ invertible transformationì´ ì–´ë ¤ìš¸ ê²ƒì´ë‹¤. : <font color='#2C4D88'>Augmentation í›„ì— {0, 90, 180, 270} ëª¨ë‘ 25%ì”© ìˆë‹¤ë©´ ëª‡ë„ì—ì„œ augmentationì„ ì‹œì‘í–ˆëŠ”ì§€ ëª¨ë¦„</font>
    - ë°˜ë©´, $p$ë¥¼ ì‘ê²Œí•˜ì—¬ ì•ˆì „í•˜ê²Œ augmentationì„ í–ˆë‹¤ë©´ invertible transformì´ ê°€ëŠ¥í•  ê²ƒì´ë‹¤. : <font color='#2C4D88'>90ë„ rotation Augmentation í›„ì— {0, 90, 180, 270}ê°€ ê°ê° 20%, 50%, 15%, 15% ìˆë‹¤ë©´, original distributionì€ {0, 90, 180, 270} - 50%, 15%, 15%, 20% ì¼ ê²ƒ</font>

---
#### StyleGAN-ada

ADAì—ì„œë„ Ambient-GANê³¼ ë§ˆì°¬ê°€ì§€ë¡œ $p$ë¥¼ ë†’ê²Œ ì„¤ì •í•˜ë©´ ì–´ë–¤ ì´ë¯¸ì§€ì—ì„œ augmentë¥¼ í–ˆëŠ”ì§€ ì•Œ ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ 0.85 ì´í•˜ì˜ í™•ë¥ ë¡œ augmentationì„ í•˜ë„ë¡ designí•˜ì˜€ë‹¤.

<span style='background-color: #E5EBF7;'> **Designing non-leaking augmentations** </span>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-5.PNG?raw=1' width = '700' ></p>

- (a) **Isotropic image scaling** : $p$ì— ê´€ê³„ ì—†ì´ non-leaking safe augmentation
- (b) **Random 90 rotation** : $p$ê°€ ë†’ìœ¼ë©´ ë¶ˆì•ˆì •, 0.8ì´í•˜ì˜ $p$ë¥¼ ì‚¬ìš©í•˜ë©´ non-leaking

> ì¦‰, augmentationì„ ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ ì ìš©í•˜ì§€ ì•Šê³  stochasticí•˜ê²Œ ì ìš©í•œë‹¤ë©´ leakingì´ ë˜ì§€ ì•Šê³  ì˜ í•™ìŠµëœë‹¤.

### 2.3 Our augmentation pipeline

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-6.PNG?raw=1' width = '800' ></p>

- ë³¸ ë…¼ë¬¸ì€ 18ê°œì˜ Transformation pipelineì„ ì‚¬ìš©í•˜ì˜€ë‹¤. (ìì„¸í•œ ë‚´ìš©ì€ Appendix B ì°¸ê³ )

> Effectiveness of **stochastic discriminator augmentation** by performing exhaustive sweeps over p for different augmentation categories and dataset sizes

---

<span style='background-color: #E5EBF7;'> **Impact of stochasticity for augmentations** </span>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-7.PNG?raw=1' width = '800' ></p>

datasetì˜ í¬ê¸°ë‚˜ augmentation categoriesì— ë”°ë¼ ìµœì ì˜ $p$ê°€ ë‹¤ë¥´ë‹¤. ë”°ë¼ì„œ ADAì—ì„œëŠ” Discriminatorì˜ outputì— ë”°ë¼ $p$ë¥¼ Adaptiveí•˜ê²Œ ë°”ê¿”ì£¼ì—ˆë‹¤.

## 3. Adaptive Discriminator Augmentation

ë§¤ë²ˆ augmentation probability $p$ ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒì€ ì–´ë µë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” overfittingì˜ ì •ë„ì— ì˜ê±°í•˜ì—¬ ë™ì ìœ¼ë¡œ $p$ë¥¼ ì¡°ì ˆí•œë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-1.PNG?raw=1' width = '700' ></p>

- Overfittingì´ ë˜ë©´ <font color='#37814E'>validation set(green)</font>ì€ <font color='#D96321'>generated images(orange)</font>ì²˜ëŸ¼ í–‰ë™í•œë‹¤.

<span style='background-color: #E5EBF7;'> **Overfitting Heuristics** </span>

$$r_{v}=\frac{\mathbb{E}\left[D_{\text {train }}\right]-\mathbb{E}\left[D_{\text {validation }}\right]}{\mathbb{E}\left[D_{\text {train }}\right]-\mathbb{E}\left[D_{\text {generated }}\right]} \quad r_{t}=\mathbb{E}\left[\operatorname{sign}\left(D_{\text {train }}\right)\right]$$

- heuristicì´ 1ì´ë©´ complete overfitting / 0ì´ë©´ overfitting X
- $r_{v}$ : validation setì˜ ê²°ê³¼ê°€ training setì™€ ë¹„ìŠ·í•œì§€, generated imageì™€ ë¹„ìŠ·í•œì§€ë¥¼ ê²€ì‚¬
- $r_{t}$ : training dataì—ì„œ `D`ê°€ realì´ë¼ê³  í›ˆë ¨í•˜ëŠ” ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ìˆëŠ”ì§€ë¥¼ ê²€ì‚¬
- $r_v$ì˜ ì„±ëŠ¥ì´ ì¢‹ì„ ê²ƒ ê°™ì§€ë§Œ ì‹¤ì œë¡œ $r_t$ì˜ ì„±ëŠ¥ì´ ë” ì¢‹ìŒ

> ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì²˜ìŒì— $p$($=r_t or r_h$)ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•œ í›„ì— 4ë²ˆì˜ minibatchë§ˆë‹¤ ì´ ê°’ì„ ì¡°ì ˆí•œë‹¤. ë”°ë¼ì„œ ***Adaptive Discriminator Augumentation (ADA)*** ë¼ê³  ë¶ˆë¦°ë‹¤. 
> 
> Control the Augmentation Strength $p$
> - If the heuristic (e.g. $r_v$ > 0.6 ) indicates too much overfitting, the augmentation probability $p$ is increased by a fixed amount.
> - If the heuristic (e.g. $r_v$ < 0.6 ) indicates too underfitting, the augmentation probability $p$ is decreased by a fixed amount
> - ë…¼ë¬¸ì—ì„œëŠ” ë¹„êµí•˜ê¸° ìœ„í•œ $p$ë¡œ 0.6ì˜ ê³ ì •ëœ ê°’ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. (hyper-parameter)

<span style='background-color: #E5EBF7;'> **Impact of target value in heuristics ** </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-8.PNG?raw=1' width = '700' ></p>

- **(a)** : 2kì˜ dataì—ì„œëŠ” optimal $r_v = 0.7$, 10kì—ì„œëŠ” optimal $r_v = 0.4 pr 0.5$, 50kì—ì„œì˜ optimal $r_v = 0.3$
    - dataì˜ ìˆ˜ì— ë”°ë¼ optimalí•œ augmentation probabilityê°€ ë‹¤ë¥´ë‹¤. (trainingì˜ ê°œìˆ˜ê°€ í´ìˆ˜ë¡ overfittingì´ ëœë˜ë‹¤ë³´ë‹ˆ augmentationì„ ì ê²Œ í•´ë„ ê´œì°®ë‹¤.)
- **(b)** : $r_t$ë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„°ì˜ í¬ê¸°ì™€ ìƒê´€ì—†ì´ 0.6ì´ best heuristic!
    - $r_t$ê°€ $r_v$ë³´ë‹¤ ì•ˆì „í•˜ê²Œ ì‹¤í—˜ì´ ë˜ë¯€ë¡œ ë³¸ ì‹¤í—˜ì—ì„œëŠ” $r_t$ë¥¼ heuristicìœ¼ë¡œ ì‚¬ìš©í•˜ì˜€ê³  overfitting/underfittingì„ í™•ì¸í•˜ëŠ” target valueë¡œëŠ” 0.6ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.
- **(c)** : heuristic $r_t$ë¥¼ ì‚¬ìš©í•˜ì—¬ trainingì„ í•˜ë©´ $p$ëŠ” ì ì  ì¦ê°€í•œë‹¤. ì´ë•Œ datasetì´ ì ì„ìˆ˜ë¡ augmentationì„ ë§ì´ í•˜ëŠ”ê²Œ íš¨ê³¼ê°€ ì¢‹ìœ¼ë¯€ë¡œ $p$ê°€ ë¹ ë¥´ê²Œ ì¦ê°€í•œë‹¤.
- **(d)** : ADAë¥¼ ì“°ì§€ ì•Šê³  ê³ ì •ëœ $p$ê°’ì„ ë°”íƒ•ìœ¼ë¡œ í›ˆë ¨ì„ í•˜ë©´ ì‹œê°„ì´ íë¦„ì— ë”°ë¼ heuristicì´ ë°œì‚°í•œë‹¤.(ì ì„ ) ë°˜ë©´, ADAë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì„ í•˜ë©´(heuristicì´ 0.6ë³´ë‹¤ í¬ë©´ augmentationì´ ì ê²Œ í•˜ê³ , heuristicì´ 0.6ë³´ë‹¤ ì‘ìœ¼ë©´ augë¥¼ ë§ì´ í•˜ëŠ” ì‹ìœ¼ë¡œ) heuristicì´ (b)ì˜ ê³ ì •ëœ $p=0.6$ë¡œ ìˆ˜ë ´í•˜ê²Œ ëœë‹¤.

<span style='background-color: #E5EBF7;'> **Effect of adaptive discriminator augmentation** </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-9.PNG?raw=1' width = '700' ></p>

Figure1ëŠ” ADAë¥¼ ì ìš©í•˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ê²°ê³¼ê°’ì´ê³ , Figure6ì€ ADAë¥¼ ì ìš©í–ˆì„ ë•Œì˜ FID scoreì´ë‹¤.

Augmentationì„ í•˜ë©´ `D`ê°€ overfittingì´ ì•ˆë˜ë„ë¡ í•™ìŠµì„ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— `G`ê°€ ë” ë‹¤ì±„ë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ë˜í•œ, ADAë¥¼ ì‚¬ìš©í•˜ë©´ loss functionì„ ë” ê°•ë ¥í•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ gradient fieldë¥¼ ì¢€ë” detailí•˜ê²Œ ìœ ì§€í•  ìˆ˜ ìˆë‹¤. 

## 4. Evaluation

### 4.1 Training from scratch

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-10.PNG?raw=1' width = '700' ></p>

- (a), (b) : ì ì€ datasetì„ ì‚¬ìš©í•˜ë”ë¼ë„ ADAë¥¼ ì‚¬ìš©í•˜ë©´ FID ìˆ˜ì¹˜ê°€ í–¥ìƒëœë‹¤ !
- (d) : ê·¸ë¦¼ (d)ì—ì„œëŠ” [bCR-GAN](https://happy-jihye.github.io/gan/gan-18/#1-bcr-gan)ì„ ì‚¬ìš©í–ˆì„ ë•Œ ìƒì„±ëœ ì´ë¯¸ì§€(blurring)ì˜ ë¶„í¬ê°€ leakingì´ ë¨ì„ ë³´ì—¬ì¤€ë‹¤. ADAëŠ” ìƒì„±ì´ë¯¸ì§€ê°€ real imageì™€ ë¹„ìŠ·í•œ ê²ƒì„ ë³´ì•„ leakingì´ ì•ˆëœë‹¤.
- (c) : ADAì™€ bCR-GANì„ ê°™ì´ ì‚¬ìš©í•˜ë©´ ì¢‹ë‹¤.

ë‹¤ë¥¸ augmentation methods(PA-GAN, WGAN-GP, zCR ë“±ë“±)ê³¼ ADAë¥¼ ë¹„êµí•´ë´ë„ ADAê°€ ì¢‹ë‹¤ê³  í•¨

### 4.2 Transfer Learning
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-11.PNG?raw=1' width = '700' ></p>

- [Freeze-D](https://arxiv.org/abs/2002.10964)ì™€ ADAë¥¼ ê°™ì´ ì“°ë©´ Transfer-Learningì´ ì˜ë¨

### 4.3 Small Datawets
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-12.PNG?raw=1' width = '700' ></p>

- ADAëŠ” small datasetì—ë„ íš¨ê³¼ì 


