---
title: "[Paper Review] CR-GAN: Consistency Regularization for Generative Adversarial Networks 간단한 논문 리뷰"
excerpt: " "


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# 목차
toc: true  
toc_sticky: true 

use_math: true
---

- Paper : [CR-GAN: Consistency Regularization for Generative Adversarial Networks](https://arxiv.org/abs/1910.12027) (ICLR 2020 / Han Zhang, Zizhao Zhang, Augustus Odena, Honglak Lee)

- [GAN-Zoos! (GAN 포스팅 모음집)](https://happy-jihye.github.io/gan/)

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/crgan-5.PNG?raw=1' width = '400' ></p>
<font color='gray'><i><p align='center' style='font-size:9px'> 네이버 AI랩 최윤제님 발표자료 </p></i></font>

GAN은 학습이 불안정
- Because GAN training implicitly requires finding the Nash equilibrium of a non-convex game in a continuous and high dimensional parameter space, it is substantially more complicated than standard neural network training


> ⭐ <font color='#2C4D88'>CR-GAN : <b>Consistency Regularization</b>을 GAN의 Discriminator에 적용</font>
> 
> - Gradient-based regularizatoin보다 simple, effective + computational cost가 적음 + 학습이 안정적!
> - Conditional GAN, Unconditional GAN 둘다 Consistency Regularization 기법을 적용했을 때 결과가 좋음 : SOTA !


---

## Consistency Regularization

[**Consistency Regularization**](https://seewoo5.tistory.com/8)
- <font color='gray'><i>Consistency Regularization이란, 간단히 말해서 모델의 Input에 augmentation을 가해서 새로운 input을 만들었을 때, output (prediction)이 별로 변하지 않아야 한다는 가정을 바탕으로 모델을 regularize하는 방법 입니다. 예를 들어서, 이미지를 분류하는 CNN이 하나 있을 때, 기존에 있던 강아지 사진을 뒤집거나 돌리는 등의 작업을 해서 새로운 강아지 이미지를 만들었을 때, 모델의 강아지에 대한 예측값 (마지막 layer의 확률값)이 크게 변하지 않게 해주는 것 입니다.(출처 : Anti Math Math Club)</i></font> 
- semi-supervised learning에서 사용됨

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/crgan-1.PNG?raw=1' width = '800' ></p>

---

<span style='background-color: #E5EBF7;'> **Consistency Regularization Loss** (line 6) </span>

$$L_{c r}=\|D(x)-D(T(x))\|^{2}$$

- $T(x)$ : stochastic data augmentation funtion
- Discriminator가 Augumentation한 이미지와 실제 이미지에 대해 동일하게 판별을 하도록 학습
- fake image를 augmentation한 것에 대해서는 학습하지 않음

---

<span style='background-color: #E5EBF7;'> **CR-GAN objective function**(line 9, 12) </span>

$$L_{D}^{c r}=L_{D}+\lambda L_{c r}, \quad L_{G}^{c r}=L_{G}$$

$L_{G}, L_{D}$는 GAN Loss : 아래의 loss들 중 아무거나 
- original GAN
  
  $$L_{D}=-\mathbb{E}_{x \sim p_{\text {data }}}[\log D(x)]-\mathbb{E}_{z \sim p(z)}[1-\log D(G(z))], \\
  L_{G}=-\mathbb{E}_{z \sim p(z)}[\log D(G(z))$$  

- NSGAN(non-saturating GAN)
  
  $$L_{D}=-\mathbb{E}_{x \sim p_{\text {data }}}[\min (0,-1+D(x))]-\mathbb{E}_{z \sim p(z)}[\min (0,-1-D(G(z)))] \\
  L_{G}=-\mathbb{E}_{z \sim p(z)}[D(G(z))]$$

- WGAN(Wassertein GAN)
  
  $$L_{D}=-\mathbb{E}_{x \sim p_{\text {data }}}[D(x)]+\mathbb{E}_{z \sim p(z)}[D(G(z))] \\
  L_{G}=-\mathbb{E}_{z \sim p(z)}[D(G(z))]$$

---

## Experiment Results
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/crgan-2.PNG?raw=1' width = '800' ></p>

CR을 적용하면 FID score가 감소한다 -> GOOD !

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/crgan-3.PNG?raw=1' width = '800' ></p>

Augumentation으로는 `Random shift + Flipping`를 하는 게 성능이 좋다.

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/crgan-4.PNG?raw=1' width = '800' ></p>

미세하지만 baseline보다 quality가 좋음