---
title: "[Paper Review] CGAN : Conditional Generative Adversarial Nets ë…¼ë¬¸ ë¶„ì„"
excerpt: "CGAN(Conditional Generative Adeversarial Networks)ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."

date: 2021-04-04
categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---


> ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” **CGAN(Conditional Generative Adeversarial Networks)**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.

- Paper : [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)
          (2014 / Mehdi Mirza, Simon Osindero)
          
- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)
          

ì´ ë…¼ë¬¸ì€ GANì´ ë‚˜ì˜¤ê³  ë‚˜ì„œ ì–¼ë§ˆì§€ë‚˜ì§€ ì•Šì•„ ë°œí‘œëœ ë…¼ë¬¸ì´ë‹¤. ì‰½ê²Œ ì“°ì—¬ì ¸ìˆê³ , ê¸¸ì´ë„ ì§§ì•„ì„œ ê°€ë³ê²Œ ì½ê¸° ì¢‹ì€ ë…¼ë¬¸ì´ë‹¤.


## 1. Introduction

ê¸°ì¡´ì˜ GANì€ Adversaria netsì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— Markov cahinì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ëê³ , ì˜¤ì§ gradientë¥¼ ì–»ê¸°ìœ„í•œ backpropagtionë§Œì´ í•„ìš”í–ˆë‹¤. ë˜í•œ ì¶”ë¡ ë„ í•„ìš”ì—†ì—ˆê¸° ë•Œë¬¸ì— í•™ìŠµì´ ì‰¬ì› ê³  SoTAë¥¼ ë‹¬ì„±í–ˆë‹¤.

> ì´ ë…¼ë¬¸ì€ ê¸°ì¡´ì˜ GANì— conditional information(ex.class labels, images, text descriptions)ë¥¼ ì¶”ê°€í•˜ì˜€ë‹¤. 


## 2. Conditional Adversarial Nets

CGANì˜ ëª¨ë¸ì€ ë§¤ìš° ê°„ë‹¨í•˜ë‹¤. ê¸°ì¡´ì˜ GANì´ ë‹¤ìŒì˜ ìˆ˜ì‹ì„ ë§Œì¡±í•˜ëŠ” Mini-Max Gameì´ì—ˆë‹¤ë©´,


$$\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{z}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]$$



CGANì€ **extra infomation**ì¸ $y$ê°€ ì¶”ê°€ëœ ì•„ë˜ì˜ ì‹ì´ë‹¤.


$$\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x} \mid \boldsymbol{y})]+\mathbb{E}_{\boldsymbol{z} \sim p_{z}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z} \mid \boldsymbol{y})))$$

ì‚¬ì‹¤ ì—„ì²­ë‚˜ê²Œ íŠ¹ë³„í•œ ê±´ ì—†ê³ , ë‹¨ì§€ **Marginal distribution**ì´ **Joint distribution**ìœ¼ë¡œ ë³€í•œê²Œ ì „ë¶€ì´ë‹¤.

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/cgan1.PNG?raw=1" width = "450" ></p>

latent vactor `z`ë¥¼ one-hot vectorë¡œ embeddingí•œ í›„, ì´ë¥¼ class label `y`ì™€ cancatenation í•´ì¤¬ë‹¤.
ë˜í•œ, ì´ ë…¼ë¬¸ì€ GANì´ ë‚˜ì˜¤ê³  ì–¼ë§ˆ ì•ˆëœ í›„ì— ë‚˜ì˜¨ ë…¼ë¬¸ì´ê¸° ë•Œë¬¸ì— MLPêµ¬ì¡°ë¥¼ ì‚¬ìš©í•œë‹¤. 

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/cgan2.PNG?raw=1" width = "800" ></p>

---

## 3. Experiment Results

ì‹¤í—˜ìœ¼ë¡œëŠ” Unimodalê³¼ multimodal, ë‘ê°€ì§€ì˜ ì‹¤í—˜ì„ ì§„í–‰í–ˆë‹¤.

### 3.1 Unimodal

- dataset : MNIST ì‚¬ìš©

- Generator nets
    uniform distributionì—ì„œ 100ì°¨ì›ì˜ noise prior `z`ë¥¼ ë½‘ì€ í›„, ReLU Layerë¥¼ ì´ìš©í•´ì„œ `z`ëŠ” 200ì°¨ì›ìœ¼ë¡œ, `y`ëŠ” 1000ì°¨ì›ìœ¼ë¡œ mappingí•œë‹¤. ì´í›„, ì´ ë‘˜ì„ concatí•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•œë‹¤.
- Discriminator
- Results
    label ë³„ë¡œ ì˜ í•™ìŠµëœë‹¤.
  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/cgan3.PNG?raw=1" width = "800" ></p>

### 3.2 Multimodal
- dataset : MIR Flickr 25,000dataset
  - UGM(User-generated metadata) ì‚¬ìš© (labeled data)
- Results
    - tagë“¤ì´ ì˜ ìƒì„±ëœë‹¤.
    <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/cgan4.PNG?raw=1" width = "600" ></p>
    
## 4. Opinion
> ğŸ¤” ì—„ì²­ë‚œ performanceë¥¼ ëƒˆë‹¤ê¸°ë³´ë‹¤ëŠ”, GANì— conditional infomationì„ ì¶”ê°€í•˜ìë¼ëŠ” ideaê°€ ê´œì°®ì•„ì„œ ìœ ëª…í•´ì§„ ë…¼ë¬¸ ê°™ë‹¤.
> GANì´ ë‚˜ì˜¤ê³  ê´œì°®ì•„ë³´ì´ë‹ˆê¹Œ ì½ì‹¸ê²Œ ë‚¸ ëŠë‚Œ ?!

---
## 5. Code

### 5.1 Generator

```python
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.init_size = opt.img_size // 4
        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))

        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),
            nn.Tanh(),
        )

    def forward(self, z):
        out = self.l1(z)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        return img
```

### 5.2 Discriminator

```python
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        def discriminator_block(in_filters, out_filters, bn=True):
            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]
            if bn:
                block.append(nn.BatchNorm2d(out_filters, 0.8))
            return block

        self.model = nn.Sequential(
            *discriminator_block(opt.channels, 16, bn=False),
            *discriminator_block(16, 32),
            *discriminator_block(32, 64),
            *discriminator_block(64, 128),
        )

        # The height and width of downsampled image
        ds_size = opt.img_size // 2 ** 4
        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())

    def forward(self, img):
        out = self.model(img)
        out = out.view(out.shape[0], -1)
        validity = self.adv_layer(out)

        return validity
```

### 5.3 Training
```python
for epoch in range(opt.n_epochs):
    for i, (imgs, _) in enumerate(dataloader):

        # Adversarial ground truths
        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)
        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)

        # Configure input
        real_imgs = Variable(imgs.type(Tensor))

        # -----------------
        #  Train Generator
        # -----------------

        optimizer_G.zero_grad()

        # Sample noise as generator input
        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))

        # Generate a batch of images
        gen_imgs = generator(z)

        # Loss measures generator's ability to fool the discriminator
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)

        g_loss.backward()
        optimizer_G.step()

        # ---------------------
        #  Train Discriminator
        # ---------------------

        optimizer_D.zero_grad()

        # Measure discriminator's ability to classify real from generated samples
        real_loss = adversarial_loss(discriminator(real_imgs), valid)
        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
        d_loss = (real_loss + fake_loss) / 2

        d_loss.backward()
        optimizer_D.step()

        print(
            "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"
            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())
        )

        batches_done = epoch * len(dataloader) + i
        if batches_done % opt.sample_interval == 0:
            save_image(gen_imgs.data[:25], "images/%d.png" % batches_done, nrow=5, normalize=True)

```

**Reference**
- Naver AI LAB ìµœìœ¤ì œ ì—°êµ¬ì›ë‹˜ ë°œí‘œìë£Œ
- https://github.com/eriklindernoren/PyTorch-GAN



