---
title: "[Paper Review] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation ë…¼ë¬¸ ë¶„ì„"
excerpt: "í•˜ë‚˜ì˜ Generatorì™€ discriminatorë¡œ ë‹¤ì–‘í•œ datasetì— ëŒ€í•´ image-to-image translationì„ í•˜ëŠ” StarGAN modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” í•˜ë‚˜ì˜ Generatorì™€ discriminatorë¡œ ë‹¤ì–‘í•œ datasetì— ëŒ€í•´ image-to-image translationì„ í•˜ëŠ” **starGAN model**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.


- Paper : [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://arxiv.org/abs/1711.09020) (CVPR 2018) / Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

> 2ê°œ ì´ìƒì˜ domainì„ ë‹¤ë£¨ëŠ” image-to-image translation ì—°êµ¬ë“¤ì€ **scalbilityì™€ robustness**ì— í•œê³„ê°€ ìˆì—ˆë‹¤. StarGANì€ ì´ë¥¼ ê°œì„ í•˜ì—¬ single networkë¡œ Multi-Domainì— ëŒ€í•´ ì´ë¯¸ì§€ ë³€í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆë‹¤. StarGANì€ flexibleí•˜ê³  scalableí•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.

## 1. Introduction

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan1.PNG?raw=1' width = '800' ></p>

ë³¸ ë…¼ë¬¸ì˜ ëŒ€í‘œì ì¸ taskëŠ” <span style='background-color: #E5EBF7;'> **CelebAì™€ RaFD datasetì„ ì´ìš©í•˜ì—¬ ì–¼êµ´ì˜ íŠ¹ì§•ê³¼ í‘œì •ì„ ë³€í™”** </span>ì‹œí‚¤ëŠ” ê²ƒì´ë‹¤.

**Using Dataset**
- CelebA : 40ê°œì˜ label (ë¨¸ë¦¬ìƒ‰, ì„±ë³„, ë‚˜ì´ ë“±ì˜ facial attributeì™€ ê´€ë ¨ëœ ì •ë³´)
- RaFD : 8ê°œì˜ label(happy, sad, angry ë“±ì˜ facial expressionì™€ ê´€ë ¨ëœ ì •ë³´)

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan2.PNG?raw=1' width = '700' ></p>
<font color="gray" font-size = "7px"><i> StarGANì—ì„œëŠ” single generatorë¥¼ ì‚¬ìš©í•´ì„œ ë‹¤ì–‘í•œ domainì„ mappingí•œë‹¤. : â­ë³„ëª¨ì–‘â­ </i></font>

**Exsiting Model : Cross-domain model**

ê¸°ì¡´ì˜ ì—°êµ¬ë“¤ì€ ë‹¤ì–‘í•œ domainì— ëŒ€í•´ image translation í•˜ëŠ” ê²ƒì´ ë§¤ìš° ë¹„íš¨ìœ¨ì ì´ì—ˆë‹¤.

Figure2ì˜ (a)ì²˜ëŸ¼ multi-domainì„ í•™ìŠµí•˜ë ¤ë©´ ê°ê°ì˜ generatorë“¤ì€ ì „ì²´ì˜ dataë¥¼ í™œìš©í•˜ì§€ ëª»í•˜ê³  ì˜¤ì§ 2ê°œì˜ domainì— ëŒ€í•´ì„œë§Œ í•™ìŠµì´ ê°€ëŠ¥í–ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ datasetì˜ domainë“¤ì„ ê²°í•©í•˜ì—¬ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì´ ì–´ë ¤ì› ë‹¤. (`k`ê°œì˜ domainì„ í•™ìŠµì‹œí‚¤ë ¤ë©´ `k(k-1)`ì˜ generatorê°€ í•„ìš”) 

---

StarGANì€ ê¸°ì¡´ ëª¨ë¸ì˜ ë¬¸ì œì (Fixed translation)ì„ ê°œì„ í•˜ì˜€ë‹¤. 

> - StarGANì€ í•˜ë‚˜ì˜ generatorë§Œìœ¼ë¡œë„ ë‹¤ì–‘í•œ domainë“¤ì„ mapppingì´ ê°€ëŠ¥í•˜ë¯€ë¡œ íš¨ìœ¨ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤.
> - ëª¨ë“  domainì˜ ì •ë³´(label)ë“¤ì„ controlí•  ìˆ˜ ìˆë„ë¡ mask vectorë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.

## 2. Related Work

**Generated Adversarial Networks**

- [[GAN] Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (2014) : [Review](https://happy-jihye.github.io/gan/gan-1/) 

**Conditionals GANs**

- [[CGAN] Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) (2014) : [Review](https://happy-jihye.github.io/gan/gan-3/)
- [Generative Adversarial Text to Image Synthesis](https://arxiv.org/abs/1605.05396) (2016) : [Review](https://happy-jihye.github.io/gan/gan-4/)

**Image-to-Image Translation**

- [[Pix2Pix] Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004) (CVPR 2017) : [Review](https://happy-jihye.github.io/gan/gan-8/)
- [[SPADE] Semantic Image Synthesis with Spatially Adaptive Normalization](https://arxiv.org/abs/1903.07291) (CVPR 2019) : [Review](https://happy-jihye.github.io/gan/gan-9/)
- [[CycleGAN] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)(ICCV 2017) : [Review](https://happy-jihye.github.io/gan/gan-10/)
- CoGAN
- DiscoGAN

ê¸°ì¡´ì˜ ì—°êµ¬ëŠ” 2ê°€ì§€ì˜ domainì— ëŒ€í•œ ê´€ê³„ë¥¼ ì°¾ì•˜ë‹¤ë©´, starganì—ì„œëŠ” ì´ë¥¼ í™•ì¥í•´ multi-domainì— ëŒ€í•´ì„œë„ ì´ë¯¸ì§€ ë³€í™˜ taskë¥¼ í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

## 3. Star Generative Adversarial Networks

### 3.1 Multi-Domain Image-to-Image Translation

> â­Our goal is to **train a single generator G that learns mappings among multiple domains.**

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan3.PNG?raw=1' width = '700' ></p>

- **Generator**ëŠ” target domain label $c$ì™€ input $x$ì„ ì´ìš©í•´ì„œ output imageë¥¼ ìƒì„±í•œë‹¤.
  $c, G(x, c) \rightarrow y$
  - input imageì—ì„œ ìœ ì—°í•˜ê²Œ ë‹¤ë¥¸ imageë¥¼ ìƒì„±í•˜ë„ë¡, target domain label $c$ëŠ” randomìœ¼ë¡œ ìƒì„±í•œë‹¤.

- **Discriminator**ëŠ” [ACGANê³¼ ìœ ì‚¬í•˜ê²Œ Auxiliary Classifier](https://happy-jihye.github.io/gan/gan-13/#2-ac-gans-auxiliary-classifier-gan)ì„ ì‚¬ìš©í•œë‹¤.
  - Auxiliary classifierëŠ” í•˜ë‚˜ì˜ discriminatorë¡œ ì—¬ëŸ¬ domainì„ controlí•œë‹¤.
  - DiscriminatorëŠ” `source`ì™€ `domain label`ì— ëŒ€í•œ í™•ë¥ ë¶„í¬ë¥¼ ìƒì„±í•œë‹¤.

#### Adversarial Loss

- GëŠ” ì•„ë˜ì˜ object functionì„ minimizeí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ, GëŠ” maximizeí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•œë‹¤.
  
$$\begin{aligned}
\mathcal{L}_{a d v}=& \mathbb{E}_{x}\left[\log D_{s r c}(x)\right]+\\
& \mathbb{E}_{x, c}\left[\log \left(1-D_{s r c}(G(x, c))\right)\right]
\end{aligned}$$

#### Domain Classification Loss

StarGANì˜ ëª©í‘œëŠ” target domain label $c$ì— ë”°ë¼ $x$ì—ì„œ $y$ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ Dì˜ ìµœìƒë‹¨ì— auxiliary classifierë¥¼ ì¶”ê°€í•˜ì—¬ domain classification lossì— ëŒ€í•´ì„œë„ í•™ìŠµí•˜ë„ë¡ í•˜ì˜€ë‹¤. 
- [[Paper Review] ACGAN: Conditional Image Synthesis with Auxiliary Classifier GANs ê°„ë‹¨í•œ ë…¼ë¬¸ ë¦¬ë·°](https://happy-jihye.github.io/gan/gan-13/)


<span style='background-color: #E5EBF7;'> (1) Domain Classification Loss of **Real image** </span>

- ì´ lossê°’ì„ ì¤„ì´ê¸° ìœ„í•´ original domain $c'$ì— ë”°ë¼ real image $x$ë¥¼ ë¶„ë¥˜í•˜ë„ë¡ í›ˆë ¨í•œë‹¤.

$$\mathcal{L}_{c l s}^{r}=\mathbb{E}_{x, c^{\prime}}\left[-\log D_{c l s}\left(c^{\prime} \mid x\right)\right]$$

<span style='background-color: #E5EBF7;'> (2) Domain Classification Loss of **Fake image** </span>

- GëŠ” target domain $c$ì— ë”°ë¼ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ ì´ loss functionì„ minimizeí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í›ˆë ¨í•œë‹¤.

$$\mathcal{L}_{c l s}^{f}=\mathbb{E}_{x, c}\left[-\log D_{c l s}(c \mid G(x, c))\right]$$


#### Reconstruction Loss

ì•„ë˜ì˜ ë‘ lossë¥¼ ì‚¬ìš©í•˜ë©´ ê·¸ëŸ´ì‹¸í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ëŠ” ìˆê² ì§€ë§Œ, domainì„ ë³€í™”ì‹œí‚¤ë©´ì„œ attributeë¥¼ ë³€í™”ì‹œí‚¬ ë•Œ input imageì˜ contentê°€ í›¼ì†ë  ìˆ˜ë„ ìˆë‹¤. íŠ¹ì„±ì„ ë³€í™”ì‹œí‚¬ ë•Œ ì›ë³¸ ì´ë¯¸ì§€ì˜ íŠ¹ì„±ì´ ë‚¨ì•„ìˆë„ë¡ [CycleGANì—ì„œ ì‚¬ìš©í•œ cycle-consistency loss](https://happy-jihye.github.io/gan/gan-10/#32-cycle-consistency-loss)ë¥¼ ì‚¬ìš©í•œë‹¤.

<span style='background-color: #E5EBF7;'> **Cycle-Consistency Loss** </span>

$$\mathcal{L}_{r e c}=\mathbb{E}_{x, c, c^{\prime}}\left[\left\|x-G\left(G(x, c), c^{\prime}\right)\right\|_{1}\right]$$

- where G takes in the translated image $G(x, c)$ and the original domain label $c'$ as input and tries to reconstruct the original image $x$
- L1 norm 

#### Full Objective

$$\begin{array}{c}
\mathcal{L}_{D}=-\mathcal{L}_{a d v}+\lambda_{c l s} \mathcal{L}_{c l s}^{r}, \\
\mathcal{L}_{G}=\mathcal{L}_{a d v}+\lambda_{c l s} \mathcal{L}_{c l s}^{f}+\lambda_{r e c} \mathcal{L}_{r e c}
\end{array}$$

- $\lambda_{c l s}$ì™€ $\lambda_{r e c}$ëŠ” hyper-parameterë¡œ, domain classificationê³¼ reconstruction lossì˜ ìƒëŒ€ì ì¸ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
- ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ì—ì„œëŠ” $\lambda_{c l s} = 1$, $\lambda_{r e c} = 10$ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.
- [ì´ ë¶€ë¶„ ì—­ì‹œ CycleGANê³¼ ìœ ì‚¬](https://happy-jihye.github.io/gan/gan-10/#33-full-object)

### 3.2 Training with Multiple Datasets

starGANì€ ì„œë¡œ ë‹¤ë¥¸ domainì„ ê°€ì§„ datasetì„ í†µí•©í•  ìˆ˜ ìˆë‹¤.
- ex) CelebAì˜ ë¨¸ë¦¬ìƒ‰ labelì„ RaFD datasetì— ì ìš©í•  ìˆ˜ ìˆìŒ

ê·¸ëŸ¬ë‚˜ ë‹¤ìˆ˜ì˜ datasetì„ í•™ìŠµì‹œí‚¬ ë•Œ, ì›í•˜ëŠ” labelì— ëŒ€í•œ ì •ë³´ëŠ” ì¼ë¶€ datasetì—ë§Œ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— ì‚¬ì§„ì„ ë³µì›í•˜ëŠ” ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ìƒê¸´ë‹¤. $\mathcal{L}_{r e c}=\mathbb{E}_{x, c, c^{\prime}}\left[\left\|x-G\left(G(x, c), c^{\prime}\right)\right\|_{1}\right]$ ì˜ ì‹ì—ì„œ $G(x, c)$ë¡œë¶€í„° input image $x$ë¥¼ ë³µì›í•˜ë ¤ë©´ $c'$ì˜ label vectorê°€ í•„ìš”í•œë° ì´ labelì´ ì—†ëŠ” ê²ƒì´ë‹¤.

(CelebAì˜ ì–¼êµ´ì„ ì›ƒëŠ” í‘œì •ì„ ë³€í™”ì‹œí‚¨ í›„ ë‹¤ì‹œ ì´ë¥¼ ìŠ¬í”ˆ í‘œì •ìœ¼ë¡œ ë³µì›ì‹œí‚¤ë ¤ê³  í•  ë•Œ, ê¸°ì¡´ì˜ CelebA datasetì€ ë¨¸ë¦¬ìƒ‰, ì£¼ê·¼ê¹¨ ë“±ì˜ labelë§Œ ìˆìœ¼ë¯€ë¡œ ìŠ¬í”ˆì–¼êµ´ $c'$ì— ëŒ€í•´ ë³µì›í•˜ê¸°ê°€ ì–´ë ¤ì›€)

#### Mask Vector
ë”°ë¼ì„œ ì´ë¥¼ ìœ„í•´ Mask vector $m$ì„ ë„ì…í•˜ì—¬ ì˜ëª¨ë¥´ëŠ” labelì— ëŒ€í•´ì„œëŠ” ë¬´ì‹œí•˜ë„ë¡ í•˜ì˜€ë‹¤. (one-hot vectorì—ì„œ 0ìœ¼ë¡œ) mask vectorë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµì„ í•˜ë©´ íŠ¹ì • datasetì˜ ì˜ ì•Œë ¤ì§„ labelì— ëŒ€í•´ì„œë§Œ í•™ìŠµì„ í•  ìˆ˜ ìˆë‹¤.

$$\tilde{c}=\left[c_{1}, \ldots, c_{n}, m\right]$$

Ex) CelebAì˜ ì´ë¯¸ì§€ë¥¼ trainingí•  ë•Œ, discriminatorëŠ” celebAì™€ ê´€ë ¨ëœ íŠ¹ì„±ë“¤(ë¨¸ë¦¬ìƒ‰, ì£¼ê·¼ê¹¨ ë“±ë“±)ì— ëŒ€í•œ classification errorë§Œì„ ìµœì†Œí™”í•˜ë„ë¡ í•™ìŠµì„ í•œë‹¤. (RaFDì˜ íŠ¹ì„±-í‘œì •ì— ê´€í•´ì„œëŠ” í•™ìŠµì„ ì•ˆí•¨)

> **Training Strategy**
> 
> DiscriminatorëŠ” CelebAì™€ RaFDë¥¼ ë²ˆê°ˆì•„ê°€ë©° í•™ìŠµì„ í•´ì„œ ë‘ datasetì˜ featureë“¤ì„ ê³¨ê³ ë£¨ í•™ìŠµí•˜ë„ë¡ í•œë‹¤. ë°˜ë©´, GeneratorëŠ” ëª¨ë“  datasetì— ëŒ€í•œ labelì„ ì œì–´í•˜ë„ë¡ í•™ìŠµí•œë‹¤.

## 4. Implementation

### Improved GAN Training

í•™ìŠµì„ ì•ˆì •í™”í•˜ê³ , ë” ì¢‹ì€ qualityì˜ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ gradient penalty($\lambda_{g p}=10$)ì™€ **Wasserstein GANì˜ objective function**ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.

$$\begin{aligned}
\mathcal{L}_{a d v}=& \mathbb{E}_{x}\left[D_{s r c}(x)\right]-\mathbb{E}_{x, c}\left[D_{s r c}(G(x, c))\right] \\
&-\lambda_{g p} \mathbb{E}_{\hat{x}}\left[\left(\left\|\nabla_{\hat{x}} D_{s r c}(\hat{x})\right\|_{2}-1\right)^{2}\right]
\end{aligned}$$

### Network Architecture

CycleGANì˜ architectureë¥¼ baselineìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
- [[Paper Review] CycleGAN : Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-10/#1-introduction)

- 2ê°œì˜ convolutional layersë¡œ êµ¬ì„±ëœ generator network 
  - stride size of 2 for downsampling
  - 6 residual blocks 
  - 2 transposed convolutional layers with the stride size of 2 for upsampling. 

- Gë§Œ instance normalization (DëŠ” X)

## 5. Experiment Results

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan4.PNG?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan6.PNG?raw=1' width = '700' ></p>

ê¸°ì¡´ì˜ **cross-domain model**ë“¤ì€ fixed translationì„ í•˜ê¸° ë•Œë¬¸ì— overfittingì´ ë˜ê¸° ì‰½ë‹¤. ë°˜ë©´, starGANì€ ìœ ì—°í•˜ê²Œ ë³€í™˜ì„ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë³´ë‹¤ í™”ì§ˆë„ ë” ì¢‹ê³  íŠ¹ì„±ë“¤ì˜ ì ìš©ì´ ì˜ëœë‹¤.


---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan5.PNG?raw=1' width = '700' ></p>

Amazon Mechanical Turk (AMT)ë¥¼ í†µí•´ ì‹¤ì œ userë“¤ì—ê²Œ í‰ê°€ë¥¼ ë°›ì•„ë´¤ëŠ”ë° starGANì´ ì œì¼ ì¢‹ì€ ê²°ê³¼ë¥¼ ë°›ì•˜ë‹¤.

---

### CelebA + RaFD
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan7.PNG?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan9.PNG?raw=1' width = '700' ></p>

í•˜ë‚˜ì˜ datasetë§Œì„ ì‚¬ìš©í•œ *StarGAN-SNG*ì€ íšŒìƒ‰ ë°°ê²½ê³¼ bluryí•œ ì´ë¯¸ì§€ê°€ ë‚˜íƒ€ë‚˜ì§€ë§Œ, datasetì„ ì„ì€ *StarGAN-JNT*ëŠ” high visual qualityì˜ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stargan8.PNG?raw=1' width = '700' ></p>

mask vectorë¥¼ ì‚¬ìš©í•´ì•¼ ì˜ ì•Œê³ ìˆëŠ” attributeì— ëŒ€í•´ì„œë§Œ í•™ìŠµì´ ë˜ë¯€ë¡œ mask vectorë¥¼ ì‚¬ìš©í•œ ì‚¬ì§„ì´ í€„ë¦¬í‹°ê°€ ê´œì°®ë‹¤.

## 6. Conclusion

> âœğŸ» StarGANì€ í•˜ë‚˜ì˜ Generatorì™€ discriminatorë§Œìœ¼ë¡œë„ ë‹¤ì–‘í•œ datasetì— ëŒ€í•´ image-to-image translationì„ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” íš¨ê³¼ì ì¸ ëª¨ë¸ì´ë‹¤. Scalablityí•˜ë‹¤ëŠ” ì¥ì ì´ ìˆìœ¼ë©°, ê¸°ì¡´ì˜ ëª¨ë¸ì— ë¹„í•´ high visual qualityì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.

