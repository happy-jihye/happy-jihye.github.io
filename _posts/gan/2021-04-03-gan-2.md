---
title: "[Paper Review] DCGAN : Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks 논문 분석"
excerpt: "GAN에 Convolutional Neural Network를 적용한 DCGAN(Deep Convolutional Generative Adeversarial Networks)에 대해 알아본다"

date: 2021-04-04
categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
search: true

# 목차
toc: true  
toc_sticky: true 

use_math: true
---


> 이번 포스팅에서는 GAN에 Convolutional Neural Network를 적용한 **DCGAN(Deep Convolutional Generative Adeversarial Networks)**에 대해 살펴본다.

- Paper : [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)
          (2015 / Alec Radford, Luke Metz, Soumith Chintala)

- [GAN-Zoos! (GAN 포스팅 모음집)](https://happy-jihye.github.io/gan/)
          
## 1. Introduction

이 논문이 나온 시점 이전까지 컴퓨터비전 분야에서는 CNN을 활용한 supervised learning 연구가 지배적이었다. 이때에도 CNN을 unsupervised에 적용시키려는 많은 노력들이 있었지만, 관련 연구들이 좋은 성과를 내지 못했었다.

<p align="center"><img src="https://github.com/happy-jihye/GAN/blob/main/images/gan3.png?raw=1" width = "500" ></p>


**이안 굿 팰로우가 제안한 [GAN(2014)](https://arxiv.org/abs/1406.2661)은 SoTA의 결과를 냈었고, discriminator와 generator 둘이 경쟁을 해서 likelihood를 maximize하려는 기법 자체도 굉장히 재미난 아이디어여서 많은 주목을 받았었다.**
(Generator가 생성한 이미지에서 feature를 뽑아서 discriminator가 감별 - discriminator는 supervised task를 수행한다. GAN에 대한 설명은 [이 글](https://happy-jihye.github.io/gan/gan-1/)을 참고)


다만, GAN은 training의 과정이 불안정했고 종종 generator는 nonsensical한 output을 만들어내기도 했다. 또한 GAN이 어떻게 학습되는지를 visualize하고 이해하기가 어려웠다.

DCGAN은 GAN에 Convolutional NN Layer를 적용하여 training을 안정화했고, GAN의 Generator와 Discriminator의 내부 네트워크를 이해할 수 있게 했다.


> DCGAN은 GAN을 안정화시켰다는 점에서 시사점이 크며, generator와 discriminator의 구조를 제시했다는 점에서 많은 주목을 받았다.
> 
> DCGAN은 `Generator`에서 특정 filter가 이미지의 어떤 feature를 학습하는지를 보여주었고, `Discriminator`에서도 다른 unsupervised algorithms과 비교했을때 꽤 괜찮은 image classification 성능을 보였다.  



---

## 2. Related Work

**2.1 Representation Learning from Unlabeld Data**

**2.2 Generating Natural Images**
- [parametric model / non-parametric model](https://process-mining.tistory.com/131)
- non-parametic model
  - [LAPGAN : Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks(2015)](https://arxiv.org/abs/1506.05751) : 고해상도의 이미지를 생성
  - [DRAW: A Recurrent Neural Network For Image Generation(2015)](https://arxiv.org/abs/1502.04623)
  - [Learning to generate chairs with convolutional neural networks(2014)](https://arxiv.org/abs/1411.5928)

**2.3 Visualizing the internals of CNNs**



---

## 3. Approach and Model Architecture

⭐ **DCGAN**
- 다양한 dataset에 대해 training을 안정화
- deeper generative model
- higher resolution

---
### DCGAN Architecture

Discriminator는 일반적인 CNN을 사용한다. Generator의 Convolutional Network는 **Transposed Conv**라는 약간 특이한 구조의 CNN을 사용하는데, 해상도를 늘리는 방향으로 학습이 진행된다.

- [Transposed Convolutions](https://zzsza.github.io/data/2018/02/23/introduction-convolution/)
<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan11.gif?raw=1" width = "400" ></p>
  
- 최근 들어서는 DCGAN의 Transposed Conv보다는 Resized Conv를 쓰는 추세!


<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan1.PNG?raw=1" width = "800" ></p>

> - **Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).**

[Striving for simplicity: The all convolutional net(2014)](https://arxiv.org/abs/1412.6806) 논문에서는 max-pooling function을 없애고 strided convolutional layer를 사용했다. DCGAN에서는 이 방식을 적용시켰다.

Generator는 max-pooling layer 대신 **fractional strided convolutions**을, Discriminator는 **strided convolutions**을 사용한다.

> - **Remove fully connected hidden layers for deeper architectures.**

그리고 <u>최근 CNN에서는 classifier로서 FC Layer보다 GAP(Global Average Pooling)을 사용하는 추세이다.</u> (FC layer는 전체 CNN보다 더 많은 parameter를 가지고, 연산도 오래걸리고, feature의 위치 정보들도 사라지는 단점들이 있음, GAP에 관한 내용은 [이 글](https://jetsonaicar.tistory.com/16) 참고)

- (추측) FC layer를 없애면 자연스레 dropout의 효과도 생기기 때문에 정규화에도 좋을 것 같다


> - **Use batchnorm in both the generator and the discriminator.**

DCGAN에서는 [Batch Normalization(2015)](https://arxiv.org/abs/1502.03167)를 추가한다. BN은 어떤 layer로부터 나온 batch단위 만큼의 activation이 있을 때, 이 값을 unit gaussian으로 만들어주기 위해 현재 batch에서 계산한 mean과 variance로 normalize를 시키는 방법이다. 
요즘 거의 모든 네트워크에 사용되는 듯? (자세한 글은 [이 글](https://happy-jihye.github.io/cs231n/cs231n-6/#4-batch-normalization) 참고)

논문에서는 BN을 사용하면 GAN의 고질적인 문제인 **Mode Collapsing**을 해결할 수 있다고 한다. 

DCGAN에서는 Generator의 output과 Discriminator의 input에는 BN을 적용하지 않았다.


> - **Use ReLU activation in generator for all layers except for the output, which uses Tanh.**
>
> - **Use LeakyReLU activation in the discriminator for all layers.**

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan10.png?raw=1" width = "700" ></p>

---

## 4. Details of Adversarial Training

**Dataset**
- Large-scale Scene Understanding (LSUN)
- Imagenet-1k
- Faces 
  - 이 dataset은 Facebook이 사진을 web에서 가져와서 opencv로 얼굴만 떼어논 데이터라고 한다.
  - 법적으로 문제가 안되려나..?!?🤔


**parameter들은 논문 3p를 참고 !**

## 5. Results

generative image model은 training sample을 기억(memorization)하고 overfitting이 잘 된다는 문제가 있다. 

DCGAN은 memorizing 현상은 안 나타난다고 주장한다.

- **LSUN**
  
  | epoch 1                                                      | epoch 5                                                      |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | <img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan2.PNG?raw=1"> | <img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan3.PNG?raw=1"> |


- **Walking in the Latent Space**
  
  GAN model에서는 latent space에서 움직일 때 (z가 약간 변할 때) 생성되는 이미지에 커다란 변화가 생기면 안된다. 
  논문에서는 이를 **Walking in the Latent Space**라고 부른다.

  논문에서는 또한 정말로 latent vector `z`가 조금 변하면 결과도 조금만 변하는지 확인해봤다.

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan4.PNG?raw=1" width = "400" ></p>

  6번째 줄을 보면, latent vector를 바꿀 때 창문이 없어졌다 생긴다. 즉, 부드럽게 변함
  
- **Discriminator**

  DCGAN의 supervised task를 평가하기 위해 discriminator를 **Imagenet-1k** 로 학습시킨 후 **CIFAR-10**으로 평가했다.

  아래의 그림을 보면 성능은 잘 나옴 !

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan5.PNG?raw=1" width = "700" ></p>


- **Visualizing the Discriminator Features**
  
  DCGAN의 내부 network가 어떻게 돌아가는지를 볼 수 있다.

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan6.PNG?raw=1" width = "600" ></p>

- **Generator**

  특정 object를 잊도록 해당 filter를 dropout을 하는 것도 가능

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan7.PNG?raw=1" width = "600" ></p>

- **Vector Arithmetic on Face Samples**

  DCGAN 논문의 굉장히 재밌는 부분이다. 
  > $vector(”King”) - vector(”Man”) + vector(”Woman”)$  = $vector("Queen")$ 를 하는 것이 가능하다 !!

  Word to Vector에 있었던 linear한 특징이 GAN의 latent space에서도 적용이 가능해짐.

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan8.PNG?raw=1" width = "500" ></p>

  - 예를 들어 `남자`를 생성하는 모델이 있을 때, 남자를 생성하는 특징 하나가 있는게 아니라 입을 생성하는 부분, 눈을 생성하는 부분 이런 식으로 각각의 특징들이 따로따로 학습되게 된다.

  <p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan9.PNG?raw=1" width = "500" ></p>
  
  > ✍🏻 vector arithmetic을 하려면 `smiling woman`과 같은 vector를 찾아야한다. (latent space에서 smiling woman에 해당하는 distribution이, neutral woman에 해당하는 distribution이 있을 것)
  > 
  > DCGAN 논문에서는 Generator에 넣었을 때 `smiling woman`가 나오는 latent vector `z`를 찾았다고 말하는데, 이 부분에 대한 설명이 논문에는 없다. 어떻게 smiling woman에 해당하는 `z`를 뽑았는지 추측을 해보자면, 학습이 끝난 Generator는 고정시켜놓고, 생성된 이미지들 중 smiling woman에 해당하는 `x`들을 뽑은 다음에 이를 back-propagation하여 input `z`를 뽑았을 거라고 추측해볼 수 있다. 즉, 역함수를 사용한 것과 비슷하다.   

## 6. Opinion

> 기존의 GAN 논문은 generator와 discriminator가 경쟁하면서 성장하는 과정에 대해서는 잘 설명이 되어있는데, generator와 discriminator 자체의 network에 대한 설명은 부족하다고 느껴졌었다.
> 
> DCGAN은 이를 잘 풀어낸 좋은 논문인 것 같다. 
> 
> 논문을 읽다보면 실험을 엄청 많이 돌려서 결과를 낸 것 같던데,, 역시 Facebook이다...
> 
> DCGAN은 GAN의 개괄인 듯한 인상을 받았다. 이를 적용한 후속 연구들 중 재미난 게 많을 것 같다 !😍


---

## Reference 

- http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-2.html
  

  