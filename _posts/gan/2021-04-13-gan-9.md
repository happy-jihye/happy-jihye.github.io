---
title: "[Paper Review] SPADE : Semantic Image Synthesis with Spatially-Adaptive Normalization ë…¼ë¬¸ ë¶„ì„"
excerpt: "Semantic Imageë¥¼ í˜„ì‹¤ì ì¸ imageë¡œ ë³€í™˜í•´ì£¼ëŠ” Spatially-adaptive normlization(SPADE) modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤"

categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” Semantic Imageë¥¼ í˜„ì‹¤ì ì¸ imageë¡œ ë³€í™˜í•´ì£¼ëŠ” **Spatially-adaptive normlization(SPADE) model**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.


- Paper : [Semantic Image Synthesis with Spatially-Adaptive Normalization](https://arxiv.org/abs/1903.07291) (CVPR 2019 / Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade2.gif?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade3.gif?raw=1' width = '700' ></p>


## 1. Introduction

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade1.PNG?raw=1' width = '700' ></p>

> We propose **spatially-adaptive normalization**, **a conditional normalization layer** that modulates the activations using input semantic layouts through a spatially adaptive, learned transformation and can effectively propagate the semantic information throughout the network.

ì´ì „ê¹Œì§€ëŠ” Semantic Image to photorealistic image taskì—ì„œ convolution, normalization, nonlinearity layerë¡œ êµ¬ì„±ëœ deep neworkë¥¼ ì‚¬ìš©í–ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ normalizationê³¼ì •ì—ì„œ semantic ì •ë³´ê°€ ì‚¬ë¼ì§„ë‹¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ spatially-adaptive normalizationì„ ì œì•ˆí•œë‹¤. 

## 2. Related Work

### 2.1 Conditional image synthesis

ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ conditional informationì„ ì£¼ë©´ ë” ë¹ ë¥´ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ê°€ ìƒì„±ëœë‹¤.

Conditional image synthesis taskë“¤ê³¼ ê´€ë ¨ ë…¼ë¬¸
- **Class-conditional models**
  - [[Paper Review] CGAN : Conditional Generative Adversarial Nets ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-3/)
  
- **Generating images based on text**
  - [[Paper Review] Generative Adversarial Text to Image Synthesis ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-4/)

- **Image to Image translation**
  - [[Paper Review] Pix2pix : Image-to-Image Translation with Conditional Adversarial Networks ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-8/)
  - <span style='background-color: #E5EBF7;'> **Segmentation masks to images : SPADE !** </span>

    *Segmentation masks to images*ëŠ” specificí•œ *Image to Image translation*ìœ¼ë¡œ, inputìœ¼ë¡œëŠ” semantic label mapì„ ë°›ê³  outputìœ¼ë¡œëŠ” photoë¥¼ ì¶œë ¥í•œë‹¤.

---

### 2.2 Unconditional normalization layers

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan-3.PNG?raw=1' width = '500' ></p>

ìœ„ì˜ unconditional normalization layerë“¤ì€ conditional normalization layerê³¼ ë‹¤ë¥´ê²Œ ì™¸ë¶€ ë°ì´í„°ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ì´ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ labelingì„ í•´ì¤˜ì•¼í•œë‹¤.

### 2.3 Conditional normalization layer

Conditional normalization layerëŠ” ì™¸ë¶€ ë°ì´í„°ì— ì˜ì¡´í•œë‹¤.(style transfer)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade4.png?raw=1' width = '700' ></p>

ë³´í†µ **Conditional normalization layer**ì€ ê·¸ë¦¼ê³¼ ê°™ì´
1. zero mean, unit deviationìœ¼ë¡œ normalizationì„ í•œ í›„,
2. ì™¸ë¶€ ë°ì´í„°ë¥¼ ë°›ì•„ denormalizeë¥¼ í•œë‹¤.(affine transformation)

> ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **normalization layerì— spatially-varing affine transformationì„ ì ìš©í•˜ì—¬ semantic maskë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ í•©ì„±**í•œë‹¤.

## 3. Semantic Image Synthesis

- ê° pixelì˜ semantic segmentation mask : $\mathbf{m} \in \mathbb{L}^{H \times W}$
  
### 3.1 SPatially-Adaptive DEnormalization
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade5.PNG?raw=1' width = '700' ></p>

- maskë¥¼ embedding spaceë¡œ projectioní•œ í›„, $\gamma, \beta$ë¡œ convolutionì„ í•œë‹¤.
- ì´ë•Œ modulation parmaeter $\gamma, \beta$ëŠ” vectorê°€ ì•„ë‹ˆë¼ tensor
  
$$\gamma_{c, y, x}^{i}(\mathbf{m}) \frac{h_{n, c, y, x}^{i}-\mu_{c}^{i}}{\sigma_{c}^{i}}+\beta_{c, y, x}^{i}(\mathbf{m})$$

- normalizationìœ¼ë¡œëŠ” instance normì´ ì•„ë‹ˆë¼ Batch Normì„ ì‚¬ìš©í–ˆë‹¤.
  
$$\begin{aligned}
\mu_{c}^{i} &=\frac{1}{N H^{i} W^{i}} \sum_{n, y, x} h_{n, c, y, x}^{i} \\
\sigma_{c}^{i} &=\sqrt{\frac{1}{N H^{i} W^{i}} \sum_{n, y, x}\left(\left(h_{n, c, y, x}^{i}\right)^{2}-\left(\mu_{c}^{i}\right)^{2}\right)}
\end{aligned}$$

### 3.2 SPADE generator

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade6.PNG?raw=1' width = '700' ></p>


- SPADEì—ì„œëŠ” learned modulation parameterë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— generatorì˜ ì²«ë²ˆì§¸ layerë¡œ segmentation mapì„ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ë‹¤. ë˜í•œ, normalization ê³¼ì •ì—ì„œ semantic maskì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ê¸° ë•Œë¬¸ì— Encoder ë¶€ë¶„(downsampling)ë„ í•„ìš” ì—†ë‹¤. (Decoder ë¶€ë¶„ë§Œ í•„ìš”)

  ë”°ë¼ì„œ generatorì˜ inputìœ¼ë¡œëŠ” random noise vectorë¥¼ ì‚¬ìš©í•˜ë©°, encoderë¥¼ ì œê±°í•¨ìœ¼ë¡œì¨ ëª¨ë¸ë„ ê²½ëŸ‰í™”ë˜ì—ˆë‹¤. 
  - inputìœ¼ë¡œ random noiseë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— latent vectorë¥¼ ì¡°ì ˆí•˜ë©´ì„œ styleì„ ë³€í™”í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•´ì¡Œë‹¤.

- upsampling layerë¡œëŠ” ResNet Blockì„ ì‚¬ìš©í•œë‹¤.
  - ëª¨ë“  normalization layerì˜ modulation parmìœ¼ë¡œëŠ” SPADEë¥¼ ì‚¬ìš©í•œë‹¤.
- multi-modal synthesisë„ ê°€ëŠ¥í•´ì¡Œë‹¤.

### 3.3 Why dose the SPADE work better?

> SPADEëŠ” ë‹¤ë¥¸ normalization layerì— ë¹„í•´ semantic informationì´ ì˜ ë³´ì¡´ëœë‹¤.

Instance Normê³¼ ê°™ì€ normalization layerëŠ” ë§ì€ conditional image í•©ì„±ì—ì„œ SoTAë¥¼ ë‹¬ì„±í–ˆì§€ë§Œ, uniform/flat segmentation maskì— ì ìš©í•˜ë©´ semantic informationì´ ì‚¬ë¼ì§„ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade7.PNG?raw=1' width = '700' ></p>

segmentation maskì—ì„œëŠ” ëŒ€ë¶€ë¶„ì˜ pixelì´ ê°™ì€ labelì„ ê°–ê³  ìˆë‹¤. ë”°ë¼ì„œ pix2pixHD ì—ì„œ Instance Normì„ ì‚¬ìš©í•˜ë©´ 0ìœ¼ë¡œ normalizedë˜ì–´ semantic informationì´ ì‚¬ë¼ì§ˆ ê²ƒì´ë‹¤.

### 3.4 Multi-model synthesis

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade8.PNG?raw=1' width = '700' ></p>

> Generatorì˜ inputìœ¼ë¡œ random vectorë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ multi-modal synthesisê°€ ê°€ëŠ¥í•´ì¡Œë‹¤.

- Encoderì—ì„œëŠ” ì´ë¯¸ì§€ì˜ styleì„ captureí•˜ê³ , generatorì—ì„œëŠ” SPADEì—ì„œì˜ segmentation mask informationê³¼ encoded styleì„ í•©ì¹œë‹¤.
  
- Encoderì™€ generatorìª½ì˜ architectureê°€ VAEì™€ ë¹„ìŠ·
- KL-Divergence lossë¡œ í•™ìŠµ

## 4. Experiments
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade9.PNG?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade10.PNG?raw=1' width = '700' ></p>

COCO-stuff, ADE20K, Cityscapes datasetìœ¼ë¡œ í•™ìŠµì„ ì‹œì¼°ì„ ë•Œ, ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ë¹„êµí•´ë´ë„ SPADEê°€ ì¢‹ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade11.PNG?raw=1' width = '700' ></p>

Amazon Mechanical Turk(AMT, ì‚¬ëŒì´ ì§ì ‘ test)ë¡œ testë¥¼ í•´ë´ë„ SPADEê°€ ì¢‹ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade12.PNG?raw=1' width = '700' ></p>

pix2pixì™€ ê°™ì€ ë‹¤ë¥¸ architectureì— SPADEë¥¼ ì‚¬ìš©í•´ë´ë„ SPADEë¥¼ ì“´ê²Œ ì¢‹ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade13.PNG?raw=1' width = '700' ></p>

random noiseë¥¼ ë°”ê¿”ë³´ë‹ˆ ì´ë¯¸ì§€ styleì´ ë³€í–ˆë‹¤. multi-model synthesisê°€ ì˜ëœë‹¤. 

## 5. Conclusions

> ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **Sp**atially-**A**daptive **(DE)**normalizatoinì„ ì œì•ˆí–ˆë‹¤. ì´ë¥¼ í†µí•´ normalization layerì—ì„œ affine ë³€í™˜ì„ í•  ë•Œ semantic ì •ë³´ë¥¼ ì˜ í™œìš©í•˜ë„ë¡ í•  ìˆ˜ ìˆì—ˆê³ , semantic imageë¡œë¶€í„° í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ í•©ì„±ì´ ê°€ëŠ¥í•´ì¡Œë‹¤.
> 
> ë˜í•œ, multi-model synthesis ë¿ë§Œ ì•„ë‹ˆë¼ guided image synthesisê°€ ê°€ëŠ¥í•´ì¡Œë‹¤.


---
**Reference**
- Naver AI LAB ìµœìœ¤ì œ ì—°êµ¬ì›ë‹˜ ë°œí‘œìë£Œ
- [https://paperswithcode.com/method/conditional-instance-normalization#](https://paperswithcode.com/method/conditional-instance-normalization#) 