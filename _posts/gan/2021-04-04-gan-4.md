---
title: "[Paper Review] GAN-CLS : Generative Adversarial Text to Image Synthesis ë…¼ë¬¸ ë¶„ì„"
excerpt: "textë¡œ imageë¥¼ ìƒì„±í•˜ëŠ” **Generative Adversarial Text to Image Synthesis** modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."

date: 2021-04-04
categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
  - nlp
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” textë¡œ imageë¥¼ ìƒì„±í•˜ëŠ” **Generative Adversarial Text to Image Synthesis** modelì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.


- Paper : [Generative Adversarial Text to Image Synthesis](https://arxiv.org/abs/1605.05396)
          (2016 / Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, Honglak Lee)
          
- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)





ì´ ë…¼ë¬¸ì´ ë‚˜ì™”ì„ ë•Œë§Œ í•´ë„ textì—ì„œ imageë¥¼ í•©ì„±í•˜ëŠ” ì—°êµ¬ê°€ í™œë°œí•˜ì§€ ì•Šì•˜ì—ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‹¹ì‹œì— ìì£¼ ì‚¬ìš©í•˜ë˜ architectureì¸  GANê³¼ deep architectrueë¥¼ ì‚¬ìš©í•˜ì—¬ text to image synthesis ëª¨ë¸ì„ ë§Œë“¤ì—ˆë‹¤.


## 1. Introduction

ë³¸ ë…¼ë¬¸ì€ textì—ì„œ imageë¥¼ í•©ì„±í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•œë‹¤. ì¦‰, wordë‚˜ charactorë¥¼ image pixelë¡œ mapping í•´ì•¼ í•œë‹¤.

**â­ Challenging Problem**
- textì—ì„œ ì¤‘ìš”í•œ visual detailsì„ ì¶”ì¶œ
- ì¶”ì¶œëœ ì •ë³´ë¡œë¶€í„° ì§„ì§œê°™ì€ ì´ë¯¸ì§€ë¥¼ í•©ì„±

## 2. Related Work

- Multimodal Learning
- Deep convolution decoder network
- GAN(Generative Adversarial Network)


## 3. Background

### 3.1 Generative Adversarial Networks


GANì€ Generatorì™€ Discriminatorê°€ ê²½ìŸì„ í•˜ë©´ì„œ í•™ìŠµì„ í•˜ëŠ” minimax game modelì´ë‹¤. (GANì— ëŒ€í•œ ì„¤ëª…ì€ [ì´ ê¸€](https://happy-jihye.github.io/gan/gan-1/)ì„ ì°¸ê³ )

$$\begin{aligned}
\min _{G} \max _{D} V(D, G)=& \mathbb{E}_{x \sim p_{\text {data }}(x)}[\log D(x)]+\\
& \mathbb{E}_{x \sim p_{z}(z)}[\log (1-D(G(z)))]
\end{aligned}$$


---

### 3.2 Deep symmetric structured joint embedding

- textì—ì„œ visually-dscriminative vectorë¥¼ ì–»ëŠ” ë°©ì‹ìœ¼ë¡œëŠ” [Learning Deep Representations of Fine-grained Visual Descriptions(2016)](https://arxiv.org/abs/1605.05395) ë…¼ë¬¸ì˜ **Deep Convolutional and Recurrent Text Encoder**ë¥¼ ì‚¬ìš©í–ˆë‹¤. 

- **Deep symmetric structured joint embedding**ëŠ” text encoding vectorì™€ image encoding vectorê°€ ê°™ì€ embedding vectorì´ë‹¤.

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti3.PNG?raw=1" width = "450" ></p>

- ë§¨ ì•„ë˜ì˜ ì‚¬ì§„ì´ textì™€ ê°€ì¥ ë¹„ìŠ·í•˜ë¯€ë¡œ lossê°€ 0ì— ê°€ê¹Œì›€

- **Classfier**
  - $f_{t}$ : text classifier

    $$\left.f_{v}(v)=\underset{y \in \mathcal{Y}}{\arg \max } \mathbb{E}_{t \sim \mathcal{T}(y)}\left[\phi(v)^{T} \varphi(t)\right)\right]$$

  - $f_{v}$ : visual classifier

    $$\left.f_{t}(t)=\underset{y \in \mathcal{Y}}{\arg \max } \mathbb{E}_{v \sim \mathcal{V}(y)}\left[\phi(v)^{T} \varphi(t)\right)\right]$$

  - $v_n$ : image / $\phi$ : image encoder(ex CNN)
  - $t_n$ : corresponding text description / $\varphi$ : text encoder (ex LSTM) 
  - $y_n$ : cass label
  - íŠ¹ì • ì´ë¯¸ì§€ê°€ ë“¤ì–´ê°”ì„ ë•Œ ê°€ì¥ ë¹„ìŠ·í•œ textë¥¼ ì´ëŒì–´ë‚´ëŠ” ë¶„ë¥˜ê¸°

- **Structure Loss**

    $$ \frac{1}{N} \sum_{n=1}^{N} \Delta\left(y_{n}, f_{v}\left(v_{n}\right)\right)+\Delta\left(y_{n}, f_{t}\left(t_{n}\right)\right) $$
    
    ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ë¡œë¶€í„° ë‚˜ì˜¨ ê°’($f_{v}\left(v_{n}\right)$, textê°’ì´ ë‚˜ì˜´)ê³¼ ì‹¤ì œ ê°’($y_{n}$)ê°„ì˜ lossë¥¼ ê³„ì‚°í•˜ê³ ,
    
    text ë¶„ë¥˜ê¸°ë¡œ ë‚˜ì˜¨ ê°’(imageê°’ì´ ë‚˜ì˜´)ê³¼ ì‹¤ì œ ê°’ê³¼ì˜ ë¹„êµí•˜ì—¬ lossë¥¼ ê³„ì‚°í•œë‹¤.

## 4. Method

> â­ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Convolutional RNNìœ¼ë¡œ encodingí•œ text featuresì™€ DCGANì„ í™œìš©í•´ì„œ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•œë‹¤.

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/dcgan1.PNG?raw=1" width = "800" ></p>

- [DCGAN ì„¤ëª…](https://happy-jihye.github.io/gan/gan-2/)


---
### 4.1 Network Architecture

- Generator : $\mathbb{R}^{Z} \times \mathbb{R}^{T} \rightarrow \mathbb{R}^{D}$
- Discriminator : $\mathbb{R}^{D} \times \mathbb{R}^{T} \rightarrow\{0,1\}$
  - T : dim of text description embedding
  - D : dim of text image embedding
  - Z : dim of noise ($z \in \mathbb{R}^{Z} \sim \mathcal{N}(0,1)$)

---


<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti2.PNG?raw=1" width = "700" ></p>

ì´ ë…¼ë¬¸ì˜ architectureëŠ” DCGANì„ ë³€í˜•í•˜ì—¬ ë§Œë“¤ì—ˆë‹¤.

**Generator**

1. text encoder $\varphi$ë¥¼ ì‚¬ìš©í•´ì„œ text query $t$ë¥¼ encoding í•œë‹¤.

2. encodingì˜ ê²°ê³¼ê°’($\varphi(t)$)ì„ FC layerì— ë„£ì–´ compressí•œ í›„ Leaky-ReLUë¥¼ ì‚¬ìš©í•´ì„œ 128-dimì˜ ì‘ì€ ì°¨ì›ìœ¼ë¡œ compressioní•œë‹¤.

3. ì´ ê°’ì„ noise vector `z`ì™€ concateí•œí›„ deconvolutional networkë¥¼ í†µí•´ generate imageë¥¼ ì–»ëŠ”ë‹¤.


**Discriminator**

1. stride-2 convolution layerì™€ BNê¸°ë²•, leaky ReLU functionì„ ì´ìš©í•´ì„œ í•™ìŠµì„ í•œë‹¤.

2. 1ë²ˆì˜ ê³¼ì •ì„ 4x4 conv layerê°€ ë ë•Œê¹Œì§€ ë°˜ë³µí•œë‹¤. (ì—¬ëŸ¬ê°œì˜ layerë¥¼ ìŒ“ìŒ)

3. 4x4 conv layerê°€ ë˜ë©´ compressiongëœ embedding vector $\varphi$ë¥¼ ì—¬ëŸ¬ê°œ ë³µì‚¬í•´ì„œ conv layer ë’¤ì— ì´ì–´ë¶™ì¸ë‹¤.(depth concatenation)

4. 1x1 conv layerê°€ ë˜ë„ë¡ ì—°ì‚°ì„ í•œ í›„ final scoreë¥¼ ì–»ëŠ”ë‹¤.

- ì´ë•Œ ëª¨ë“  conv layerì— ëŒ€í•´ì„œ BNì„ í•´ì¤€ë‹¤.

---

### 4.2 Matching-aware discriminator (GAN-CLS)

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti9.PNG?raw=1" width = "700" ></p>

conditional GANì€ discriminatorê°€ (text, images) pairê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ íŒë‹¨í•˜ë„ë¡ í•™ìŠµí•œë‹¤. ì´ë•Œ <u>ë¬¸ì œì ì€ discriminatorëŠ” real training imageê°€ ì–´ë–¤ text embedding contextì™€ matchë˜ëŠ”ì§€ ëª¨ë¥¸ë‹¤ëŠ” ì ì´ë‹¤.</u>

ì¦‰, real imageê°€ ìê¸°ë¥¼ ì„¤ëª…í•˜ì§€ ì•Šì€ textì™€ matchë  ìˆ˜ë„ ìˆë‹¤.(mismatch)

> ë”°ë¼ì„œ (real image, mismatched text term)ì„ ì¶”ê°€í•˜ë„ë¡ GAN training algorithmì„ ìˆ˜ì •í•˜ì—¬ **discriminatorê°€ fakeì— ëŒ€í•´ì„œë„ í•™ìŠµ**ì„ í•  ìˆ˜ ìˆê²Œ í•œë‹¤.

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti4.PNG?raw=1" width = "550" ></p>

ê¸°ì¡´ì˜ GANì€ ìœ„ì˜ algorithmì—ì„œ 7,9ì˜ scoreë§Œ ìˆì—ˆë‹¤ë©´ ì´ì œëŠ” line 8ì— ìˆëŠ” scoreë„ ì¶”ê°€ëœë‹¤.

---

### 4.3 Learning with manifold interpolation (GAN-INT)

> ìš°ë¦¬ê°€ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œì—ëŠ” ì£¼ì–´ì§„ textë§Œì„ ê°€ì§€ê³  imageë¥¼ ë§Œë“¤ì§€ë§Œ, ì‹¤ì œë¡œ ì´ë¥¼ ì‚¬ìš©í•  ë•Œì—ëŠ” training datasetì— ì—†ëŠ” textë¥¼ ì¤˜ë„ imageë¥¼ ìƒì„±í•  ìˆ˜ ìˆì–´ì•¼í•œë‹¤.
>
> ì¦‰, training datasetì— ìˆëŠ” textì™€ ë¹„ìŠ·í•œ textë¥¼ ì…ë ¥í–ˆì„ ë•Œì—ë„ imageë¥¼ ìƒì„±í•´ì•¼í•˜ê¸° ë•Œë¬¸ì— interpolationì˜ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ ì¡°ê¸ˆ ë” íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµì„ í•  ìˆ˜ ìˆê²Œ ëœë‹¤.


- ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ëŠ” embedding pairì‚¬ì´ì˜ interpolationì—ì„œ representationì„ í•™ìŠµí•œë‹¤.
  - interpolation(ë³´ê°„)ì€ [data manifold](https://greatjoy.tistory.com/51) ê·¼ì²˜ì—ì„œ ìƒê¹€
  - (text1, image1), (text2, image2)ê°€ ìˆì„ ë•Œ text1ê³¼ text2ê°€ spaceë‚´ì—ì„œ ê°€ê¹Œì´ì— ìˆë‹¤ë©´ image1ì„ í•™ìŠµí•  ë•Œ text1ì˜ featureì™¸ì—ë„ text2ì˜ featureê°€ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤. text1ê³¼ text2ì˜ ë³´ê°„ê°’ì„ ê°€ì§€ê³  í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤.

- ë”°ë¼ì„œ **interpolated text embedding($\beta t_{1}+(1-\beta) t_{2}$)**ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì•„ë˜ì˜ ì‹ì„ ì‚¬ìš©í•œë‹¤.
  - ì´ë•Œ interpolated text embeddingì€ ì‚¬ëŒì´ ì“´ textëŠ” ì•„ë‹ˆë‹¤. text1ê³¼ text2ì˜ ë³´ê°„ëœ embeddingê°’ì´ text3ë¼ë©´ text3ë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ” ê²ƒ!

    $$\mathbb{E}_{t_{1}, t_{2} \sim p_{\text {data }}}\left[\log \left(1-D\left(G\left(z, \beta t_{1}+(1-\beta) t_{2}\right)\right)\right)\right]$$

  - generatorëŠ” t1ê³¼ t2ì˜ ë³´ê°„ê°’ìœ¼ë¡œ í•™ìŠµì„ í•œë‹¤.
  - ë³´í†µ $\beta$ë¡œëŠ” 0.5ë¥¼ ì‚¬ìš©í•œë‹¤.

### 4.3 Inverting the generator for style transfer

> text encoding $\varphi(t)$ëŠ” image content(ex. flower shape, colors)ë¥¼ ì°¾ì•„ë‚´ëŠ” ì—­í• ì„ í•œë‹¤. (textì—ì„œ ì´ë¯¸ì§€ë¡œ í‘œí˜„í•  ë§Œí•œ featureë“¤ì„ ì¶”ì¶œ) ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´ ì‚¬ë¬¼ì˜ íŠ¹ì§•ë“¤ì„ ì˜ ì¶”ì¶œí•˜ì—¬ ìƒì„±í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ì§€ë§Œ, ê·¸ ì™¸ì˜ ì •ë³´ë“¤(ex.ë°°ê²½ì´ë‚˜ ìì„¸)ë“¤ì„ ìƒì„±í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ë‹¤.

ìš°ë¦¬ëŠ” ì´ ì •ë³´ë“¤ì„(objectì™¸ì˜ ì •ë³´)ë¥¼ **style factor**ë¼ê³  ë¶€ë¥´ëŠ”ë°, noise sample `z`ì—ì„œ style factorë¥¼ ë§Œë“œë ¤ë©´ **style transfer**ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.


style transferëŠ” ê¸°ì¡´ì˜ GANê³¼ ë‹¤ë¥´ë‹¤. ê¸°ì¡´ì—ëŠ” $\hat{x} \leftarrow G(z, \varphi(t))$ë¥¼ í•™ìŠµí–ˆë‹¤ë©´, **style transferì—ì„œëŠ” $\hat{x}$ì—ì„œ $z$ë¡œ ê±°ê¾¸ë¡œ í›ˆë ¨**ì„ í•œë‹¤.

ì •ë¦¬í•˜ìë©´, <u>Style transferëŠ” query imageë¥¼ text(style factor)ë¡œ ë°”ê¿”ì£¼ëŠ” ê¸°ë²•ì´ë‹¤.</u>


lossí•¨ìˆ˜ë¡œëŠ” ë‹¤ìŒì˜ **simple squared loss**ë¥¼ ì‚¬ìš©í•œë‹¤. (SëŠ” style encoder network)

$$\mathcal{L}_{\text {style }}=\mathbb{E}_{t, z \sim \mathcal{N}(0,1)}\|z-S(G(z, \varphi(t)))\|_{2}^{2}$$

## 5. Experiments

**Dataset**
  - CUB dataset (bird)
  - Oxford-102 dataset (flower)

**Structure**
- Text encoder : pre-train deep convolutional-recurrent
  - pre-trainëœ modelì„ ì‚¬ìš©í•œ ê±´, ì—°ì‚° ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•˜ë ¤ê³  í•œê±°ì§€ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¼ì¹˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.
- Image encoder : 1024-dim GoogleLeNet image embedding
  
**Hyper-parameterëŠ” ë…¼ë¬¸ ì°¸ê³ **

### 5.1 Qualitative Results

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti5.PNG?raw=1" width = "800" ></p>

GAN-CLSì™€ GAN-INTë¥¼ ë™ì‹œì— ì ìš©í•˜ë©´ ì¢‹ì€ ê²°ê³¼ë¥¼ ëƒ„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

---

### 5.2 Disentangling style and content / Pose and back ground style transfer



text embedding/text captionëŠ” image content(objectì˜ íŠ¹ì§•ë“¤)ì— ëŒ€í•œ ì •ë³´ëŠ” ê°–ê³  ìˆì§€ë§Œ, style informationì— ëŒ€í•œ ì •ë³´ë“¤ì€ ì—†ë‹¤. 5.2 ì‹¤í—˜ì€ **style informationì„ ì°¾ê¸° ìœ„í•œ ì‹¤í—˜**ì´ë‹¤.


ì´ë¯¸ì§€ì˜ similar/dissimilarë¥¼ ë§Œë“  ë‹¤ìŒ, style encoderë¥¼ í†µí•´ style vectorë¥¼ ì˜ˆì¸¡í•œë‹¤.(4.3ì²˜ëŸ¼) 

ì´ë¥¼ ìœ„í•´ ë³¸ ì‹¤í—˜ì—ì„œëŠ” **K-meanì„ ì‚¬ìš©í•´ì„œ imageë¥¼ 100ê°œì˜ clusterë¡œ grouping**í–ˆë‹¤. í•™ìŠµì„ ì‹œí‚¨ë‹¤ë©´, ë¹„ìŠ·í•œ styleì„ ê°€ì§„ ì´ë¯¸ì§€ë“¤ì˜ similarityëŠ” ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì„ ê°€ì§„ similarityë³´ë‹¤ í´ ê²ƒì´ë‹¤. 

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti6.PNG?raw=1" width = "600" ></p>

- **Background color** : RGB channelë¡œ cluster
- **Bird Pose** : 6 keypoint(beak, belly, breast, crown, forehead, and tail)ë¡œ cluster

ìœ„ì˜ ê·¸ë¦¼ì„ ë³´ë©´ ì´ë¯¸ì§€ ìƒì„±ì‹œì— styleì„ ì˜ ì ìš©ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

---

### 5.3 Sentence interpolation

ì•„ë˜ì˜ ê·¸ë¦¼ì€ Generatorê°€ í•™ìŠµì„ í•  ë•Œ **Interpolation(4.2) text maniford**ì—ì„œ í•™ìŠµì„ í•¨ì„ ì¦ëª…í•œë‹¤.


<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti7.PNG?raw=1" width = "700" ></p>

**Text Interpolation(Left)**
- noise distributionì€ ìœ ì§€í•˜ë©´ì„œ text embeddingë§Œì„ ë°”ê¾¸ë©´ ì™¼ìª½ ê·¸ë¦¼ì²˜ëŸ¼ ì´ë¯¸ì§€ê°€ ë³€í•œë‹¤.

**Noise Interpolation(Right)**
- text encodingì€ ê³ ì •í•˜ê³  ë‘ ê°€ì§€ì˜ noise vectorë§Œì„ ë°”ê¿”ë´¤ì„ ë•Œ ì´ ê²°ê³¼ ì—­ì‹œ smoothí•˜ê²Œ ë³€í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

---

### 5.4 Beyond birds and flowers

<p align="center"><img src="https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/gantti7.PNG?raw=1" width = "600" ></p>

MS-COCO datasetì„ ì´ìš©í•˜ì—¬ GAN-CLSë¥¼ í•™ìŠµì‹œì¼œë´¤ë‹¤. 

text encoder/GAN architecture, hyperparameterëŠ” CUB, Oxford-102ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œì™€ ë™ì¼í•œ ê²ƒì„ ì‚¬ìš©í–ˆë‹¤.
ë‹¤ë§Œ, MS-COCO datasetì€ classë‹¹ objectê°€ ì—¬ëŸ¬ê°œì´ê¸° ë•Œë¬¸ì— text encodingì„ í•  ë•Œ category levelì´ ì•„ë‹Œ instance levelì—ì„œ imageì™€ matchingì„ í–ˆë‹¤.

ì¼ë¶€ëŠ” í•™ìŠµì´ ì˜ë˜ì§€ë§Œ, ì¼ë¶€ëŠ” í•™ìŠµì´ ì˜ ì•ˆëœë‹¤. ê°ì²´ê°€ ë§ì€(textê°€ ë§ì€) datasetì„ í•™ìŠµì— ëŒ€í•´ì„œëŠ” ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”â­

## 6. Conclusion

>- visual descriptionìœ¼ë¡œ ë¶€í„° imageë¥¼ ìƒì„±í•˜ëŠ” ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ì¸ modelì„ ì œì•ˆ
>- visual interpretationì„ ì‚¬ìš©í•˜ë©´ ì¡°ê¸ˆ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.
>- Styleê³¼ contentë¥¼ ë¶„ë¦¬í•˜ëŠ” ëª¨ë¸ì„ ì œì•ˆ
>- ì´ë¯¸ì§€ ìƒì„±ì´ ì–´ë ¤ìš´ MS-COCO datasetì—ì„œë„ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤.

## 7. Opinion

> ì•„ì´ë””ì–´ë„ ì‹ ì„ í•˜ê³ , ì‹¤í—˜ë„ ë‹¤ì–‘í•œ ì¢‹ì€ ë…¼ë¬¸ì¸ ê²ƒ ê°™ë‹¤. text to image ê´€ë ¨ í›„ì† ë…¼ë¬¸ë“¤ë„ ì½ì–´ë³´ê³  ì‹¶ë‹¤!


---

**Reference**
- https://www.youtube.com/watch?v=M6E6ne4PSi0
- Code : https://github.com/aelnouby/Text-to-Image-Synthesis