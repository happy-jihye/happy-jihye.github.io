---
title: "[Paper Review] ACGAN: Conditional Image Synthesis with Auxiliary Classifier GANs ê°„ë‹¨í•œ ë…¼ë¬¸ ë¦¬ë·°"
excerpt: "classì— ë”°ë¼ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” Auxiliary Classfier GANs, ACGAN modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” classì— ë”°ë¼ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” Auxiliary Classfier GANs, **ACGAN model**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.


- Paper : [Conditional Image Synthesis With Auxiliary Classifier GANs](https://arxiv.org/abs/1610.09585) (ICML 2017 / Augustus Odena, Christopher Olah, Jonathon Shlens)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

<span style='background-color: #FFF2CC;'> ACGANì€ CGANì´í›„ì— ë‚˜ì˜¨ ë…¼ë¬¸ìœ¼ë¡œ, Discriminatorê°€ real/fakeë¥¼ íŒë³„í•  ë¿ë§Œ ì•„ë‹ˆë¼ class predictionë„ ê°™ì´ í•™ìŠµì„ í•œë‹¤. </span>

- [[CGAN] Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) (2014) : [Review](https://happy-jihye.github.io/gan/gan-3/)

ëª¨ë¸ì˜ architectureëŠ” ë§¤ìš° ê°„ë‹¨í•˜ë©°, ìƒì„± ì´ë¯¸ì§€ì˜ ë‹¤ì–‘ì„±ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ metric ì—­ì‹œ ì¶”ê°€ì ìœ¼ë¡œ ì œì‹œí•œë‹¤.



> í˜„ì¬ì—ëŠ” ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ë¯€ë¡œ ê°„ë‹¨í•˜ê²Œ ë¦¬ë·°ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤ğŸ˜‰ 


## 1. Introduction

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/acgan5.PNG?raw=1' width = '700' ></p>

- Demonstrate an image synthesis model for all 1000 ImageNet classes at a 128x128 spatial resolution (or any spatial resolution - see Section 3). 
- Measure how much an image synthesis model actually uses its output resolution (Section 4.1). 
- Measure perceptual variability and â€™collapsingâ€™ behavior in a GAN with a fast, easy-to-compute metric (Section 4.2). 
- Highlight that a high number of classes is what makes ImageNet synthesis difficult for GANs and provide an explicit solution (Section 4.6). 
- Demonstrate experimentally that GANs that perform well perceptually are not those that memorize a small number of examples (Section 4.3). 
- Achieve state of the art on the Inception score metric when trained on CIFAR-10 without using any of the techniques from (Salimans et al., 2016) (Section 4.4).


## 2. AC-GANs (Auxiliary Classifier GAN)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/acgan1.PNG?raw=1' width = '700' ></p>
<font color="gray" font-size = "x-small"><p align='center'><i> (ì¶œì²˜) Naver AI Lab ìµœìœ¤ì œ ì—°êµ¬ì›ë‹˜ ë°œí‘œìë£Œ  </i></p></font>


ACGANì˜ 
- **Generator**ëŠ” noiseë¥¼ samplingí•  ë•Œ class labelë„ ê°™ì´ samplingí•œë‹¤. 
  
$$X_{\text {fake }}=G(c, z)$$

- **Discriminator** : sourceì™€ class labelì˜ í™•ë¥ ë¶„í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµì„ í•œë‹¤.

$$P(S \mid X), P(C \mid X)=D(X)$$

**Object Function**
- log likelihood of the **correct source** $L_s$

$$\begin{array}{r}
L_{S}=E\left[\log P\left(S=\text { real } \mid X_{\text {real }}\right)\right]+E\left[\log P\left(S=\text { fake } \mid X_{\text {fake }}\right)\right]
\end{array}$$

- log likelihood of the **correct class** $L_c$

$$\begin{array}{r}
L_{C}=E\left[\log P\left(C=c \mid X_{\text {real }}\right)\right]+E\left[\log P\left(C=c \mid X_{\text {fake }}\right)\right]
\end{array}$$

> DëŠ” $L_s + L_c$ë¥¼, GëŠ” $L_c - L_s$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•œë‹¤.


<span style='background-color: #E5EBF7;'> real/fake ìª½ì„ íŒë³„í•˜ëŠ” ë¶€ë¶„ì€ Gì™€ Dê°€ ì ëŒ€ì ìœ¼ë¡œ í•™ìŠµì„ í•˜ì§€ë§Œ, class prediction ìª½ì€ adversarial í•˜ì§€ ì•Šê²Œ í•™ìŠµí•œë‹¤. </span>

ë˜í•œ, ì´ì „ ì—°êµ¬ë“¤ì€ classì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ qualityê°€ ì¤„ì–´ë“¤ì—ˆì§€ë§Œ, <span style='background-color: #E2F0D9;'> ACGANì€ classë³„ë¡œ í° ë°ì´í„°ì…‹ì„ ë‚˜ëˆˆ í›„ ê° subsetì— ëŒ€í•´ Gì™€ Dë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì•ˆì •ì ì´ë©° quality ì—­ì‹œ ê´œì°®ë‹¤.  </span>
- 1000ê°œ classì˜ ImageNetë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ 10ê°œë‹¨ìœ„ë¡œ í¬ê²Œ ë‚˜ëˆˆ í›„ 100ê°œì˜ AC-GANsì„ í•™ìŠµì‹œì¼°ë‹¤.
  

## 3. Results

ë³¸ ë…¼ë¬¸ì€ ImageNETì˜ datasetì„ ê°€ì§€ê³  ACGANì„ í›ˆë ¨ì‹œí‚¨ë‹¤. 

### Generating High Resolution Images Improves Discriminability

ACGANì€ `64 x 64`ì™€ `128 x 128`ì˜ resolutionì„ ê°€ì§„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. ì‹¤í—˜ì„ í•´ë³´ë©´ ê³ í•´ìƒë„ì˜ ì´ë¯¸ì§€ëŠ” ì €í•´ìƒë„ì˜ sampleì„ ë‹¨ìˆœíˆ resizingí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤ì œ ì´ë¯¸ì§€ì˜ íŠ¹ì„±ì„ ë” ì˜ ë°˜ì˜í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/acgan2.PNG?raw=1' width = '700' ></p>

ê³ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ë¡ discriminabilityê°€ ì¦ê°€í•˜ì˜€ë‹¤.

### Measuring the Diversity of Generated Images

<span style='background-color: #E5EBF7;'> âœğŸ» ë³¸ ë…¼ë¬¸ì—ì„œëŠ” image discriminabilityë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•œ metricì¸ MS-SSIM metricì„ ì œì•ˆí•˜ì˜€ë‹¤. </span>(ìì„¸í•œ ì„¤ëª…ì€ ìƒëµ) 

ê° classë‚´ì˜ ì´ë¯¸ì§€ì˜ ê°œìˆ˜ê°€ ì ë‹¤ë©´, ìƒì„±ëª¨ë¸ì€ í•´ë‹¹ í´ë˜ìŠ¤ ë‚´ì˜ ì‚¬ì§„ë“¤ì„ ì•”ê¸°í•  ìˆ˜ë„ ìˆë‹¤. mode collapseê°€ ìƒê¸¸ ìˆ˜ë„ ìˆëŠ”ë°, Inception scoreë¡œëŠ” ì´ë¥¼ ì¸¡ì •í•˜ì§€ ëª»í•œë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/acgan3.PNG?raw=1' width = '600' ></p>
ë”°ë¼ì„œ ìƒì„±ëª¨ë¸ì„ í‰ê°€í•˜ë ¤ë©´ ë‹¤ì–‘ì„±ì„ ì¸¡ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” MS-SSIM(0~1)ì˜ methodë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ë‹¤ì–‘ì„±ì„ í‰ê°€í•œë‹¤. ë‹¤ì–‘ì„±ì´ ë†’ì„ìˆ˜ë¡ MS-SSIM scoreê°€ ë‚®ê²Œ ë‚˜ì˜¨ë‹¤.

> ACGANì—ì„œëŠ” ê¸°ì¡´ì˜ GANê³¼ëŠ” ë‹¤ë¥´ê²Œ ë†’ì€ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í• ìˆ˜ë¡ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ê°€ ìƒì„±ëœë‹¤. (mode collapseì— ë¹ ì§ˆ í™•ë¥ ì´ ì¤„ì–´ë“¦)

---

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/acgan4.PNG?raw=1' width = '600' ></p>

ê¸°ì¡´ì˜ SoTA modelë³´ë‹¤ ì´ë¯¸ì§€ê°€ ì˜ ìƒì„±ëœë‹¤.

## 4. Discussion

> classì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©´ high-resolution ì´ë¯¸ì§€ì˜ discriminability í›ˆë ¨ì´ ë” ì˜ë¯€ë¡œ, ë” ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  í™•ë¥ ì´ ë†’ë‹¤. ë³¸ ë…¼ë¬¸ì€ 100ê°œì˜ classë¥¼ ê°€ì§„ ImageNET datasetì— ëŒ€í•´ì„œë„ ê³ í•´ìƒë„(`128 x 128`)ì˜ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆë‹¤.
