---
title: "About Talking Head Models #02: Landmark based model..."
excerpt: "Landmark based talking head model(FTSH, LPD)ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/talking-head-ex.gif?raw=1' width = '700' ></p>
<font color='gray'><i><p align='center' style='font-size:9px'> Talking Head Task Example [ì¶œì²˜](https://gfycat.com/ko/horribledampislandcanary-generative-adversarial-networks) </p></i></font>


> Neural Talking Head Modelì— ëŒ€í•´ ì„¤ëª…í•œ ê¸€ì…ë‹ˆë‹¤. 
> 
> Talking head taskì˜ ì •ì˜ì™€ ê´€ë ¨ ëª¨ë¸ë“¤ì„ ì„¤ëª…í•œ 1í¸ ë¨¼ì € ì½ì–´ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤ ğŸ˜Š
> - [About Talking Head Models #01: Definition, Methods, SoTA Models, Warping based modelâ€¦](https://happy-jihye.github.io/gan/gan-29)


---

## Various Talking Head Model

> ë³¸ í¬ìŠ¤íŒ…ì—ì„œëŠ” Talking Head Modelë“¤ ì¤‘ì—ì„œ Landmark based modelì— ëŒ€í•´ ì‚´í´ë³¼ ì˜ˆì •ì´ë‹¤. 
> 
> Talking Head model Paper ëª¨ìŒì§‘ì€ [ì´ ë§í¬](https://stream-chameleon-81c.notion.site/1fa3a78b6c54415784175c50eddfe3cc?v=ddc7ecf4fb0f484d8a98cb7da3fd1ea5)ì— ğŸ¤—


- [`FSTH`: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](https://happy-jihye.github.io/gan/gan-22/) (ICCV 2019) : [Paper](https://arxiv.org/abs/1905.08233)
- `LPD`: Neural Head Reenactment with Latent Pose Descriptors (CVPR 2020) : [Paper](https://arxiv.org/abs/2004.12000) 



---
### FSTH: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models (ICCV 2019)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/fsth-1.PNG?raw=1' width = '700' ></p>

> â­ï¸ **Keyword**: Adversarial Training, Model Agnostic Meta-Learning(MAML), Landmark

- [`FSTH`: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](https://happy-jihye.github.io/gan/gan-22/) (ICCV 2019) : [Paper](https://arxiv.org/abs/1905.08233), [review](https://happy-jihye.github.io/gan/gan-22/)


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/FSTH-10.jpeg?raw=1' width = '700' ></p>

- **Adversarial Meta-Learning**: meta-learning ê³¼ì •ì— adversarial trainingì„ ë„ì…í•˜ì—¬ meta-learning stageì—ì„œ ë³´ì§€ ëª»í–ˆë˜ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë“¤ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•¨.
  - í•©ì„±ëœ ì´ë¯¸ì§€ê°€ landmarkë¥¼ ì˜ ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ë¥¼ íŒë³„í•˜ëŠ” `Discriminator`ë¥¼ ë‘ 
- Meta-Learning ArchitectureëŠ” **Embedderì™€ Generator**ë¡œ êµ¬ì„±
  - `Embedder`
    - video frameê³¼ ê·¸ landmarkë¥¼ inputë¡œ ë°›ì•„ Nì°¨ì›ì˜ Embedding vector $\hat{e_i}$ ë¡œ mapping
    - $\hat{e_i}$ : ì‚¬ëŒì˜ identityì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ (poseë“±ì— ë¬´ê´€)
  - `Generator`
    - landmarkë¥¼ inputìœ¼ë¡œ ë°›ì€ í›„, AdaIN operationì„ í†µí•´ embedding vectorë¡œ ë¶€í„° target personì— ëŒ€í•œ styleì„ ì…í˜€ì¤Œ. 
- Few-shotì˜ ì´ë¯¸ì§€ë¡œ pre-trained modelì„ **fine-tuning**
  - target personì˜ imageë“¤ì„ meta-learned Embedderì— ë„£ì–´ ìƒˆë¡œìš´ embedding vector $\hat{\mathbf{e}}_{\mathrm{NEW}}$ë¥¼ ê³„ì‚°
  - ìƒˆë¡œ ê³„ì‚°ëœ embedding vectorì™€ landmarkë¥¼ ì´ìš©í•˜ì—¬ Generatorë¥¼ Fine-tuning
  - modelì— ëŒ€í•œ fine-tuningì´ ì™„ë£Œë˜ë©´ ì›í•˜ëŠ” í‘œì •ì— í•´ë‹¹í•˜ëŠ” landmarkë¥¼ ì´ìš©í•˜ì—¬ ìƒˆë¡œìš´ talking head video ìƒì„±

- **Result**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/talking-head-ex.gif?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/FSTH-11.gif?raw=1' width = '700' ></p>


---

### LPD: Neural Head Reenactment with Latent Pose Descriptors (CVPR 2020)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-1.png?raw=1' width = '700' ></p>

> â­ï¸ **Keyword**: Adversarial Training, Meta-Learning, Landmark, Segmentation(Masking)

- `LPD`: Neural Head Reenactment with Latent Pose Descriptors (CVPR 2020) : [Paper](https://arxiv.org/abs/2004.12000), [project](https://saic-violet.github.io/latent-pose-reenactment/), [code](https://github.com/shrubb/latent-pose-reenactment)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-3.jpeg?raw=1' width = '700' ></p>


- FSTH ë³´ë‹¤ ëŠ¦ê²Œ ë‚˜ì˜¨ ë…¼ë¬¸. FSTHì˜ ì•„ì´ë””ì–´ë¥¼ ë‹¤ìˆ˜ ì°¨ìš©
- **Adversarial Meta-Learning**: meta-learning ê³¼ì •ì— adversarial trainingì„ ë„ì…í•˜ì—¬ meta-learning stageì—ì„œ ë³´ì§€ ëª»í–ˆë˜ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë“¤ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•¨.
  - adversarial trainingì„ identityì™€ poseê°€ disentaglementë˜ë„ë¡ ë„ì™€ì¤Œ
- **Embedder**
  1. `Identity encoder`
     - ResNeXt-50 (32 x 4d)
     - high-capacity convolutional net $F$
     - FSTH modelì²˜ëŸ¼ inputìœ¼ë¡œ ì´ë¯¸ì§€ì™€ landmarkë¥¼ í•¨ê»˜ ë°›ì§€ ì•Šê³ , inputìœ¼ë¡œëŠ” kê°œì˜ ì´ë¯¸ì§€ë§Œì„ ë°›ìŒ
  2. `Pose encoder`
     - MobileNetV2
     - inputìœ¼ë¡œ random pose-augmentation transform ë³€í™˜ì„ í•œ ì´ë¯¸ì§€ $A(I_{K+1})$ ë¥¼ ì‚¬ìš© (ì´ transformationì„ ì‚¬ìš©í•˜ë©´ poseì™€ identityê°€ ë” disentanglement ë˜ëŠ” íš¨ê³¼ê°€ ìˆìŒ)
- **Generator**
  - `pose & identity embedding vector` concat í•˜ì—¬ MLPë¥¼ ê±°ì¹˜ê²Œ í•œ í›„, ì´ë¥¼ AdaIN operationì„ í†µí•´ Generatorì— ë„£ì–´ $K+1$ ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ reconstruct
  - `Generator`ëŠ” FSTHì˜ Generatorì™€ `StyleGAN v1`ì˜ êµ¬ì¡°ë¥¼ ë”°ë¦„  - Learned constant tensor (`512 x 4 x 4`)ì—ì„œ ì‹œì‘í•˜ì—¬ ì—¬ëŸ¬ê°œì˜ convolutional blockìœ¼ë¡œ êµ¬ì„±ë¨. AdaIN blockì€ ê°ê°ì˜ Conv layerì— ì‚½ì…
- **Loss Function**: Content Loss, Adversarial Loss, discriminator feature matching loss
- Few-shotì˜ ì´ë¯¸ì§€ë¡œ pre-trained modelì„ **Fine-Tuning**
  - ëª¨ë¸ì´ meta-learned ë˜ë©´, meta-learning ê³¼ì •ì—ì„œ ë³´ì§€ ëª»í•œ ìƒˆë¡œìš´ identityì— ëŒ€í•´ì„œë„ talking-head videoë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ Fine-Tuning ! (FSTHì˜ ë°©ì‹ì„ ì°¨ìš©)
  1. ìƒˆë¡œìš´ ì‚¬ëŒì˜ ì´ë¯¸ì§€ë“¤ì„ identity encoderì— ë„£ì€ í›„, ê° vectorë“¤ì„ í‰ê·  ë‚´ì–´ new identity vector $\bar{x}$ ë¥¼ ì–»ìŒ
  2. `meta-learned model`ì„ fine-tuning
      - ì´ ê³¼ì •ì—ì„œ identity vector $\bar{x}$ì™€ pose embedding networkëŠ” fix 

> - one-shotì˜ ì´ë¯¸ì§€ë¡œë„ talking-head taskê°€ ì˜ë˜ëŠ” ëª¨ë¸. ì‹¤í—˜ì„ í•´ë³´ë©´ ì´ë¯¸ì§€ê°€ ëª‡ì¥ ìˆëƒë³´ë‹¤ëŠ” target personì˜ identityê°€ ë” ì¤‘ìš”í•¨ (ex. 10ì¥ì˜ ì—˜ì‚¬ë³´ë‹¤ëŠ” 1ì¥ì˜ ê°•ë™ì›ì´ ë” ì˜ ë¨)
> - ë°í¬ë¡œë©”ê°€ ì‹¬í•˜ì§€ ì•Šë‹¤ë©´, cross-domainì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë„ ì¢‹ì€ ê²°ê³¼ë¥¼ ëƒ„
> - publicìœ¼ë¡œ ê³µê°œë˜ì§€ ì•Šì€ VoxCeleb2 datasetì„ ì‚¬ìš© (ì €ìë“¤ì´ youtube ë§í¬ì—ì„œ ì˜ìƒë“¤ì„ ë‹¤ìš´ë°›ì€ í›„ ì§ì ‘ data-preprocessingì„ í•œ ê²ƒìœ¼ë¡œ ì¶”ì¸¡ë¨. ì´ ë°ì´í„°ì…‹ì€ ê³µê°œí•˜ì§€ ì•ŠìŒ)
> - LPD Align: ì €ìë“¤ì´ ì§ì ‘ align ê·œê²©ì„ ë§Œë“¤ì–´ modelì„ í•™ìŠµ. FFHQ Alignì™€ ë‹¬ë¦¬ rotationì„ í•˜ì§€ ì•Šìœ¼ë©°, meta-learning ê³¼ì •ì—ì„œë„ rotationì„ ì•ˆí•œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ë„ ê²°ê³¼ê°€ ì˜ ë‚˜ì˜´


- **Result**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-3.png?raw=1' width = '700' ></p>

- **Comparison**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-2.png?raw=1' width = '700' ></p>