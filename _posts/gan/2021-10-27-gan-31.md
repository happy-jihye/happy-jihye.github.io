---
title: "About Talking Head Models #02: Landmark based model..."
excerpt: "Landmark based talking head model(FTSH, LPD)에 대해 알아본다."


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# 목차
toc: true  
toc_sticky: true 

use_math: true
---


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/talking-head-ex.gif?raw=1' width = '700' ></p>
<font color='gray'><i><p align='center' style='font-size:9px'> Talking Head Task Example [출처](https://gfycat.com/ko/horribledampislandcanary-generative-adversarial-networks) </p></i></font>


> Neural Talking Head Model에 대해 설명한 글입니다. 
> 
> Talking head task의 정의와 관련 모델들을 설명한 1편 먼저 읽어보시길 권장합니다 😊
> - [About Talking Head Models #01: Definition, Methods, SoTA Models, Warping based model…](https://happy-jihye.github.io/gan/gan-29)


---

## Various Talking Head Model

> 본 포스팅에서는 Talking Head Model들 중에서 Landmark based model에 대해 살펴볼 예정이다. 
> 
> Talking Head model Paper 모음집은 [이 링크](https://stream-chameleon-81c.notion.site/1fa3a78b6c54415784175c50eddfe3cc?v=ddc7ecf4fb0f484d8a98cb7da3fd1ea5)에 🤗


- [`FSTH`: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](https://happy-jihye.github.io/gan/gan-22/) (ICCV 2019) : [Paper](https://arxiv.org/abs/1905.08233)
- `LPD`: Neural Head Reenactment with Latent Pose Descriptors (CVPR 2020) : [Paper](https://arxiv.org/abs/2004.12000) 



---
### FSTH: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models (ICCV 2019)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/fsth-1.PNG?raw=1' width = '700' ></p>

> ⭐️ **Keyword**: Adversarial Training, Model Agnostic Meta-Learning(MAML), Landmark

- [`FSTH`: Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](https://happy-jihye.github.io/gan/gan-22/) (ICCV 2019) : [Paper](https://arxiv.org/abs/1905.08233), [review](https://happy-jihye.github.io/gan/gan-22/)


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/FSTH-10.jpeg?raw=1' width = '700' ></p>

- **Adversarial Meta-Learning**: meta-learning 과정에 adversarial training을 도입하여 meta-learning stage에서 보지 못했던 새로운 이미지들을 생성할 수 있도록 함.
  - 합성된 이미지가 landmark를 잘 반영하고 있는지를 판별하는 `Discriminator`를 둠
- Meta-Learning Architecture는 **Embedder와 Generator**로 구성
  - `Embedder`
    - video frame과 그 landmark를 input로 받아 N차원의 Embedding vector $\hat{e_i}$ 로 mapping
    - $\hat{e_i}$ : 사람의 identity에 대한 정보를 담고 있음 (pose등에 무관)
  - `Generator`
    - landmark를 input으로 받은 후, AdaIN operation을 통해 embedding vector로 부터 target person에 대한 style을 입혀줌. 
- Few-shot의 이미지로 pre-trained model을 **fine-tuning**
  - target person의 image들을 meta-learned Embedder에 넣어 새로운 embedding vector $\hat{\mathbf{e}}_{\mathrm{NEW}}$를 계산
  - 새로 계산된 embedding vector와 landmark를 이용하여 Generator를 Fine-tuning
  - model에 대한 fine-tuning이 완료되면 원하는 표정에 해당하는 landmark를 이용하여 새로운 talking head video 생성

- **Result**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/talking-head-ex.gif?raw=1' width = '700' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/FSTH-11.gif?raw=1' width = '700' ></p>


---

### LPD: Neural Head Reenactment with Latent Pose Descriptors (CVPR 2020)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-1.png?raw=1' width = '700' ></p>

> ⭐️ **Keyword**: Adversarial Training, Meta-Learning, Landmark, Segmentation(Masking)

- `LPD`: Neural Head Reenactment with Latent Pose Descriptors (CVPR 2020) : [Paper](https://arxiv.org/abs/2004.12000), [project](https://saic-violet.github.io/latent-pose-reenactment/), [code](https://github.com/shrubb/latent-pose-reenactment)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-3.jpeg?raw=1' width = '700' ></p>


- FSTH 보다 늦게 나온 논문. FSTH의 아이디어를 다수 차용
- **Adversarial Meta-Learning**: meta-learning 과정에 adversarial training을 도입하여 meta-learning stage에서 보지 못했던 새로운 이미지들을 생성할 수 있도록 함.
  - adversarial training을 identity와 pose가 disentaglement되도록 도와줌
- **Embedder**
  1. `Identity encoder`
     - ResNeXt-50 (32 x 4d)
     - high-capacity convolutional net $F$
     - FSTH model처럼 input으로 이미지와 landmark를 함께 받지 않고, input으로는 k개의 이미지만을 받음
  2. `Pose encoder`
     - MobileNetV2
     - input으로 random pose-augmentation transform 변환을 한 이미지 $A(I_{K+1})$ 를 사용 (이 transformation을 사용하면 pose와 identity가 더 disentanglement 되는 효과가 있음)
- **Generator**
  - `pose & identity embedding vector` concat 하여 MLP를 거치게 한 후, 이를 AdaIN operation을 통해 Generator에 넣어 $K+1$ 번째 이미지를 reconstruct
  - `Generator`는 FSTH의 Generator와 `StyleGAN v1`의 구조를 따름  - Learned constant tensor (`512 x 4 x 4`)에서 시작하여 여러개의 convolutional block으로 구성됨. AdaIN block은 각각의 Conv layer에 삽입
- **Loss Function**: Content Loss, Adversarial Loss, discriminator feature matching loss
- Few-shot의 이미지로 pre-trained model을 **Fine-Tuning**
  - 모델이 meta-learned 되면, meta-learning 과정에서 보지 못한 새로운 identity에 대해서도 talking-head video를 생성할 수 있도록 Fine-Tuning ! (FSTH의 방식을 차용)
  1. 새로운 사람의 이미지들을 identity encoder에 넣은 후, 각 vector들을 평균 내어 new identity vector $\bar{x}$ 를 얻음
  2. `meta-learned model`을 fine-tuning
      - 이 과정에서 identity vector $\bar{x}$와 pose embedding network는 fix 

> - one-shot의 이미지로도 talking-head task가 잘되는 모델. 실험을 해보면 이미지가 몇장 있냐보다는 target person의 identity가 더 중요함 (ex. 10장의 엘사보다는 1장의 강동원이 더 잘 됨)
> - 데포로메가 심하지 않다면, cross-domain의 이미지에 대해서도 좋은 결과를 냄
> - public으로 공개되지 않은 VoxCeleb2 dataset을 사용 (저자들이 youtube 링크에서 영상들을 다운받은 후 직접 data-preprocessing을 한 것으로 추측됨. 이 데이터셋은 공개하지 않음)
> - LPD Align: 저자들이 직접 align 규격을 만들어 model을 학습. FFHQ Align와 달리 rotation을 하지 않으며, meta-learning 과정에서도 rotation을 안한 데이터셋을 사용해도 결과가 잘 나옴


- **Result**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-3.png?raw=1' width = '700' ></p>

- **Comparison**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/lpd-2.png?raw=1' width = '700' ></p>