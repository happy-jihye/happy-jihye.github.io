---
title: "[Paper Review] StyleGAN3-Editing: Third Time's the Charm? Image and Video Editing with StyleGAN3 ë…¼ë¬¸ ë¦¬ë·°"
excerpt: " "


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

- Paper : Third Time's the Charm? Image and Video Editing with StyleGAN3 (arxiv 2022) ([arxiv](https://arxiv.org/abs/2201.13433), [project](https://yuval-alaluf.github.io/stylegan3-editing/), [code](https://github.com/yuval-alaluf/stylegan3-editing))

- ğŸ˜ StyleGAN Review Series
    - [`[Paper Review] StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks ë…¼ë¬¸ ë¶„ì„`](https://happy-jihye.github.io/gan/gan-6/)
    - [`[Paper Review] StyleGAN2 : Analyzing and Improving the Image Quality of StyleGAN ë…¼ë¬¸ ë¶„ì„`](https://happy-jihye.github.io/gan/gan-7/)
    - [`[Paper Review] StyleGAN2-ADA #01: Training Generative Adversarial Networks with Limited Data ë…¼ë¬¸ ë¶„ì„`](https://happy-jihye.github.io/gan/gan-19/)
    - [`[Paper Review] StyleGAN2-ADA #02: Training Generative Adversarial Networks with Limited Data ì½”ë“œ ë¦¬ë·°`](https://happy-jihye.github.io/gan/gan-20/)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

> **StyleGAN3**ëŠ” ê¸°ì¡´ ëª¨ë¸(StyleGAN ver1, 2)ì˜ ë¬¸ì œì ì´ì—ˆë˜ texture stickingì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•œ ëª¨ë¸ì´ë‹¤. 
>
> ğŸ¤” ê·¸ë ‡ë‹¤ë©´, ê¸°ì¡´ StyleGAN2 ëª¨ë¸ì—ì„œ íŒŒìƒë˜ì—ˆë˜ ë‹¤ì–‘í•œ ì—°êµ¬ë“¤(ex. image editing, gan inversion)ì€ StyleGAN3ì—ì„œë„ ì ìš©ì´ ë ê¹Œ?


ë³¸ ë…¼ë¬¸ì—ì„œëŠ” StyleGAN3ë¡œ ë³€í™”í•˜ë©´ì„œ ì–´ë–¤ ì´ì ì´ ìƒê²¼ëŠ”ì§€, ê·¸ë¦¬ê³  ê¸°ì¡´ì˜ ì—°êµ¬ë“¤ì€ ì–´ë–»ê²Œ ë³€í™”í•  ê²ƒì¸ì§€ë¥¼ ë¶„ì„í•œë‹¤.

- StyleGAN3ì˜ latent spaceê°€ StyleGAN2ì— ë¹„í•´ ì–¼ë§ˆë‚˜ disentanglementí•œì§€ë¥¼ ë¹„êµ
- ê¸°ì¡´ image editing/GAN-inversion ì—°êµ¬ë“¤ì€ stylegan3ì—ì„œ ì˜ ë™ì‘í•˜ëŠ”ì§€ ë¶„ì„
- unaligned imageì— ëŒ€í•´ì„œë„ inversionì„ í•  ìˆ˜ ìˆëŠ” StyleGAN3 Encoder
- ì‹¤í—˜ì„ í•´ë³´ë‹ˆ aligned Gê°€ unaligned Gë³´ë‹¤ disentangleí•˜ê²Œ inversionë˜ê³  editingì´ ì˜ëœë‹¤ê³  í•¨ â†’ ì´ë¯¸ì§€ ìƒì„±ì— aligned G ì‚¬ìš©
- StyleGAN3ë¡œ ë¹„ë””ì˜¤ë¥¼ inversion & recon í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë¡  ì œì•ˆ


<p align='center'><video controls width="700">
  <source src="https://yuval-alaluf.github.io/stylegan3-editing/videos/Jim_young_coupled.mp4?raw=1"
    type="video/webm">
</video></p>

---

# 1. The StyleGAN3 Architecture

## 1.1 Latent Space

- StyleGAN2
  - initial latent code $z \sim \mathcal{N}(0,1)^{512}$ â†’ MLP â†’ intermediate code $w$

- StyleGAN3
  - StyleGAN2ëŠ” ì–´ë–¤ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëƒì— ë”°ë¼ $w$ì˜ dimensionì´ ë‹¤ë¦„
    - 1024 - `18x512` , 256 - `14x512`
  - StyleGAN3: output image resolutionê³¼ ìƒê´€ì—†ì´  $w$ëŠ” 16ê°œë¡œ ê³ ì •

    $$\left(w_{0}, \ldots, w_{15}\right)$$

## 1.2 Constant Input â†’ Fourier Feature

- StyleGAN2: `4x4x512` learned constant input

- StyleGAN3: Fourier Feature
  - ì™œ Fourier Featureë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ëŠ” [ë‹¤ìŒ ë§í¬](https://happy-jihye.github.io/gan/gan-33/#32-fourier-features)ë¥¼ ì°¸ê³ 
  - Fourier Featureë¥¼ inputìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— rotationê³¼ translationì´ ìš©ì´
    - $w_{0}$ â†’ learned affine layer â†’ Fourier Feature
    - $w_{i}$ â†’ learned affine layersì— ë„£ì–´ì„œ conv kernel weightë¥¼ ì¡°ì ˆ

  - ì´ë¥¼ ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ë©´

    $y=G\left(w ;\left(r, t_{x}, t_{y}\right)\right)$



<span style='background-color: #E5EBF7;'> <b>Image Editing</b> </span>

- ê¸°ì¡´ StyleGAN2ëŠ” intermediate latent code $w$ë¥¼ ì¡°ì ˆí•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ë¥¼ editing í•œë‹¤.
- ì´ì™€ ë‹¬ë¦¬ StyleGAN3ëŠ” rotationì´ë‚˜ translationì´ ëœ ì´ë¯¸ì§€ë¥¼ ì–»ê¸° ìœ„í•´ Fourier Featureë¥¼ ì¡°ì ˆ

  â‡’ ğŸ˜Š aligned imageë§Œìœ¼ë¡œ í•™ìŠµëœ Generatorë¼ë„, Fourier Featureì„ ì¡°ì ˆí•˜ë©´ rotationì´ë‚˜ translationëœ ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥!

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled.png?raw=1' width = '500' ></p>


<span style='background-color: #E5EBF7;'> <b>$G_{unaligned}$ ë¡œ alignedëœ ì´ë¯¸ì§€ ìƒì„±</b> </span>

Unaligned imageë¡œ í•™ìŠµëœ Generatorì˜ ê²½ìš°

- Fourier Featureì˜ inputìœ¼ë¡œ $w_{0}$ë¥¼ ì‚¬ìš©í•˜ë©´ unaligned imageê°€ ìƒì„±ë˜ë‚˜
- $(w_{1}, \ldots, w_{15})$ ì˜ í‰ê· , $\bar{w}$ì„ Fourier Featureì˜ inputìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ê°•ì••ì ìœ¼ë¡œ alignedì´ ëœ ì´ë¯¸ì§€ê°€ ìƒì„±ë¨
  - Why? 
  (1) training distributionì˜ input poseì˜ í‰ê· ì´ ì„¼í„°ì— align ë˜ì–´ìˆì„ ìˆ˜ë„ ìˆê³ , 
  (2) ì£¼ë¡œ ì²«ë²ˆì§¸ layerì—ì„œ translationê³¼ rotation ì—¬ë¶€ê°€ ê²°ì •ë˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ ì¡°ì ˆí•˜ë©´ ì•„ì˜ˆ alignì´ ëœ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ì´ë¯¸ì§€ê°€ ìƒì„±ë¨

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%201.png?raw=1' width = '600' ></p>

---

# 2. Analysis

## 2.1 Rotation Control

> $w_{0}$ëŠ” ì´ë¯¸ì§€ì˜ translationê³¼ rotationì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì´ë‹¤. 
>
> ğŸ¤” ê·¸ë ‡ë‹¤ë©´ $w_{0}$ ê°€ ì–´ëŠ layerê¹Œì§€ ì´ë¯¸ì§€ì˜ t&rë¥¼ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆì„ê¹Œ?

<span style='background-color: #E5EBF7;'> <b>Experiment 01</b> </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%202.png?raw=1' width = '700' ></p>

- $w_{1}$ë§Œì„ ë³€í™”ì‹œí‚¤ê³  ë‚˜ë¨¸ì§€$(w_{0},w_{2},w_{3}...)$ ëŠ” ê·¸ëŒ€ë¡œ ë‘ 

  â‡’ (ê²°ê³¼) ì–¼êµ´ì˜ rotationì´ ì¡°ê¸ˆì”© ë³€í™”ê°€ ìˆì—ˆìŒ + face shape, eyeì™€ ê°™ì€ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì—ë„ ë³€í™”ê°€ ìˆì—ˆìŒ

<span style='background-color: #E5EBF7;'> <b>Experiment 02</b> </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%203.png?raw=1' width = '700' ></p>

- $w_{0}, w_{1}$ì€ ê³ ì •í•˜ê³  ë‚˜ë¨¸ì§€ code $w^{*}$ ë§Œ randomìœ¼ë¡œ ìƒì„±

$$G\left(\left(w_{0}, w_{1}, w^{*}, \ldots, w^{*}\right)\right)$$

  â‡’ (ê²°ê³¼) translationì´ë‚˜ rotationì€ ê·¸ëŒ€ë¡œì´ê³  identityë§Œ ë°”ë€œ

> (ê²°ë¡ ) $w_{0}$ëŠ” ì´ë¯¸ì§€ì˜ translationê³¼ rotationì„ ê²°ì •í•˜ë©°, $w_{1}$ë„ ì´ë¯¸ì§€ì˜ rotationì— ì¼ì •ë¶€ë¶„ ê´€ì—¬í•œë‹¤.


## 2.2 Disentanglement Analysis

- Paper: [A framework for the quantitative evaluation of disentangled representations](https://openreview.net/forum?id=By-7dz-AZ) (ICLR 2018)

ìœ„ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ `DCI metric`ì„ í†µí•´ latent spaceì˜ disentanglementí•¨ì„ ì¸¡ì •í•œë‹¤.

- **D (Disentanglement)**: latent spaceê°€ ì–¼ë§ˆë‚˜ disentangleí•œì§€
  - íŠ¹ì • ë°©í–¥ìœ¼ë¡œì˜ editingì´ ìš©ì´í•´ì•¼í•¨(íŠ¹ì • identityë¥¼ ë°”ê¾¸ê³ ì í–ˆì„ ë•Œ ë‹¤ë¥¸ íŠ¹ì§•ë„ ë³€í™”í•˜ë©´ ì•ˆë¨)
- **C (Conpleteness)**: single codeì˜ ë³€í™”ê°€ ì–´ë–¤ íŠ¹ì„±ì„ ì–¼ë§ˆë‚˜ ë³€í™”ì‹œí‚¤ëŠ”ì§€
- **I (Informativeness)**: generative factorì— ëŒ€í•´ codeê°€ ì–¼ë§ˆë‚˜ ìœ ìµí•œì§€(ìœ ì˜ë¯¸í•œ ë³€í™”ë¥¼ ë¼ì¹˜ëŠ”ì§€)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%204.png?raw=1' width = '500' ></p>

> StyleGAN2, 3 ëª¨ë‘ latent spaceê°€ StyleSpaceì—ì„œ ê°€ì¥ disentanglementí•˜ë©°, 
>
> StyleGAN3ì˜ W spaceê°€ StyleGAN2ì˜ W spaceì— ë¹„í•´ ë³„ë¡œ..

---

# 3. Image Editing

## 3.1 Editing via Linear Latent Directions

> InterfaceGAN ì²˜ëŸ¼ latent spaceì—ì„œ ì„ í˜•ì  ë°©í–¥ì„ ì°¾ì€ ë‹¤ìŒ ì´ë¥¼ ìˆ˜ì •í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ editingí•˜ëŠ” ë°©ë²•

<span style='background-color: #E5EBF7;'> <b>aligned imageì˜ ê²½ìš°</b> </span>

- stylegan2ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ editing

$$
G_{\text {aligned }}(w+\delta D ;(0,0,0))
$$

<span style='background-color: #E5EBF7;'> <b>unaligned imageì˜ ê²½ìš°</b> </span>

1. unaligned generator ì‚¬ìš©

    - classifierë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • attributeì— ê´€ì—¬í•˜ëŠ” ë°©í–¥ ì°¾ê¸°
      - (ë¬¸ì œì ) ì‚¬ìš©í•œ pre-trained classifierê°€ aligned imageë¡œ í•™ìŠµë˜ì–´ìˆì–´ì„œ unaligned imageì— ëŒ€í•´ì„œëŠ” ì¢‹ì€ classification scoreë¥¼ êµ¬í•˜ì§€ ëª»í•¨ â†’ latent space W ì—ì„œ ì´ìƒí•œ directionì„ í•™ìŠµ
      - Fourier Featureì˜ inputìœ¼ë¡œ $w_{0}$ ëŒ€ì‹  $\bar{w}$ ë¥¼ ì¨ì„œ ê°•ì œë¡œ alignëœ ë“¯ í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ ë‹¤ìŒì— pretrained classifierë¡œ latentâ€™s attribute scoreë¥¼ êµ¬í•¨

2. aligned generator ì‚¬ìš©

    - aligned generatorë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  $(r, t_{x}, t_{y})$ ê°’ì„ ì¡°ì ˆ

      â‡’ aligned & unaligned ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë“¤ ëª¨ë‘ ê°™ì€ latent direction ì¡°ì ˆí•˜ì—¬ ì´ë¯¸ì§€ë¥¼ editing í•  ìˆ˜ ìˆê²Œ ë¨

      $$
      G_{\text {aligned }}(w+ \left.\delta D ;\left(r, t_{x}, t_{y}\right)\right)
      $$

<span style='background-color: #E5EBF7;'> <b>Result</b> </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%205.png?raw=1' width = '700' ></p>

- ì‹¤í—˜ ê²°ê³¼ $G_{unaligned}$ì˜ latent spaceê°€ $G_{aligned}$ë³´ë‹¤ entangleí•¨ì„ í™•ì¸

  â‡’ $G_{aligned}$ë¥¼ ì´ìš©í•˜ì—¬ ì°¨í›„ ì—°êµ¬ë¥¼ ì§„í–‰

## 3.2 Editing via Non-Linear Latent Paths

> latent spaceì—ì„œ ë¹„ì„ í˜•ì ìœ¼ë¡œ latent codeë¥¼ ì¡°ì ˆí•˜ë©´ ë” disentangleí•˜ê²Œ ì´ë¯¸ì§€ editingì´ ê°€ëŠ¥í•˜ë‹¤.

- ê´€ë ¨ë…¼ë¬¸
  - Styleflow: Attribute-conditioned exploration of stylegan-generated images using conditional continuous normalizing flows (2020)
  - Guidedstyle: Attribute knowledge guided style manipulation for semantic face editing (2020)

W+ spaceë¥¼ ì‚¬ìš©í•˜ëŠ” StyleCLIP mapperë¥¼ ë´ë„ ì´ë¯¸ì§€ë¥¼ editing í–ˆì„ ë•Œ ë°°ê²½ê¹Œì§€ ê°™ì´ ë³€í™”í•¨ â†’ ì†ì„±ë“¤ë¼ë¦¬ entangle í•œ ê²ƒ

â‡’ ì €ìë“¤ì€ Wë‚˜ W+ ë³´ë‹¤ disentangleí•œ S spaceë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ë¡ 

## 3.3 Editing via Latent Directions in S

> StyleSpaceì—ì„œì˜ codeë¥¼ ì¡°ì ˆí•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ë¥¼ editingí•˜ë©´(`Fig 7`) Wë‚˜ W+ spaceì—ì„œ ì´ë¯¸ì§€ë¥¼ editing í–ˆì„ ë•Œ(`Fig 6`)ì— ë¹„í•´ disentangleí•˜ê²Œ image editingì´ ê°€ëŠ¥í•˜ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/fig6.png?raw=1' width = '500' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/fig7.png?raw=1' width = '500' ></p>


- `Fig 6`ì— ë¹„í•´ `Fig 7` ëŠ” ì›í•˜ëŠ” ì†ì„±ë§Œ ë”± ë³€í™”í•˜ê³  ë°°ê²½ì€ ê±°ì˜ ë³€í•˜ì§€ ì•ŠìŒ

---

# 4. StyleGAN3 Inversion

Optimize ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ ë‹¤ìŒ lossë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ inversioní•  ìˆ˜ ìˆë‹¤.

$$
\hat{w}=\underset{w}{\arg \min } \mathcal{L}\left(x, G\left(w ;\left(r, t_{x}, t_{y}\right)\right)\right.
$$

ê·¸ëŸ¬ë‚˜ optimizeë¥¼ í•´ì„œ imageë¥¼ inversioní•˜ë©´, ë¹„ë””ì˜¤ë¡œ ë´¤ì„ ë•Œ consistencyê°€ ë–¨ì–´ì§„ë‹¤. 

> â‡’ Encoderë¡œ ì‚¬ìš©!
> 
> encoderë¥¼ í†µí•´ ì—¬ëŸ¬ ì´ë¯¸ì§€ë“¤(ë¹„ë””ì˜¤)ì„ inversioní•˜ë©´ ì´ë¯¸ì§€ë“¤ ê°„ì— consistencyê°€ ìˆê¸° ë•Œë¬¸ì— ë¹„ë””ì˜¤ë¡œ ë´¤ì„ ë•Œ ìì—°ìŠ¤ëŸ½ë‹¤.

ë‹¤ìŒ loss functionì„ í†µí•´ ì—¬ëŸ¬ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ inversion í•  ìˆ˜ ìˆëŠ” Encoderë¥¼ í•™ìŠµí•˜ì˜€ë‹¤.

$$
\sum_{i=1}^{N} \mathcal{L}\left(x_{i}, G\left(E\left(x_{i}\right)\right)\right)
$$

- image inversion: $w=E\left(x\right)$
- edited image: $y_{\text {edit }}=G\left(f(w) ;\left(r, t_{x}, t_{y}\right)\right)$

## 4.1 Designing the Encoder Network

- Unaligned Generatorë¡œ Unaligned imageì— ëŒ€í•´ inversion ì‹œí‚¬ ìˆ˜ ìˆëŠ” Encoderë¥¼ í•™ìŠµì‹œì¼œë´„
  - ì•„ë˜ì˜ ì‹: Encoderë¥¼ í•™ìŠµì‹œí‚¤ëŠ” loss function
  - Generator: pretrained *unaligned* G

$$
\sum_{i=1}^{N} \mathcal{L}\left(x_{\text {unaligned }}^{i}, G\left(E\left(x_{\text {unaligned }}^{i}\right)\right)\right)
$$

> (ê²°ë¡ ) unaligned imageëŠ” ì´ë¯¸ì§€ì˜ ë¶„í¬ê°€ ë„ˆë¬´ ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì— inversion & reconì´ ì–´ë ¤ì›€

ê·¸ë ‡ë‹¤ë©´ aligned imageì— ëŒ€í•´ì„œë§Œ inversioní•˜ë„ë¡ Encoderë¥¼ ë‹¨ìˆœí™”í•´ë³´ì!

  â†’ EncoderëŠ” unaligned imageì— ë¹„í•´ ë¹„êµì  ë‹¨ìˆœí•œ ë¶„í¬ë¥¼ ê°€ì§€ëŠ” ì´ë¯¸ì§€(=aligned image)ë¥¼ ì¸ì½”ë”©í•˜ê¸° ë•Œë¬¸ì— inputì˜ identityë¥¼ ì¢€ ë” ì˜ í¬ì°©í•  ìˆ˜ ìˆìŒ
  
  â†’ aligned imageë¥¼ inversioní•˜ë”ë¼ë„ Generatorë¥¼ ì´ìš©í•˜ì—¬ unaligned imageì²˜ëŸ¼ ë§Œë“¤ ìˆ˜ ìˆìŒ

> ğŸ¤” ì—¬ì „íˆ StyleGAN3ì˜ ì¥ì ì„ ì‚´ë ¤ì„œ unaligned imageì— ëŒ€í•´ì„œë„ encodingì„ í•˜ê³  ì‹¶ì€ë°.. ì´ ê²½ìš°ì—ëŠ” ì–´ë–»ê²Œ í• ê¹Œ?

### 4.1.1 Aligned Encoderë¡œ Unaligned image inversioní•˜ê¸°

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%206.png?raw=1' width = '700' ></p>

1. ìš°ì„  unaligned image $x_{\text {unaligned }}$ì— ëŒ€í•´ alignì„ ë§ì¶¤ â†’ $x_{\text {aligned }}$

2. 1ì˜ ê³¼ì •ì„ í†µí•´ alignì´ ë§ì¶°ì§„ ì´ë¯¸ì§€ì— ëŒ€í•´ encoderë¡œ inversion

   $$
   w_{\text {aligned }}=E\left(x_{\text {aligned }}\right) 
   $$

3. $x_{\text {unaligned }}$ì—ì„œ ì–¼ë§ˆë‚˜ rotation & translation $(r, t_{x}, t_{y})$ ì„ í•˜ë©´ $x_{\text {aligned }}$ê°€ ë˜ëŠ”ì§€ë¥¼ ê³„ì‚°

   How? (1) ë‘ ì´ë¯¸ì§€( $x_{\text {unaligned }}$ì™€ $x_{\text {aligned }}$)ì—ì„œ ëˆˆì„ detect â†’ ì´ë¥¼ ë¹„êµí•˜ì—¬ ì–¼ë§ˆë‚˜ rotationì´ ë˜ì—ˆëŠ”ì§€ë¥¼ ê³„ì‚°

   (2) (1)ì—ì„œ ê³„ì‚°í•œ ê°’ì„ í† ëŒ€ë¡œ $x_{\text {unaligned }}$ë¥¼ rotation 

   (3) rotationì´ ëœ  $x_{\text {unaligned }}$ì™€  $x_{\text {aligned }}$ì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•˜ì—¬(vertical & horizontal distance) ì–¼ë§ˆë‚˜ translation ë˜ì—ˆëŠ”ì§€ë¥¼ ê³„ì‚° 

4. 3ì—ì„œ ê³„ì‚°í•œ $(r, t_{x}, t_{y})$ì„ í† ëŒ€ë¡œ ì´ë¯¸ì§€ ìƒì„±

   $$
   y_{\text {unaligned }}=G\left(w_{\text {aligned }} ;\left(r, t_{x}, t_{y}\right)\right)
   $$

---

### 4.1.2 EncoderëŠ” ì–´ë–¤ êµ¬ì¡°ë¥¼ ì‚¬ìš©í• ê¹Œ?


ì €ìë“¤ì€ **pSp, e4e, restyle Encoder**ë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤. 

> ğŸ¤”  ì €ìë“¤ì´ ì´ ì„¸ ê°€ì§€ encoderë“¤ì˜ ì½”ë“œ hierarchyê°€ ë˜‘ê°™ì•„ì„œ ì–˜ë“¤ë¡œë§Œ ë¹„êµ ì‹¤í—˜í•œ ê²ƒ ê°™ë‹¤.(ì‹¤í—˜ì´ ì‰¬ìš°ë‹ˆê¹Œ..) ë‹¤ë¥¸ idinvertë‚˜ ë‹¤ë¥¸ stylegan encoderë“¤ë„ ì‹¤í—˜í•´ë´¤ìœ¼ë©´ ì¢‹ì•˜ì„ í…ë°.. ì•„ìˆ©..

aligned imageì— ëŒ€í•´ì„œ inversioní•˜ëŠ” Encoderë¥¼ í•™ìŠµì‹œí‚¤ë¯€ë¡œ Encoder êµ¬ì¡°ëŠ” StyleGAN2ì™€ ë™ì¼í•˜ë‹¤.


<span style='background-color: #E5EBF7;'> <b>ë‚˜ë¨¸ì§€ëŠ” ë‹¤ ê·¸ëŒ€ë¡œê³  Encoder í•™ìŠµì— í•„ìš”í•œ Generatorë§Œ ë³€í™”</b> </span>

- ì´ì „ì—ëŠ” StyleGAN2 ì˜€ë‹¤ë©´, ì´ë²ˆì—ëŠ” pretrained aligned StyleGAN3 Generatorë¥¼ ì‚¬ìš©
- ëª¨ë“  encoderë“¤ì€ 7ë§Œì¥ì˜ FFHQ datasetìœ¼ë¡œ í•™ìŠµë¨


<span style='background-color: #E5EBF7;'> <b>pSpì™€ e4e í•™ìŠµ</b> </span>

- í›ˆë ¨ ë””í…Œì¼: Due to the larger memory consumption required by StyleGAN3, our encoders are trained using a batch size of 2. To match the batch size used in the official implementations of the StyleGAN2 pSp and e4e encoders, we apply gradient accumulation to attain an effective batch size of 8 (i.e., an optimization step is performed every four batches). All encoders are trained using a single NVIDIA P40 GPU.
- Loss function

$$
\mathcal{L}(x)=\lambda_{l 2} \mathcal{L}_{2}(x)+\lambda_{\text {lpips }} \mathcal{L}_{L P I P S}(x)+\lambda_{i d} \mathcal{L}_{\mathrm{id}}(x)
$$


<span style='background-color: #E5EBF7;'> <b>restyle í•™ìŠµ</b> </span>

- restyle encoderëŠ” progressiveí•˜ê²Œ trainingí•˜ëŠ”ë° ì €ìë“¤ì€ ì´ë¥¼ ì•ˆí–ˆë‹¤ê³  í•¨
- ëŒ€ì‹  ì²« trainingë¶€í„° 16 latent codesë¥¼ í•œë²ˆì— ì˜ˆì¸¡! (ì´ë ‡ê²Œ í–ˆë”ë‹ˆ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í–ˆë‹¤ê³  report)

## 4.2 Inverting Images into StyleGAN3

- test setìœ¼ë¡œëŠ” CelebA-HQ ë¥¼ ì‚¬ìš©

<span style='background-color: #E5EBF7;'> <b>Qualitative Evalution</b> </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%207.png?raw=1' width = '700' ></p>

- StyleGAN3ê°€ 2ì™€ ë¹„êµí•´ë„ ê´œì°®ê²Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•¨
- StyleGAN3: unaligned source imageì— ëŒ€í•´ alignì„ ë§ì¶”ê³  encoding í–ˆë‹¤ê°€ ê³„ì‚°ëœ r&t ê°’ì„ ë°”íƒ•ìœ¼ë¡œ unaligned imageë¥¼ ìƒì„±í•˜ëŠ”ë°, ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ê½¤ ê´œì°®ìŒ

<span style='background-color: #E5EBF7;'> <b>Quantitative Evalution</b> </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%208.png?raw=1' width = '700' ></p>

- StyleGAN3ì˜ scoreê°€ StyleGAN2ì˜ scoreë³´ë‹¤ ì•ˆì¢‹ìŒ
  - ì €ìë“¤ì€ ì´ ì›ì¸ì´ (StyleGAN3ì—ê²Œ) entangleí•œ W+ spaceìœ¼ë¡œ inversion í–ˆê¸° ë•Œë¬¸ì´ë¼ê³  ì£¼ì¥.
  - ì €ìë“¤ì€ S spaceë¡œ inversioní•˜ë©´ StyleGAN3ë„ ê½¤ ê´œì°®ì€ ì„±ëŠ¥ì„ ê°€ì§ˆê±°ë¼ê³  ìƒê°í•˜ë‚˜ë´„

<span style='background-color: #E5EBF7;'> <b>Editability via Latent Space Manipulation</b> </span>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%209.png?raw=1' width = '700' ></p>

- $Restyle_{e4e}$ encoder: ì´ë¯¸ì§€ì˜ identityë„ ë³´ì¡´ë˜ë©´ì„œ image editingì´ ë§¤ìš° ì˜ë¨
- $Restyle_{pSp}$ encoder: ì´ë¯¸ì§€ reconì€ ì˜í•˜ì§€ë§Œ, editing ì„±ëŠ¥ì´ ë–¨ì–´ì§
- ì´ëŸ° ì„±ëŠ¥ì°¨ì´ê°€ StyleGAN3ì—ì„œ ë” ì‹¬í•¨

---

# 5. Inverting and Editing Videos

ë¹„ë””ì˜¤ inversionì€ ë§¤ìš° ì–´ë µë‹¤. Why?

1. ë¹„ë””ì˜¤ì˜ ê° í”„ë ˆì„ë“¤ì„ recon & editing í–ˆì„ ë•Œ consistencyë¥¼ ìœ ì§€í•˜ê¸° ì–´ë ¤ì›€
2. ëˆˆì„ ê°ê³  ìˆê±°ë‚˜ ì…ì„ ë²Œë¦¬ê³  ìˆë‹¤ë˜ê°€ í•˜ëŠ” ì–´ë ¤ìš´ í‘œì •ë“¤ì´ ì¡´ì¬

StyleGAN3ëŠ” ë‹¤ì–‘í•œ ìœ„ì¹˜ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê³ , texture stickingë„ ì—†ê¸° ë•Œë¬¸ì— ë¹„ë””ì˜¤ ìƒì„±ì— ì í•©í•˜ë‹¤. ë‹¤ë§Œ, ë¹„ë””ì˜¤ ìì²´ì— ì œì•½ì€ ìˆë‹¤. (unaligned imageë¼ê³  í•˜ë”ë¼ë„ ì£¼ì–´ì§„ ë²”ìœ„(fixed bounding box) ë‚´ì—ì„œ cropì´ ëœ ì´ë¯¸ì§€ì—¬ì•¼í•¨ - ex. vox1 dataset)

unaligned imageì— ëŒ€í•´ inversion & reconí•˜ëŠ” ê³¼ì •ì€ ë‹¤ìŒ ê³¼ì •ì„ ë”°ë¥´ë©°, ì´ë¥¼ í†µí•´ ë¹„ë””ì˜¤ê°€ ìƒì„±ëœë‹¤.

$$
y_{i}=G\left(w_{i} ;\left(r_{i}, t_{x, i}, t_{y, i}\right)\right)
$$

ë¹„ë””ì˜¤ ì „ì²´ë¥¼ editingí•  ìˆ˜ë„ ìˆìŒ

$$
y_{i, edit}=G\left(f(w_{i}) ;\left(r_{i}, t_{x, i}, t_{y, i}\right)\right)
$$

## 5.1 Latent Vector Smoothing

r&t ì¢Œí‘œë¡œ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì›ìœ„ì¹˜ë¡œ ë³´ë‚¸ë‹¤ê³  í•´ë„, ì—¬ëŸ¬ ì´ë¯¸ì§€ë“¤ê°„ì˜ consistencyë¥¼ í™•ì¸í•˜ê³  inversioní•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€ ê°ê°ì— ëŒ€í•´ì„œ inversion & reconì„ í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— <u> ë¹„ë””ì˜¤ë¥¼ reconí–ˆì„ ë•Œ ì—°ì†ëœ í”„ë ˆì„ ê°„ì— inconsistencyê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤. </u> (shaking issue)

ì €ìë“¤ì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ latent codeë“¤ì„ smoothingí•˜ëŠ” ê³¼ì •ì„ ì§„í–‰í•œë‹¤.

$$
\begin{aligned}w_{i, \text { smooth }} &=\sum_{j=i-2}^{i+2} \mu_{j} f\left(w_{j}\right) \\T_{i, \text { smooth }} &=\sum_{j=i-2}^{i+2} \mu_{j} T_{j}\end{aligned}
$$

where

$$
\left[\mu_{i-2}, \mu_{i-1}, \mu_{i}, \mu_{i+1}, \mu_{i+2}\right]=\frac{1}{3}[0.25,0.75,1,0.75,0.5]
$$

## 5.2 PTI (Pivotal Tuning Inversion) method ì ìš©

- Paper: [Pivotal Tuning for Latent-based Editing of Real Images (arxiv 2021)](https://arxiv.org/abs/2106.05744)

ì €ìë“¤ì€ unaligned imageë¥¼ ë§Œë“¤ê¸° ìœ„í•´ PTI methodë¥¼ ì±„íƒí–ˆë‹¤ê³  í•œë‹¤. 

PTI ë…¼ë¬¸ ì»¨ì…‰ì´ ê³¼ë…ì„ ë§ì¶”ë ¤ê³  ë…¸ë ¥í•˜ê¸° ë³´ë‹¤ëŠ” ê³¼ë…ì˜ ìœ„ì¹˜ë¥¼ ì˜®ê²¨ì£¼ê² ë‹¤ ì´ëŸ° ì»¨ì…‰ì¸ë°..

ì €ìë“¤ë„ ì´ ëª¨ë¸ì˜ ì•„ì´ë””ì–´ë¥¼ ì°¨ìš©í•˜ì—¬ ê°•ì œë¡œ unaligned imageê°€ ë§Œë“¤ì–´ì§€ë„ë¡ Generatorë¥¼ fine-tuning í•´ì£¼ì—ˆë‹¤.

$$
y_{i, \mathrm{PTI}}=G_{\mathrm{PTI}}\left(w_{i} ;\left(r_{i}, t_{x, i}, t_{y, i}\right)\right)
$$

> ê²°ê³¼ ë¹„ë””ì˜¤ë¥¼ ì˜ ë§Œë“œë ¤ê³  engineeringì„ ì—„ì²­ ì—´ì‹¬íˆ í•œ ë“¯í•œ....

**Detail**

For inverting and editing a given video we perform a pervideo fine-tuning of the StyleGAN3 generator network using the pivotal tuning technique from Roich et al. [56]. For each video, training is performed for a total of 8, 000 optimization steps with a batch size of 2 using the L2 pixel-wise loss and the LPIPS [56] loss, both with equal weight coefficients. For example, given a video consisting of 200 frames, each frame is observed an average of 40 times during training. During training, we do not alter the weights of the input Fourier features layer of the generator.

## 5.3 Bringing It All Together

ë§ˆì§€ë§‰ìœ¼ë¡œëŠ” smoothed edited latent code, smoothed transformation, ê·¸ë¦¬ê³  fine-tuned generatorë¥¼ ë‹¤ê°™ì´ ì‚¬ìš©!

$$
y_{i, \text { final }}=G_{\mathrm{PTI}}\left(w_{i, s m o o t h} ; T_{i, s m o o t h}\right)
$$

**ì •ë¦¬í•˜ìë©´..**

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%2010.png?raw=1' width = '700' ></p>

1. **align & crop the frame**: Cropped Frame($x_{\text {unaligned }}$)ì—ì„œ alignì„ ë§ì¶°ì„œ Aligned Frame($x_{\text {aligned }}$)ì„ ì–»ìŒ
2. **computing the Fourier feature transformations**
   - `Predict Transforms` ëª¨ë“ˆë¡œ ì–¼ë§ˆë‚˜ rotation & translation ë˜ì—ˆëŠ”ì§€ë¥¼ ê³„ì‚°
   - ì´ë•Œ, í™•ì¥ëœ viewì— ëŒ€í•´ì„œë„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì¶”ê°€ë¡œ y ë°©í–¥ìœ¼ë¡œ translationì´ ë” ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë„ ìƒì„±ì„ í•œë‹¤.
3. alignëœ ì´ë¯¸ì§€($x_{\text {aligned }}$) Encoderë¡œ inversion + editing í• ê±°ë©´ w ìˆ˜ì • (â†’ f(w))
4. PTI-tuned StyleGAN3ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
5. ë‘ ì´ë¯¸ì§€ë¥¼ í•©ì³ì„œ í™•ì¥ëœ edited result image êµ¬í•˜ê¸°

**Result**

<p align='center'><video controls width="700">
  <source src="https://yuval-alaluf.github.io/stylegan3-editing/videos/obama_edit.mp4?raw=1"
    type="video/webm">
</video></p>

<p align='center'><video controls width="700">
  <source src="https://yuval-alaluf.github.io/stylegan3-editing/videos/shakira_edit.mp4?raw=1"
    type="video/webm">
</video></p>

<p align='center'><video controls width="700">
  <source src="https://yuval-alaluf.github.io/stylegan3-editing/videos/michael_edit.mp4?raw=1"
    type="video/webm">
</video></p>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%2011.png?raw=1' width = '700' ></p>

## 5.4 Expanding the Field of View

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan3-editing/Untitled%2012.png?raw=1' width = '700' ></p>

ë…¼ë¬¸ì—ì„œ êµ‰ì¥íˆ í¥ë¯¸ë¡œìš´ íŒŒíŠ¸ì´ë‹¤. StyleGAN3ì˜ ì´ì ì„ í†¡í†¡íˆ í™œìš©í•œ ê²ƒ ê°™ë‹¤.

ì €ìë“¤ì€ ì´ë¯¸ì§€ë¥¼ shiftí•´ì„œ ë” ë„“ì€ viewì— ëŒ€í•´ ì˜ìƒì„ ìƒì„±í•˜ì˜€ë‹¤.

$$
\begin{aligned}y &=G_{\mathrm{PTI}}\left(w_{i, \text { smooth }} ; T_{i, s m o o t h}\right) \\y_{\text {shift }} &=G_{\mathrm{PTI}}\left(w_{i, s m o o t h} ; T_{\Delta} \cdot T_{i, s m o o t h}\right)\end{aligned}
$$

**í™•ì¥ ì „**

<p align='center'><video controls width="700">
  <source src="https://yuval-alaluf.github.io/stylegan3-editing/videos/mars_reconstruction.mp4?raw=1"
    type="video/webm">
</video></p>

**í™•ì¥ í›„**

<p align='center'><video controls width="700">
  <source src="https://yuval-alaluf.github.io/stylegan3-editing/videos/mars_edit_coupled.mp4?raw=1"
    type="video/webm">
</video></p>

---

# 6. Opinion

> ğŸ¤— StyleGAN2ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆë˜ ë‹¤ì–‘í•œ ì—°êµ¬ë“¤ì„ StyleGAN3ì— ì ìš©í•´ë³´ê³  ì‹¶ì—ˆëŠ”ë°, ë°œë¹ ë¥´ê²Œ ë…¼ë¬¸ì´ ë‚˜ì™€ì„œ ì¬ë¯¸ë‚˜ê²Œ ì½ì—ˆë˜ ë…¼ë¬¸ì´ë‹¤. 
>
> ê²°ê³¼ë„ ì˜ ë‚˜ì˜¤ëŠ” ê²ƒ ê°™ê³ , ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ë„ í¥ë¯¸ë¡œì› ë˜ ë…¼ë¬¸! ì•„ì‰¬ìš´ ì ë“¤ë„ ì¼ë¶€ ë³´ì´ì§€ë§Œ.. ê·¸ë˜ë„ idea developì— ë§ì€ ë„ì›€ì´ ë˜ì—ˆë‹¤. 
>
> ì–¼ë¥¸ ì½”ë“œ ê³µê°œë˜ì—ˆìœ¼ë©´!