---
title: "[Paper Review] BicycleGAN : Toward Multimodal Image-to-Image Translation ë…¼ë¬¸ ë¶„ì„"
excerpt: "Multimodal Image-to-Image translation taskì— ëŒ€í•´ í˜„ì‹¤ì ì´ê³  ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ”, BicycleGAN modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤."


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” Multimodal Image-to-Image translation taskì— ëŒ€í•´ í˜„ì‹¤ì ì´ê³  ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ”,  **BicycleGAN model**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.


- Paper : [[BicycleGAN] Toward Multimodal Image-to-Image Translation](https://arxiv.org/abs/1711.11586) (NeurIPS 2018 / Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

ê¸°ì¡´ì˜ <span style='background-color: #E5EBF7;'> image-to-image translation ì—°êµ¬ë“¤ì€ ì—¬ëŸ¬ê°œì˜ latent codeì—ì„œ í•˜ë‚˜ì˜ outputìœ¼ë¡œ many-to-one mapping ë˜ëŠ” **mode collapse** ë¬¸ì œ </span>ê°€ ìˆì—ˆë‹¤. 

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ outputì—ì„œ latent codeë¡œ ê°€ëŠ” mapping ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œì¼°ë‹¤.(bijective consistency) ë˜í•œ, ë‹¤ì–‘í•œ objection functionê³¼ network architecture, latent codeë“¤ì„ ì œì‹œí•˜ì—¬ í˜„ì‹¤ì ì´ê³  ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì˜€ë‹¤.

> â­ BicycleGAN
> - image-to-image translationì˜ mode collapse ë¬¸ì œ í•´ê²°
> - ë‹¤ì–‘í•œ styleì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë¨(multimodal)

## 1. Introduction

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan1.PNG?raw=1' width = '800' ></p>

> ê·¸ë™ì•ˆì˜ ìƒì„±ëª¨ë¸ì€ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆë‹¤ë©´, ë³¸ ë…¼ë¬¸ì€ **í•˜ë‚˜ì˜ inputìœ¼ë¡œ ë¶€í„° ì—¬ëŸ¬ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” Multimodal Image-to-Image Translationì— ê´€í•œ ì—°êµ¬**ì´ë‹¤. BicycleGANì€ **(1) í˜„ì‹¤ì ì´ê³  (2) ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ìƒì„±**ì„ ëª©í‘œë¡œ í•œë‹¤.

Multimodalityí•œ ì´ë¯¸ì§€ë¥¼ ë§Œë“œë ¤ë©´ low-dimensional latent codeì˜ í™•ë¥ ë¶„í¬ì™€ input ì´ë¯¸ì§€ë¡œ output ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆì–´ì•¼í•œë‹¤. ë˜í•œ, mode-collapseê°€ ìƒê¸°ì§€ ì•Šë„ë¡ ì•„ì£¼ ì‘ì€ ìˆ˜ì˜ inputì„ outputê³¼ mapping í•´ì•¼í•œë‹¤.

---

<span style='background-color: #E5EBF7;'>**Pix2Pix**</span>

ë³¸ ë…¼ë¬¸ì€ paired datasetì— ëŒ€í•´ ê³ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ **pix2pix framework**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì˜€ë‹¤.
- [[Paper Review] Pix2pix : Image-to-Image Translation with Conditional Adversarial Networks ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-8/)

pix2pixì˜ loss functionì€ latent codeì™€ ì‹¤ì œ input imageë¥¼ ëª¨ë‘ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í•™ìŠµì„ í•œë‹¤. 

ì´ë•Œ, ë¬¸ì œëŠ” Generatorê°€ í•™ìŠµ ì‹œì— latent codeë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤. (latent codeë¥¼ ë„£ì—ˆì„ ë•Œë‚˜ ëºì„ ë•Œ ëª¨ë‘ ë¹„ìŠ·í•˜ê²Œ í•™ìŠµì´ ë¨) 

ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì€ trainingê³¼ì •ì—ì„œ latent codeë¥¼ í™œìš©í•˜ë„ë¡ latent spaceì™€ outputì´ bijetioní•œ ê´€ê³„ë¥¼ ê°–ê²Œ í•˜ì˜€ë‹¤.

---

<span style='background-color: #E5EBF7;'> **CycleGAN** </span>

ë˜í•œ, BicycleGANì€ CycleGANì²˜ëŸ¼ **(1) latent codeë¥¼ outputìœ¼ë¡œ mappingí•˜ê³  (2) output ì´ë¯¸ì§€ë¥¼ latent spaceë¡œ ë‹¤ì‹œ ë³µêµ¬í•˜ëŠ” encoderë¥¼ í•™ìŠµ**í•˜ì—¬ ì—¬ëŸ¬ê°œì˜ latent codeê°€ í•˜ë‚˜ì˜ imageë¥¼ ìƒì„±í•˜ì§€ ì•Šë„ë¡ í•œë‹¤.(mode collapse ì˜ˆë°©)

- [[Paper Review] CycleGAN : Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-10/)

---

<span style='background-color: #E5EBF7;'> **Objective Functions** </span>
- **cVAE-GAN**
  - ground truth imageë¥¼ latent spaceë¡œ encoding

- **cLR-GAN**
  - latent vector -> G ë¡œ í•™ìŠµ : ì´ë ‡ê²Œ ë˜ë©´ ìƒì„±ëœ ì´ë¯¸ì§€ëŠ” í˜„ì‹¤ì ì´ì§€ë§Œ, ground truthë‘ ë¹„ìŠ·í•˜ì§€ëŠ” ì•ŠìŒ
  - encoderëŠ” output imageì—ì„œ latent vectorë¡œ ë³µì›ì´ ë˜ë„ë¡ í•™ìŠµ
  - latent regressor, infoGAN

- **BicycleGAN**
  - latent encodingê³¼ outputì˜ bijective consistencyë¥¼ í•™ìŠµ!

## 2. Related Work

<span style='background-color: #E5EBF7;'> **Generative modeling** </span>

ë‹¤ì–‘í•œ ìƒì„± ëª¨ë¸ì´ ìˆì§€ë§Œ GANì´ íš¨ê³¼ì ì´ë‹¤.

---

<span style='background-color: #E5EBF7;'> **Conditional Image Generation** </span>

- conditional VAEs
- autoregressive models
- image-to-image conditional GANs
  - (ì¢‹ì€ ì„±ëŠ¥) ê³ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤
  - ë‹¤ë§Œ, Generatorê°€ random noiseë¥¼ ë¬´ì‹œí•˜ê³  conditional informationë§Œì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— ë‹¤ì–‘ì„±ì´ ë–¨ì–´ì§„ë‹¤. (noiseë¥¼ ë¬´ì‹œí•˜ë©´ í•™ìŠµì´ ë” ì•ˆì •ì ìœ¼ë¡œ ë¨)

---

<span style='background-color: #E5EBF7;'> **Explicitly-encoded multimodality** </span>

latentì™€ image spaceê°€ tightí•˜ê²Œ ì—°ê²°ë˜ë„ë¡ ì´ ë‘˜ì„ encodingí•œ í›„, generatorì— ë„£ì–´ í•™ìŠµì„ ì‹œí‚¨ë‹¤.

## 3. Multimodal Image-to-Image Translation

> â­Goal : ë³¸ ë…¼ë¬¸ì€ ê°„ë‹¨í•œ ì‹ ë°œì˜ edgeë¡œë¶€í„° ì—¬ëŸ¬ í˜•íƒœì˜ ì‹ ë°œì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì²˜ëŸ¼ **ë‘ image domainê°„ì˜ multi-modal mappingì„ í•™ìŠµ**í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.


- input domain : $\mathcal{A} \subset \mathbb{R}^{H \times W \times 3}$
- output domain : $\mathcal{B} \subset \mathbb{R}^{H \times W \times 3}$

input instance $A$ì— ëŒ€í•´ ë‹¤ì–‘í•œ paired instance $B$ë¥¼ ë§Œë“¤ì–´ì•¼í•˜ì§€ë§Œ, trainingì„ í•  ë•Œì—ëŠ” (input, output)ì˜ í•˜ë‚˜ì˜ data pairë¥¼ ì´ìš©í•˜ì—¬ í›ˆë ¨ì„ í•œë‹¤. 

ë”°ë¼ì„œ ë³¸ ëª¨ë¸ì€ test time ë•Œ $p(\mathbf{B} \mid \mathbf{A})$ë¡œ ë¶€í„° ë‹¤ì–‘í•œ output $\mathcal{\hat{B}}$ ì„ samplingí•˜ë„ë¡ í•™ìŠµì„ í•œë‹¤.

$$G:(\mathbf{A}, \mathbf{z}) \rightarrow \mathbf{B}$$

---

### 3.1 BaseLine : Pix2pix + noise ($\mathbf{z} \rightarrow \widehat{\mathbf{B}}$)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan2.PNG?raw=1' width = '800' ></p>

baselineìœ¼ë¡œëŠ” pix2pixì˜ ëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤. ë‹¤ë§Œ, pix2pixì˜ ì‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤ë©´ í•™ìŠµì‹œì— noiseë¥¼ ë¬´ì‹œí•˜ëŠ” ë¬¸ì œê°€ ìƒê¸°ë¯€ë¡œ noiseë¥¼ ê³ ë ¤í•˜ë„ë¡ ëª¨ë¸ì„ ìˆ˜ì •í•œë‹¤. (3.2, 3.3)

$$\mathcal{L}_{\mathrm{GAN}}(G, D)=\mathbb{E}_{\mathbf{A}, \mathbf{B} \sim p(\mathbf{A}, \mathbf{B})}[\log (D(\mathbf{A}, \mathbf{B}))]+\mathbb{E}_{\mathbf{A} \sim p(\mathbf{A}), \mathbf{z} \sim p(\mathbf{z})}[\log (1-D(\mathbf{A}, G(\mathbf{A}, \mathbf{z})))]$$ 

$$(G)=\mathbb{E}_{\mathbf{A . B} \sim p(\mathbf{A}, \mathbf{B}), \mathbf{z} \sim p(\mathbf{z})}\|\mathbf{B}-G(\mathbf{A}, \mathbf{z})\|_{1}$$

$$G^{*}=\arg \min _{G} \max _{D} \quad \mathcal{L}_{\mathrm{GAN}}(G, D)+\lambda \mathcal{L}_{1}^{\mathrm{image}}(G)$$

### 3.2 Conditional Variational Autoencoder GAN : cVAE-GAN ($\mathbf{B} \rightarrow \mathbf{z} \rightarrow \widehat{\mathbf{B}}$)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan3.PNG?raw=1' width = '500' ></p>

latent vectorë¥¼ ì¼ë°˜ Gaussian ë¶„í¬ì—ì„œ ë½‘ìœ¼ë©´, noiseê°€ í•™ìŠµ ì‹œì— ë¬´ì‹œë  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ë”°ë¼ì„œ latent vectorì™€ ground truthê°€ ì—°ê´€ì´ ë  ìˆ˜ ìˆë„ë¡ <span style='background-color: #E5EBF7;'> **latent vectorë¥¼ Bì™€ ê´€ë ¨ëœ gaussian í™•ë¥ ë¶„í¬ì—ì„œ sampling** </span>í•˜ë„ë¡ ëª¨ë¸ì„ ìˆ˜ì •í•œë‹¤.

- $Q(\mathbf{z} \mid \mathbf{B})$ê°€ Bì˜ í™•ë¥  ë¶„í¬ì—ì„œ latent vectorë¥¼ samplingí•˜ëŠ” ê²ƒì²˜ëŸ¼ ë˜ë„ë¡ Encoderë¥¼ ì‚¬ìš©í•œë‹¤. 

  $$\mathbf{z} \sim E(\mathbf{B}), Q(\mathbf{z} \mid \mathbf{B}) \triangleq E(\mathbf{B})$$
- ë˜í•œ, $E(\mathbf{B})$ì— ì˜í•´ encodingëœ latent distributionì´ random Gaussian ë¶„í¬ì™€ ë¹„ìŠ·í•˜ë„ë¡ ì•„ë˜ì˜ lossë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.

  $$\mathcal{L}_{\mathrm{KL}}(E)=\mathbb{E}_{\mathbf{B} \sim p(\mathbf{B})}\left[\mathcal{D}_{\mathrm{KL}}(E(\mathbf{B}) \| \mathcal{N}(0, I))\right]$$


<span style='background-color: #E5EBF7;'> **ìˆ˜ì •ëœ Objection Function** </span>

$$\mathcal{L}_{\mathrm{GAN}}^{\mathrm{VAE}}=\mathbb{E}_{\mathbf{A}, \mathbf{B} \sim p(\mathbf{A}, \mathbf{B})}[\log (D(\mathbf{A}, \mathbf{B}))]+\mathbb{E}_{\mathbf{A}, \mathbf{B} \sim p(\mathbf{A}, \mathbf{B}), \mathbf{z} \sim E(\mathbf{B})}[\log (1-D(\mathbf{A}, G(\mathbf{A}, \mathbf{z})))]$$

$$\mathcal{L}_{1}^{\mathrm{VAE}}(G)=\mathbb{E}_{\mathbf{A}, \mathbf{B} \sim p(\mathbf{A}, \mathbf{B}), \mathbf{z} \sim E(\mathbf{B})}\|\mathbf{B}-G(\mathbf{A}, \mathbf{z})\|_{1}$$

$$G^{*}, E^{*}=\arg \min _{G, E} \max _{D} \quad \mathcal{L}_{\mathrm{GAN}}^{\mathrm{VAE}}(G, D, E)+\lambda \mathcal{L}_{1}^{\mathrm{VAE}}(G, E)+\lambda_{\mathrm{KL}} \mathcal{L}_{\mathrm{KL}}(E)$$

---

### 3.3 Conditional Latent Regressor GAN: cLR-GAN $(\mathbf{z} \rightarrow \widehat{\mathbf{B}} \rightarrow \widehat{\mathbf{z}})$

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan4.PNG?raw=1' width = '500' ></p>

latent vectorë¥¼ ì˜ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œëŠ” **latent regressor** modelê³¼ ìœ ì‚¬í•œ objection functionì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ ìˆë‹¤.

ì´ë•ŒëŠ” latent code `z`ë¥¼ randomìœ¼ë¡œ samplingí•œ í›„, Encoderë¥¼ í™œìš©í•˜ì—¬ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ $\hat{z}$ë¡œ ë³µì›ì‹œí‚¤ë„ë¡ í•™ìŠµì„ í•œë‹¤. $\widehat{\mathbf{z}}=E(G(\mathbf{A}, \mathbf{z}))$

$$\mathcal{L}_{1}^{\text {latent }}(G, E)=\mathbb{E}_{\mathbf{A} \sim p(\mathbf{A}), \mathbf{z} \sim p(\mathbf{z})}\|\mathbf{z}-E(G(\mathbf{A}, \mathbf{z}))\|_{1}$$

ìµœì¢… object functionì´ë‹¤. ì´ ê²½ìš°ì—ëŠ” L1 lossë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ëœë‹¤.

$$G^{*}, E^{*}=\arg \min _{G, E} \max _{D} \quad \mathcal{L}_{\mathrm{GAN}}(G, D)+\lambda_{\text {latent }} \mathcal{L}_{1}^{\text {latent }}(G, E)$$

---

### 3.4 BicycleGAN : Hybrid Model!



> **bicycleGANì€ 3.2ì™€ 3.3ì˜ cVAE-GANê³¼ cLR-GANì˜ objective functionì„ ëª¨ë‘ ì‚¬ìš©**í•œë‹¤.
> 
> cVAE-GANì„ ì‚¬ìš©í•˜ë¯€ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ëŠ” ground truthì˜ input-output pairì™€ ìœ ì‚¬í•˜ë©°, cLR-GANì„ ì‚¬ìš©í•˜ë¯€ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ëŠ” í˜„ì‹¤ì ì´ë‹¤. ë‘ cycleì˜ ì´ì ì„ í•©ì¹œê²Œ **bicycle GAN**!! $(\mathbf{B} \rightarrow \mathbf{z} \rightarrow \mathbf{B} \operatorname{and} \mathbf{z} \rightarrow \mathbf{B} \rightarrow \widehat{\mathbf{z}})$

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan5.PNG?raw=1' width = '800' ></p>


$$\begin{aligned}
G^{*}, E^{*}=\arg \min _{G, E} \max _{D} & \mathcal{L}_{\mathrm{GAN}}^{\mathrm{VAE}}(G, D, E)+\lambda \mathcal{L}_{1}^{\mathrm{VAE}}(G, E) \\
&+\mathcal{L}_{\mathrm{GAN}}(G, D)+\lambda_{\text {latent }} \mathcal{L}_{1}^{\text {latent }}(G, E)+\lambda_{\mathrm{KL}} \mathcal{L}_{\mathrm{KL}}(E),
\end{aligned}$$

## 4. Implementation

- Generator : U-Net, skip connection ì‚¬ìš©
- Discriminator : 2ê°œì˜ patchGAN
  - [pix2pixì˜ architecture](https://happy-jihye.github.io/gan/gan-8/#32-network-architectures)
- variantìœ¼ë¡œëŠ” LSGANì„ ì°¸ê³ 

ìì„¸í•œ ë‚´ìš©ì€ ìƒëµ

## 5. Experiment
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan6.PNG?raw=1' width = '800' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan7.PNG?raw=1' width = '800' ></p>

**pix2pix+noise**ëŠ” í˜„ì‹¤ì ì´ì§€ë§Œ ë³€í™”ê°€ ê±°ì˜ ì—†ê³ , **cVAE-GAN**ì€ ë‹¤ì–‘ì„±ì´ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì§€ë§Œ, spaceê°€ ì¡°ë°€í•˜ì§€ ì•Šì•„ì„œ artifactê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤. **cLR-GAN**ì€ ë‹¤ì–‘í•˜ì§€ëŠ” ì•Šì§€ë§Œ í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.(mode collapseê°€ ìƒê¸¸ ìˆ˜ ìˆìŒ)

**bicycleGAN**ì€ ë‹¤ì–‘í•˜ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ë¥¼ ë§Œë“ ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/bicyclegan8.PNG?raw=1' width = '800' ></p>

## 6. Conclusion

> latent vectorì™€ output spaceë¥¼ bijective mappingí•˜ëŠ” objective functionì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ë‹¤ì–‘í•˜ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

