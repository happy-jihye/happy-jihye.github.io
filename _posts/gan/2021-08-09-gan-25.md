---
title: "2021 ìƒì„±ëª¨ë¸ ì—°êµ¬ ë™í–¥ ë° ì£¼ìš” ë…¼ë¬¸ / AI Content Creation: Deep Generative Model"
excerpt: " "


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

<p align='center'>
  <iframe src="https://www.youtube.com/embed/rfx3whKgFVo"
    frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen style="width: 42.5em; height: 25em;"></iframe>
</p>

> Interpreting Deep Generative Models for Interactive AI Content Creation by Bolei Zhou ì˜ìƒì„ ë³´ê³  ë¦¬ë·°í•œ ê¸€ì…ë‹ˆë‹¤.

- [GAN-Papers (Github)](https://github.com/happy-jihye/GAN)
- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---
# Progress for Image Generation
---
## GAN-based Model

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-1.png?raw=1' width = '800' ></p>

- `GAN`: Generative Adversarial Networks (NIPS 2014) : [arxiv](https://arxiv.org/abs/1406.2661), [review](https://happy-jihye.github.io/gan/gan-1/)
- `DCGAN`: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (ICLR 2016)  : [arxiv](https://arxiv.org/abs/1511.06434), [review](https://happy-jihye.github.io/gan/gan-2/)
- `PG-GAN`: Progressive Growing of GANs for Improved Quality, Stability, and Variation (ICLR 2018) : [arxiv](https://arxiv.org/abs/1710.10196), [review](https://happy-jihye.github.io/gan/gan-5/)
- `BigGAN`: Large Scale GAN Training for High Fidelity Natural Image Synthesis (2019) : [arxiv](https://arxiv.org/abs/1809.11096) 
- `StyleGAN`: A Style-Based Generator Architecture for Generative Adversarial Networks (CVPR 2019) : [arxiv](https://arxiv.org/abs/1812.04948), [review](https://happy-jihye.github.io/gan/gan-6/)
- `StyleGAN v2`: Analyzing and Improving the Image Quality of StyleGAN (2020) : [arxiv](https://arxiv.org/abs/1912.04958), [review](https://happy-jihye.github.io/gan/gan-7/)
- `StyleGAN-ADA`: Training Generative Adversarial Networks with Limited Data (NeurlPS 2020) : [arxiv](https://arxiv.org/abs/2006.06676)  : review [#01](https://happy-jihye.github.io/gan/gan-19/), [#02](https://happy-jihye.github.io/gan/gan-20/)

---
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-2.png?raw=1' width = '800' ></p>

- `NeRF`: Representing Scenes as Neural Radiance Fields for View Synthesis (ECCV 2020) : [arxiv](https://arxiv.org/abs/2003.08934), [project page](https://www.matthewtancik.com/nerf)
  - ì—¬ëŸ¬ ê°ë„ì—ì„œ ì´¬ì˜í•œ ì´ë¯¸ì§€ë“¤ì„ inputìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ viewì—ì„œì˜ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚¸ ëª¨ë¸
- `DALLE`: Zero-Shot Text-to-Image Generation (ICML 2021) : [arxiv](https://arxiv.org/abs/2102.12092), [project page](https://openai.com/blog/dall-e/)
  - `Text-to-Image Generation` : OpenAIì—ì„œ ê³µê°œí•œ ëª¨ë¸ë¡œ, textë¡œ ë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ (transformer ê¸°ë°˜)

---

## Generative Adversarial Networks (GANs)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-3.png?raw=1' width = '800' ></p>

- `GAN`: Generative Adversarial Networks (NIPS 2014) : [arxiv](https://arxiv.org/abs/1406.2661), [review](https://happy-jihye.github.io/gan/gan-1/)
- Ian-Goodfellowê°€ 2014ë…„ì— ê³µê°œí•œ ëª¨ë¸ë¡œ, í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ ìƒì„±ëª¨ë¸ì€ GANì˜ networkë¥¼ ë”°ë¥´ê³  ìˆìŒ
- `Generator`ê°€ random vector `z`ë¡œ ë¶€í„° fake image `G(z)` ë¥¼ ìƒì„±í•˜ë©´, `Discriminator`ê°€ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ë¥¼ íŒë³„
- `G` ì™€ `D` ê°€ ì‹¸ìš°ë©´ì„œ í•™ìŠµí•˜ëŠ” ë°©ì‹

## How to Steer Neural Image Generation?

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-4.png?raw=1' width = '800' ></p>

>ì¹¨ëŒ€ë¼ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤ê³  í• ë•Œ, ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ì¹¨ëŒ€ë‚˜ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ì°ì€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´ ì–´ë–»ê²Œ í• ê¹Œ?
> â†’ latent spaceë‚˜ conv filterë¥¼ ì¡°ì ˆ !

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-5.png?raw=1' width = '800' ></p>

- Deep Generative Modelì€ Latent vectorë¥¼ Convolutional Neural Networkì˜ inputìœ¼ë¡œ ë„£ì–´ ì´ë¯¸ì§€ë¥¼ ìƒì„±
- ì´ë¯¸ì§€ì˜ ì£¼ìš” featureëŠ” **(1) Conv filtersì™€ (2) latent space**ì—ì„œ ê²°ì •ë¨
- ì´ ë‘ê°€ì§€ì˜ ìš”ì†Œì— ë”°ë¼ ì´ë¯¸ì§€ê°€ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ë¥¼ ì´í•´í•œë‹¤ë©´, ì›í•˜ëŠ” ëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ editingí•  ìˆ˜ ìˆì„ ê²ƒ !

# Interpretation Approaches

> - **Supervised Approach** : Labelì´ë‚˜ í›ˆë ¨ëœ classifierë¡œ Generatorê°€ ì´ë¯¸ì§€ë¥¼ ì˜ ìƒì„±í•˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•œ ground truthë¥¼ ì œê³µí•˜ëŠ” ë°©ì‹
> - **Unsupervised Approach** : Labelì´ë‚˜ í›ˆë ¨ëœ classifierì—†ì´ Generatorë¥¼ í•™ìŠµ
> - **Zero-Shot Approach** : align language embedding with generative representations

---

## 1. Supervised Approach

>  Use labels or trained classifiers to probe the representation of the generator

### 1.1 Manipulating Conv filters

#### 1.1.1 GAN Dissection

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-6.png?raw=1' width = '800' ></p>


- `GAN Dissection`: Visualizing and Understanding Generative Adversarial Networks (ICLR 2019) : [arxiv](https://arxiv.org/abs/1811.10597), [project page](https://gandissect.csail.mit.edu/)
- Supervised Aprroachì˜ ì´ˆê¸° ì—°êµ¬
- GANì˜ feature mapê³¼ ì´ë¯¸ì§€ì˜ semantic segmentationì´ matchingë˜ë„ë¡ í•™ìŠµ
- íŠ¹ì • feature mapì´ ì´ë¯¸ì§€ ë‚´ì— ì–´ë–¤ objectë¥¼ ìƒì„±í•˜ëŠ”ì§€ë¥¼ ì—°êµ¬í•˜ì˜€ìŒ.
- interactiveí•˜ê²Œ ì´ë¯¸ì§€ ë‚´ì˜ íŠ¹ì • objectë¥¼ ì§€ìš¸ ìˆ˜ë„ ìˆê³ , ìƒì„±í•  ìˆ˜ë„ ìˆìŒ.


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-7.png?raw=1' width = '800' ></p>

ì˜ˆë¥¼ ë“¤ì–´, êµíšŒ ì´ë¯¸ì§€ê°€ ìƒì„±ëì„ ë•Œ
1. ê°™ì€ objectë¼ë¦¬ grouping(b). (ex. ë‚˜ë¬´ëŠ” ë‚˜ë¬´ë¼ë¦¬ grouping) 
   - object unitì˜ featuremapì´ semantic segmentationê³¼ matchë˜ë„ë¡ í•´ì•¼í•¨.
2. ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • objectë¥¼ ì‚¬ë¼ê²Œ í•˜ê±°ë‚˜(c), ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆì–´ì•¼ í•¨(d)
3. Generatorê°€ ë°°ê²½ê³¼ object ì‚¬ì´ì— ê´€ê³„ë¥¼ ì´í•´í•´ì•¼í•¨ (ex. ê±´ë¬¼ì— ë¬¸ì€ ìƒê¸¸ ìˆ˜ ìˆì–´ë„, ê±´ë¬¼ì— êµ¬ë¦„ì´ë‚˜ ë‚˜ë¬´ê°€ ìˆìœ¼ë©´ ì•ˆë¨)

---

### 1.2 Manipulating Latent Space

> ê°ê°ì˜ Conv Filterì´ ì–´ë–¤ objectë¥¼ ìƒì„±í•˜ëŠ”ì§€ë¥¼ ì°¾ì€ í›„ì— ì´ë¥¼ editingí•˜ëŠ” ë°©ì‹ë„ ìˆì§€ë§Œ, **latent spaceê°€ disentangleí•˜ë‹¤ë©´ ì´ë¥¼ ì¡°ì ˆí•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ë¥¼ editing**í•˜ëŠ”ê²Œ ë” ìˆ˜ì›”í•¨

#### 1.2.1 HiGAN

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-8.png?raw=1' width = '800' ></p>

- `HiGAN`: Semantic Hierarchy Emerges in Deep Generative Representations for Scene Synthesis (IJCV 2020) : [arxiv](https://arxiv.org/abs/1911.09267), [project page](https://genforce.github.io/higan/)
- í›ˆë ¨ëœ classifierë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ objectë“¤ì„ ë¶„ë¥˜í•œ í›„(category, attribute), ê°ê°ì˜ objectë“¤ì´ latent vectorì™€ ì–´ë–»ê²Œ ì—°ê´€ì´ ë˜ì–´ìˆëŠ”ì§€ë¥¼ í•™ìŠµ â†’ íŠ¹ì • featureë¥¼ ìƒì„±í•˜ëŠ” latent vectorë¥¼ ì¡°ì ˆí•˜ë©´ì„œ image editing


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-9.png?raw=1' width = '800' ></p>

$$\Delta s_{i}=\frac{1}{K} \sum_{k=1}^{K} \max \left(F_{i}\left(G\left(\mathbf{z}^{k}+\lambda \mathbf{n}_{i}\right)\right)-F_{i}\left(G\left(\mathbf{z}^{k}\right)\right), 0\right)$$

**Result**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-10.png?raw=1' width = '800' ></p>

---
#### 1.2.2 InterFaceGAN

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-11.png?raw=1' width = '800' ></p>


- `InterFaceGAN`: Interpreting the Latent Space of GANs for Semantic Face Editing (CVPR 2020) : [arxiv](https://arxiv.org/abs/1907.10786), [project page](https://genforce.github.io/interfacegan/)
- `HiGAN` ëª¨ë¸ì„ ì—°êµ¬í•œ `genforce`ì—ì„œ ë°œí‘œí•œ ëª¨ë¸
- latent vectorì˜ íŠ¹ì • ë°©í–¥ì´ íŠ¹ì • attributeë¥¼ ì¡°ì ˆí•¨ì„ ì°¾ì€ í›„, latent manipulationì„ í†µí•´ face imageë¥¼ editingí•˜ëŠ” ëª¨ë¸ (PGGAN, StyleGAN ë“±ì— ì ‘ëª© ê°€ëŠ¥)

---
#### 1.2.3 StyleFlow

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-15.png?raw=1' width = '800' ></p>


- `StyleFlow`: Attribute-conditioned Exploration of StyleGAN-Generated Images using Conditional Continuous Normalizing Flows (ACM TOG 2021) : [arxiv](https://arxiv.org/abs/2008.02401), [project page](https://rameenabdal.github.io/StyleFlow/)

- StyleFlow: StyleGAN + Flow-based conditional model
  - 17ê°€ì§€ì˜ face-attributeì— ê´€ì—¬í•˜ëŠ” íŠ¹ì • latent vectorë¥¼ ì°¾ëŠ” ëª¨ë¸
  - `attribute classifier` ë¥¼ ì‚¬ìš©í•˜ì—¬ StyleGANì„ í†µí•´ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ attributeë“¤ì„ ë½‘ì€ í›„, ì´ë¥¼ labelë¡œ ì‚¬ìš©í•˜ì—¬ conditional í•˜ê²Œ ì´ë¯¸ì§€ editingì— ê´€ì—¬í•˜ëŠ” latent vectorë¥¼ í•™ìŠµí•˜ì—¬ ì°¾ìŒ
- ê¸°ì¡´ì˜ latent mainpulation modelë“¤ì€ linearí•˜ê²Œ latent vectorë¥¼ ìˆ˜ì •í•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ë¥¼ editing í–ˆë‹¤ë©´, ì´ ëª¨ë¸ì€ **non-linear í•˜ê²Œ latent vectorë¥¼ ì¡°ì ˆ**
- ì´ ëª¨ë¸ì€ ë‘ê°€ì§€ taskë¥¼ í•  ìˆ˜ ìˆìŒ : **(1) attribute-conditioned sampling**: target attributeë¥¼ ê°€ì§€ê³  ìˆëŠ” high-quality ì´ë¯¸ì§€ë¥¼ ìƒì„± **(2) attribute-controlled editing**: real imageë¥¼ target attributeë¥¼ ê°€ì§„ ì´ë¯¸ì§€ë¡œ editing

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-12.png?raw=1' width = '800' ></p>

- â­ï¸ **contribution** : (1) ê¸°ì¡´ì˜ ëª¨ë¸ë“¤(ex. GANSpace) ë³´ë‹¤ ì„±ëŠ¥ í–¥ìƒ (2) entangleí•œ latent spaceë¥¼ conditionalí•˜ê²Œ ì‚´í´ë´„ìœ¼ë¡œì¨ disentangleí•˜ê²Œ ì¡°ì ˆí•  ìˆ˜ ìˆë„ë¡ í•¨
- (Fig2) leftê°€ styleganì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€, middleì´ Image2StyleGANìœ¼ë¡œ ì›ƒëŠ” ì–¼êµ´ë¡œ editingí•œ ì´ë¯¸ì§€, rightê°€ StyleFlowì˜ ê²°ê³¼
  - StyleFlowëŠ” non-linear pathë¥¼ ì°¾ê¸° ë•Œë¬¸ì— featureë¥¼ ë½‘ì€ í›„ disentangleí•˜ê²Œ latent vectorë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥ 

**model aritecture**
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-13.png?raw=1' width = '800' ></p>

- `CNF block` : Conditional Conitinous Normalizing Flows
- input latent vector $z_k$ ë¥¼ attribute variable $a^+_t$ì„ ë°˜ì˜í•˜ë„ë¡ í•™ìŠµ

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-14.png?raw=1' width = '800' ></p>

**Joint Reverse Encoding(JRE)**
- real imageì—ì„œ ì‹œì‘ì„ í•œë‹¤ê³  ê°€ì •í•˜ë©´, encoderë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ $w \in \mathbb{R}^{1 \times 512}$ vectorë¡œ projectioní•œ í›„, ìƒì„±ëœ ì´ë¯¸ì§€ $I(w)$ì˜ `attribute classifier` $\mathcal{A}$ ë¡œ attributeë¥¼ ì¶”ì • 
  - `attribute classifier`: face classifier API(MS) & lighting predction DRP network)
- ì´í›„ reverse inferenceë¡œ $w, a_t$ì—ì„œ $z_0$ ì„ ì¶”ì •

**Conditional Foward Editing (CFE)**
- imageë¥¼ projectioní•˜ì—¬ ì–»ì€ ê³ ì •ëœ $z_0$ vectorì—ì„œ ì‹œì‘í•˜ì—¬ target attribute $a_t'$ë¥¼ ë°˜ì˜í•˜ëŠ” intermediate latent vector $w'$ ë¥¼ inference

---

### 1.3 Parsing 3D Information from 2D Image Generator

#### 1.3.1 StyleGANRender

<p align='center'><img src='https://nv-tlabs.github.io/GANverse3D/figures/ICLR_teaser.png?raw=1' width = '800' ></p>

- `StyleGANRender`: Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering (ICLR 2021) : [arxiv](https://arxiv.org/abs/2010.09125), [project page](https://nv-tlabs.github.io/GANverse3D/)
- nvidiaì—ì„œ ë‚¸ ë…¼ë¬¸ìœ¼ë¡œ, 2D imageë¥¼ ë°”íƒ•ìœ¼ë¡œ 3D imageë¥¼ ìƒì„±. SoTA inverse graphics network.
- StyleGANìœ¼ë¡œ ìƒì„±ëœ multi-view imageë¥¼ í† ëŒ€ë¡œ Inverse Graphics Networkë¥¼ í•™ìŠµí•œ í›„, ì´ networkë¡œ latent codeë¥¼ disentangleí•˜ê²Œ êµ¬í•´ 3D ì´ë¯¸ì§€ë¥¼ ìƒì„±

<p align='center'><img src='https://nv-tlabs.github.io/GANverse3D/figures/reconstruction.gif?raw=1' width = '800' ></p>

---

### 1.4 Challenges for Supervised Approach

- How to expand the annotated dictionary size?
- How to further disentangle the relevant attributes? 
- How to align latent space with image region attributes?


---

## 2. Unsupervised Approach

> Identify the controllable dimensions of generator without labels/classifiers

### 2.1 SeFA

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-17.png?raw=1' width = '800' ></p>

- `sefa`: Closed-Form Factorization of Latent Semantics in GANs (CVPR 2021) : [arxiv](https://arxiv.org/abs/2007.06600), [project page](https://genforce.github.io/sefa/), [code](https://github.com/happy-jihye/GAN/tree/main/SEFA)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-16.png?raw=1' width = '800' ></p>

- latent vector ì¤‘ íŠ¹ì • featureë¥¼ ë³€í™”ì‹œí‚¤ëŠ” layerê°€ ì–´ë””ì¸ì§€ ì°¾ì€ í›„ ì´ë¥¼ ì¡°ì ˆí•¨ìœ¼ë¡œì¨ imageë¥¼ editing
- Human-in-the-loop AI content creation


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/cartoongan/sefa-pose.gif?raw=1' width = '700' ></p>
<font color='gray'><i><p align='center' style='font-size:11px'> Cartoon-StyleGAN (https://github.com/happy-jihye/Cartoon-StyleGAN) </p></i></font>

### 2.2 GANspace

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-18.png?raw=1' width = '800' ></p>

- `GANSpace`: Discovering Interpretable GAN Controls (NeurIPS 2020) : [arxiv](https://arxiv.org/abs/2004.02546), [code](https://github.com/harskish/ganspace)
- [`PCA(Principal Component Analysis)`](https://darkpgmr.tistory.com/110)ì˜ ë°©ì‹ìœ¼ë¡œ StyleGANì˜ latent spaceì™€ BigGANì˜ feature spaceì˜ ì£¼ìš” directionì„ ì°¾ìŒ


### 2.3 Hessian Penalty


- `Hessian Penalty`: A weak prior for unsupervised disentanglement (ECCV 2020) : [arxiv](https://arxiv.org/abs/2008.10599), [project page](https://www.wpeebles.com/hessian-penalty)
- í•™ìŠµ ê³¼ì •ì— `Hessian Penalty` ë¼ëŠ” ê°„ë‹¨í•œ regularization termì„ ë„ì…í•˜ì—¬ ìƒì„± ëª¨ë¸ì˜ ì…ë ¥ì— ëŒ€í•œ ëŒ€ê°ì„ ì„ ìœ ë„
- **Hessian Matrix** : $i$ì™€ $j$ë¼ëŠ” ë‘ attributeê°€ ì„œë¡œ disentangleí•˜ë‹¤ë©´ $H_{ij}$ëŠ” 0ì¼ ê²ƒ

$$H_{i j}=\frac{\partial^{2} G}{\partial z_{i} \partial z_{j}}=\frac{\partial}{\partial z_{j}}\left(\frac{\partial G}{\partial z_{i}}\right)=0$$

- **Hessian panalty in training** : latent spaceê°€ disentangleí•´ì§€ë„ë¡ í›ˆë ¨ê³¼ì •ì—ì„œ Hessian panaltyë¥¼ ì¶”ê°€ (ë§Œì•½ $i$ì™€ $j$ê°€ ë‹¤ë¥¸ ë°©í–¥ì´ì§€ë§Œ ì„œë¡œ ë¹„ìŠ·í•œ attributeë¥¼ ìƒì„±í•œë‹¤ë©´, hessain penalty termì˜ ê°’ì´ ì»¤ì§ˆ ê²ƒ)

$$\mathcal{L}_{H}(G)=\sum_{i=1}^{|z|} \sum_{j \neq i}^{|z|} H_{i j}^{2}$$

$$\mathcal{L}_{\mathrm{G}}=\underbrace{\mathbb{E}_{z \sim p_{z}(z)}[f(1-D(G(z)))]}_{\text {Standard Adversarial Loss }}+\underbrace{\lambda \underset{z \sim p_{z}(z)}{\mathbb{E}}\left[\mathcal{L}_{\mathbf{H}}(G)\right]}_{\text {The Hessian Penalty }}$$

```python
def hessian_penalty(G, z, k, epsilon):
    # Input G: Function to compute the Hessian Penalty of
    # Input z: Input to G that the Hessian Penalty is taken w.r.t.
    # Input k: Number of Hessian directions to sample
    # Input epsilon: Finite differences hyperparameter
    # Output: Hessian Penalty loss
    G_z = G(z)
    vs = epsilon * random_rademacher(shape=[k, *z.size()])
    finite_diffs = [G(z + v) - 2 * G_z + G(z - v) for v in vs]
    finite_diffs = stack(finite_diffs) / (epsilon ** 2)
    penalty = var(finite_diffs, dim=0).max()
    return penalty
```

### 2.4 EigenGAN

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-19.png?raw=1' width = '800' ></p>

- `EigenGAN`: Layer-Wise Eigen-Learning for GANs : [arxiv](https://arxiv.org/abs/2104.12476), [code](https://github.com/bryandlee/eigengan-pytorch)
- Design inductive bias of disentanglement in the generator


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-20.png?raw=1' width = '800' ></p>

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-21.png?raw=1' width = '800' ></p>


- ë³´í†µ generatorëŠ” ì´ˆê¸°ì— coarseí•œ íŠ¹ì§•ë“¤(ex. ìì„¸, ì„±ë³„)ì„ í•™ìŠµí•˜ê³ , ë§ˆì§€ë§‰ layerë¡œ ê°ˆìˆ˜ë¡ fineí•œ íŠ¹ì§•ë“¤(ex. ì‹œì„ , ë¹›)ì„ í•™ìŠµ. ì´ ëª¨ë¸ì€ ì´ëŸ¬í•œ generatorì˜ íŠ¹ì§•ì„ ì´ìš©í•˜ì—¬ ê° generatorì— injectionë˜ëŠ” latent vectorë“¤ì´ ì–´ë–¤ íŠ¹ì§•ë“¤ì„ ê²°ì •í•˜ëŠ”ì§€ê¹Œì§€ ê°™ì´ í•™ìŠµí•˜ê² ë‹¤ëŠ” ì»¨ì…‰
  - stylespace ì´ eigengan ëª¨ë¸ì˜ ì»¨ì…‰ì„ styleganì— ì ìš©ì‹œì¼°ë‹¤ê³  ë³´ë©´ ë¨
- $t$-layerì˜ generatorì™€ $t$ê°œì˜ latent set $z_i$ë¥¼ mapping : generatorì˜ ê° layerë§ˆë‹¤ latent vectorë¥¼ injection
- [`BlockGAN`](https://github.com/thunguyenphuoc/BlockGAN), [`HoloGAN`](https://github.com/thunguyenphuoc/HoloGAN)ê³¼ ë¹„ìŠ·

### Challenges for UnSupervised Approach

- How to evaluate the results?
- How to annotate each disentangled dimensions?
- How to improve the disentanglement in GAN training?

---

## 3. Zero-Shot Approach

> Align language embedding with generative representations
### 3.1 StyleCLIP

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/styleclip-1.PNG?raw=1?raw=1' width = '800' ></p>


- `StyleCLIP`: Text-Driven Manipulation of StyleGAN Imagery (arXiv 2021) : [arxiv](https://arxiv.org/abs/2103.17249), [review](https://happy-jihye.github.io/gan/gan-15/), [code](https://github.com/orpatashnik/StyleCLIP)
- `StyleGAN`ê³¼ `CLIP`ì„ baselineìœ¼ë¡œ ì‚¼ì•„ textê¸°ë°˜ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ ëª¨ë¸

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-22.png?raw=1' width = '800' ></p>

ì„¸ê°€ì§€ ë°©ì‹ìœ¼ë¡œ CLIP ê¸°ë°˜ì˜ ìƒì„±ëª¨ë¸ì„ ì œì•ˆ. ìì„¸í•œ architecutre ì„¤ëª…ì€ [`ì´ ë§í¬`](https://happy-jihye.github.io/gan/gan-15/)ë¥¼ ì°¸ê³ 
1. Latent Optimization
2. Latent Mapper
3. Global Direction

### 3.2 Paint by Word
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-23.png?raw=1' width = '800' ></p>

- Paint by Word (2021) : [arxiv](https://arxiv.org/abs/2103.10951)
- brushë¡œ íŠ¹ì • ì˜ì—­ì„ ìƒ‰ì¹ í•œ í›„, textë¥¼ ì…ë ¥í•˜ë©´ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì • (CLIP modelì˜ joint-embedding spaceë¥¼ ì‚¬ìš©)

### 3.3 DALL.E

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-24.png?raw=1' width = '800' ></p>


- `DALLE`: Zero-Shot Text-to-Image Generation (ICML 2021) : [arxiv](https://arxiv.org/abs/2102.12092), [project page](https://openai.com/blog/dall-e/), [mini-dalle](borisdayma/dalle-mini)
- `Text-to-Image Generation` : OpenAIì—ì„œ ê³µê°œí•œ ëª¨ë¸ë¡œ, textë¡œ ë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ (transformer ê¸°ë°˜)
- 250M(2.5ì–µê°œ)ì˜ text-image pairë¡œ í•™ìŠµ. 12B(120ì–µê°œ)ì˜ parameter

1. Train a discrete variational autoencoder (`dVAE`)
2. Train an autoregressive transformer to model the joint distribution of text and image tokens

---

## Latent Spaces of GANâ€™s Generator

GAN Inversion ë° Encoderì— ê´€í•œ ê±´ ì•„ë˜ì˜ ê¸€ ì°¸ê³  
- [GAN Inversion / Encoder : Image2stylegan, IDInvert, pSp, e4e](https://happy-jihye.github.io/gan/gan-23/)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-25.png?raw=1' width = '800' ></p>

- `z space` : stochasticí•œ ë¶„í¬ì—ì„œ ë½‘ì€ random vector
- StyleGANì´ ë‚˜ì˜¤ë©´ì„œ latent spaceë“¤ì´ ë” í™•ì¥ë˜ì—ˆìŒ
  - `w space` : MLPë¥¼ ê±°ì³ ì–»ì€ vector. w vectorë¥¼ AdaIN í•œ í›„, Generatorì˜ ê° layerì— injectionë˜ì—ˆì—ˆìŒ
  - `S space` : `w`ë¥¼ AdaINí•œ í›„ì— ì–»ì€ style vector (Layer-wise codes)
  - `w+ space` : GAN inversionì„ í•˜ë©´ì„œ ë„ì…ëœ space. `w vector`ëŠ” ëª¨ë“  AdaINì— ë“¤ì–´ê°€ëŠ” vectorë“¤ì´ ê°™ì•˜ë‹¤ë©´, `w+ vector`ëŠ” ë‹¤ë¦„
  - `p/p+ space`

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-26.png?raw=1' width = '800' ></p>

> StyleSpace ê°€ ê°€ì¥ disentangle


- `StyleSpace`: StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation (CVPR 2021) : [arxiv](https://arxiv.org/abs/2011.12799), [code](https://github.com/xrenaa/StyleSpace-pytorch), [code2](https://github.com/happy-jihye/GAN/tree/main/StyleSpace)

- `GHFeat`: Generative Hierarchical Features from Synthesizing Images (CVPR 2021) : [arxiv](https://arxiv.org/abs/2007.10379), [project page](https://genforce.github.io/ghfeat/)


## Encoding Real Image into StyleGAN space

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-27.png?raw=1' width = '800' ></p>

> ìµœê·¼ì—ëŠ” GANì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ Inversioní•œ í›„ ì´ë¥¼ manipulationí•˜ì—¬ imageë¥¼ editingí•˜ëŠ” ì—°êµ¬ê°€ ëŒ€ì„¸ ğŸ™ƒ
> - [GAN Inversion / Encoder : Image2stylegan, IDInvert, pSp, e4e](https://happy-jihye.github.io/gan/gan-23/)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-28.png?raw=1' width = '800' ></p>

- ì´ë¯¸ì§€ reconstructionì—ë„ StyleSpaceë¥¼ ì´ìš©í•œê²Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ìŒ
- `ALAE`: Adversarial latent autoencoders (CVPR 2020) : [arxiv](https://arxiv.org/abs/2004.04467), [code](https://github.com/podgorskiy/ALAE)
- `IdInvert` : In-Domain GAN Inversion for Real Image Editing (ECCV 2020) : [arxiv](https://arxiv.org/abs/2004.00049), [review](https://happy-jihye.github.io/gan/gan-23/), [code](https://github.com/happy-jihye/GAN/tree/main/In-Domain-GAN)
- `GHFeat`: Generative Hierarchical Features from Synthesizing Images (CVPR 2021) : [arxiv](https://arxiv.org/abs/2007.10379), [project page](https://genforce.github.io/ghfeat/)

## Applying the pretrained GAN model to image processing tasks

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/ai-content-creation-29.png?raw=1' width = '800' ></p>

- GAN-Inversionì„ í†µí•´ ë‹¤ì–‘í•œ taskë„ ê°€ëŠ¥í•¨