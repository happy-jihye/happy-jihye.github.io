---
title: "[Paper Review] GauGAN : Semantic Image Synthesis with Spatially-Adaptive Normalization (SPADE) ë…¼ë¬¸ ë¶„ì„"
excerpt: "Semantic Imageë¥¼ í˜„ì‹¤ì ì¸ imageë¡œ ë³€í™˜í•´ì£¼ëŠ” Spatially-adaptive normlization(SPADE) modelì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤"

categories:
 - GAN
tags:
  - deeplearning
  - ai
  - pytorch
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---

> âœğŸ» ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” Semantic Imageë¥¼ í˜„ì‹¤ì ì¸ imageë¡œ ë³€í™˜í•´ì£¼ëŠ” **Spatially-adaptive normlization(SPADE) model**ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.


- Paper : [Semantic Image Synthesis with Spatially-Adaptive Normalization](https://arxiv.org/abs/1903.07291) (CVPR 2019 / Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---

|                                                              |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade3.gif?raw=1'>| <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade2.gif?raw=1' >|




## 1. Introduction
> We propose **spatially-adaptive normalization**, **a conditional normalization layer** that modulates the activations using input semantic layouts through a spatially adaptive, learned transformation and can effectively propagate the semantic information throughout the network.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade1.PNG?raw=1' width = '800' ></p>


ì´ì „ê¹Œì§€ëŠ” Semantic Image to photorealistic image taskì—ì„œ **convolution, normalization, nonlinearity layerë¡œ êµ¬ì„±ëœ deep nework**ë¥¼ ì‚¬ìš©í–ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ normalizationê³¼ì •ì—ì„œ semantic ì •ë³´ê°€ ì‚¬ë¼ì§„ë‹¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ <span style='background-color: #E5EBF7;'> **spatially-adaptive normalization** </span>ì„ ì œì•ˆí•œë‹¤. 

## 2. Related Work

### 2.1 Conditional image synthesis

ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ conditional informationì„ ì£¼ë©´ ë” ë¹ ë¥´ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ê°€ ìƒì„±ëœë‹¤.

<span style='background-color: #FFF2CC;'> Conditional image synthesis taskë“¤ê³¼ ê´€ë ¨ ë…¼ë¬¸ </span>
- **Class-conditional models**
  - [[Paper Review] CGAN : Conditional Generative Adversarial Nets ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-3/)
  
- **Generating images based on text**
  - [[Paper Review] Generative Adversarial Text to Image Synthesis ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-4/)

- **Image to Image translation**
  - [[Paper Review] Pix2pix : Image-to-Image Translation with Conditional Adversarial Networks ë…¼ë¬¸ ë¶„ì„](https://happy-jihye.github.io/gan/gan-8/)
  - <span style='background-color: #E5EBF7;'> **Segmentation masks to images : SPADE !** </span>

    *Segmentation masks to images*ëŠ” specificí•œ *Image to Image translation*ìœ¼ë¡œ, inputìœ¼ë¡œëŠ” semantic label mapì„ ë°›ê³  outputìœ¼ë¡œëŠ” photoë¥¼ ì¶œë ¥í•œë‹¤.

---

### 2.2 Unconditional normalization layers


<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan-3.PNG?raw=1' width = '600' ></p>

ìœ„ì˜ unconditional normalization layerë“¤ì€ conditional normalization layerê³¼ ë‹¤ë¥´ê²Œ ì™¸ë¶€ ë°ì´í„°ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ì´ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ labelingì„ í•´ì¤˜ì•¼í•œë‹¤.

### 2.3 Conditional normalization layer

Conditional normalization layerëŠ” ì™¸ë¶€ ë°ì´í„°ì— ì˜ì¡´í•œë‹¤.(style transfer)

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade4.png?raw=1' width = '700' ></p>

ë³´í†µ **Conditional normalization layer**ì€ Figure3 ê³¼ ê°™ì´ ì™¸ë¶€ ë°ì´í„°ì—ì„œ ì–»ì–´ì§„ ì •ë³´ë¡œ normalizeê°€ ë˜ê³¤ í•œë‹¤. ì´ëŠ” ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì§„í–‰ëœë‹¤.

1. layer activationì„ zero mean, unit deviationìœ¼ë¡œ ì •ê·œí™”(normalization)ì„ í•œ í›„,
2. ì™¸ë¶€ ë°ì´í„°ë¡œë¶€í„° ì¶”ë¡ ëœ `learned affine transformation`ë¥¼ ì´ìš©í•˜ì—¬ (1ì—ì„œ) ì •ê·œí™”ëœ activationì„ denormalize

ë³´í†µ style-transfer ì™€ ê°™ì€ taskëŠ” ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ styleì„ ë°”ê¿”ì•¼í•˜ê¸° ë•Œë¬¸ì— affine parameterê°€ output imageì˜ globalí•œ styleì„ ì¡°ì ˆí•˜ê³ , ê³µê°„ì¢Œí‘œì— ë”°ë¼ affine transformationì˜ parameterê°€ ì¼ì •(uniform)í•˜ë‹¤.

> ë°˜ë©´, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” semantic maskë“¤ë§ˆë‹¤ ê°ê¸° ë‹¤ë¥¸ styleì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ì›í•œë‹¤. ë”°ë¼ì„œ  
> ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **normalization layerì— spatially-varing affine transformationì„ ì ìš©í•˜ì—¬ semantic maskë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ í•©ì„±**í•œë‹¤.

## 3. Semantic Image Synthesis

- ê° pixelì˜ semantic segmentation mask : $\mathbf{m} \in \mathbb{L}^{H \times W}$
- â­ Goal: input segmentation mask $m$ ì„ photorealistic imageë¡œ ë°”ê¿”ì£¼ëŠ” mapping network í•™ìŠµ
  
### 3.1 SPADE: SPatially-Adaptive DEnormalization

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade5.PNG?raw=1' width = '400' ></p>

1. maskë¥¼ embedding spaceë¡œ projectioní•œ í›„, 
2. ì´ë¥¼ convolution í•´ì„œ modulation parameters $\gamma, \beta$ ë¥¼ ë§Œë“¦
  - ì´ë•Œ modulation parmaeter $\gamma, \beta$ëŠ” vectorê°€ ì•„ë‹ˆë¼ tensor  
  - $\gamma_{c, y, x}^{i}(\mathbf{m}), \beta_{c, y, x}^{i}(\mathbf{m})$ ëŠ” normalization layerì˜ modulation parameter
      - ì´ variableì€ í•™ìŠµì´ ë˜ë©°, Batch-Normê³¼ ë‹¤ë¥´ê²Œ input segmentation maskì™€ location $(y, x)$ ì— ì˜í–¥ì„ ë°›ëŠ”ë‹¤.
3. $\gamma, \beta$ ëŠ” normalized activationì— ê°ê° multiplied & added

$$\gamma_{c, y, x}^{i}(\mathbf{m}) \frac{h_{n, c, y, x}^{i}-\mu_{c}^{i}}{\sigma_{c}^{i}}+\beta_{c, y, x}^{i}(\mathbf{m})$$

- normalizationìœ¼ë¡œëŠ” instance normì´ ì•„ë‹ˆë¼ Batch Normì„ ì‚¬ìš©í–ˆë‹¤.
  
$$\begin{aligned}
\mu_{c}^{i} &=\frac{1}{N H^{i} W^{i}} \sum_{n, y, x} h_{n, c, y, x}^{i} \\
\sigma_{c}^{i} &=\sqrt{\frac{1}{N H^{i} W^{i}} \sum_{n, y, x}\left(\left(h_{n, c, y, x}^{i}\right)^{2}-\left(\mu_{c}^{i}\right)^{2}\right)}
\end{aligned}$$

ğŸ¤” ì‚¬ì‹¤ SPADE(SPatially-Adaptive DEnormalization)ëŠ” ì¡´ì¬í•˜ëŠ” normalization layerë“¤ì˜ ì¼ë°˜í™”ëœ í‘œí˜„ì´ë‹¤.

ë§Œì•½ (1) segmentation mask $m$ ì„ image class labelë¡œ ë°”ê¾¸ê³  (2) modulation param $\gamma, \beta$ ë¥¼ ê³µê°„ì¢Œí‘œì— ë”°ë¼ ë³€í•˜ì§€ ì•Šë„ë¡(spatially invariant)í•˜ê²Œ ë°”ê¾¼ë‹¤ë©´, ì´ëŠ” Conditional BatchNormê³¼ ìœ ì‚¬í•´ì§ˆ ê²ƒ ì´ë‹¤.

- ë³¸ ë…¼ë¬¸ì€ modulation param $\gamma, \beta$ ì„ input seg maskì— ë”°ë¼ adaptiveí•˜ë„ë¡ í–ˆê¸° ë•Œë¬¸ì— semantic image synthesisë¥¼ ë” ì˜í•˜ëŠ” ê²ƒ !!

  
---

### 3.2 SPADE generator


- SPADEì—ì„œëŠ” learned modulation parameterë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— generatorì˜ ì²«ë²ˆì§¸ layerë¡œ segmentation mapì„ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ë‹¤. ë˜í•œ, normalization ê³¼ì •ì—ì„œ semantic mask ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ê¸° ë•Œë¬¸ì— Encoder ë¶€ë¶„(downsampling)ë„ í•„ìš” ì—†ë‹¤. (ì´ë¯¸ ì´ modulation paramì´ label layoutì— ëŒ€í•œ ì •ë³´ë“¤ì„ ì¶©ë¶„íˆ ì˜ encodingí•˜ë‹ˆê¹Œ) 
  - ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì€ encoderë¥¼ ì œê±°í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì„ ê²½ëŸ‰í™”í–ˆë‹¤. 

- ë˜í•œ, generatorì˜ inputìœ¼ë¡œëŠ” random noise vectorë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë‹¨ìˆœí™”í•˜ê³ , multi-modal synthesisê°€ ê°€ëŠ¥í•˜ë„ë¡ í–ˆë‹¤.
  - inputìœ¼ë¡œ random noiseë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— latent vectorë¥¼ ì¡°ì ˆí•˜ë©´ì„œ styleì„ ë³€í™”í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•´ì§

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade6.PNG?raw=1' width = '800' ></p>

- Upsampling layerë¡œëŠ” ResNet Blockì„ ì‚¬ìš©í•œë‹¤.
  - ëª¨ë“  normalization layerì˜ modulation paramëŠ” SPADEë¡œ í•™ìŠµ
  - ê° residual blockì€ ê°ê¸° ë‹¤ë¥¸ scaleì—ì„œ ì‘ë™ì´ ë˜ê¸° ë•Œë¬¸ì— ì €ìë“¤ì€ semantic maskë¥¼ ê° spatial resolutionê³¼ matchë˜ë„ë¡ downsampling í–ˆë‹¤.

- ì €ìë“¤ì€ pix2pixHDì—ì„œ ì‚¬ìš©í•œ multi-scale discriminatorì™€ loss functionì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤.
  - ì´ë•Œ, least squared lossë¥¼ hinge lossë¡œ ëŒ€ì²´

### 3.3 Why dose the SPADE work better?

> A) ì¼ë°˜ì ì¸ normalization layersë³´ë‹¤ semanticí•œ ì •ë³´ë¥¼ ë” ì˜ ë³´ì¡´í•˜ê¸° ë•Œë¬¸ì—!

Instance Normê³¼ ê°™ì€ normalization layerëŠ” ë§ì€ conditional image í•©ì„±ì—ì„œ SoTAë¥¼ ë‹¬ì„±í–ˆì§€ë§Œ, uniform/flat segmentation maskì— ì ìš©í•˜ë©´ semantic informationì´ ì‚¬ë¼ì§„ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade7.PNG?raw=1' width = '450' ></p>

segmentation maskì—ì„œëŠ” ëŒ€ë¶€ë¶„ì˜ pixelì´ ê°™ì€ labelì„ ê°–ê³  ìˆë‹¤. ë”°ë¼ì„œ Instance Normì„ ì‚¬ìš©í•˜ë©´ 0ìœ¼ë¡œ normalizedë˜ì–´ semantic informationì´ ì‚¬ë¼ì§ˆ ê²ƒì´ë‹¤. (`Fig3`ì˜ pix2pixHD ê²°ê³¼ ì°¸ê³ )

> ë°˜ë©´, SPADEëŠ” ë‹¤ë¥¸ normalization layerì— ë¹„í•´ **semantic information**ì´ ì˜ ë³´ì¡´ëœë‹¤.

--- 

### 3.4 Multi-model synthesis

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade8.PNG?raw=1' width = '450' ></p>

> Generatorì˜ inputìœ¼ë¡œ random vectorë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ multi-modal synthesisê°€ ê°€ëŠ¥í•´ì¡Œë‹¤.

- ë‹¤ìŒê³¼ ê°™ì´ VAE ì²˜ëŸ¼ Generatorë¥¼ êµ¬ì„±í•  ìˆ˜ë„ ìˆë‹¤. (Encoderì™€ generatorìª½ì˜ architectureê°€ VAEì™€ ë¹„ìŠ·)
- ì´ ê²½ìš°ì—ëŠ” **`Encoder`ì—ì„œëŠ” ì´ë¯¸ì§€ì˜ styleì„ captureí•˜ê³ , `Generator`ì—ì„œëŠ” SPADEì—ì„œì˜ segmentation mask informationê³¼ encoded styleì„ í•©ì¹œë‹¤.**
- KL-Divergence lossë¡œ í•™ìŠµ

### 3.5 Block and network architectures

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade14.PNG?raw=1' width = '800' ></p>
---
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade15.PNG?raw=1' width = '800' ></p>

- SPADE Generator with VAEsëŠ” VAEì²˜ëŸ¼ í•™ìŠµì´ ëœë‹¤. latent vectorë¥¼ gaussianì—ì„œ ë½‘ëŠ”ê²Œ ì•„ë‹ˆë¼ reference ì´ë¯¸ì§€ë¡œë¶€í„° inferenceí•œ ë‹¤ìŒì— generatorì— ë„£ì–´ì¤€ë‹¤.

## 4. Experiments

**Implementation details.**

We apply the **Spectral Norm** [38] to all the layers in both generator and discriminator. The **learning rates** for the generator and discriminator are 0.0001 and 0.0004, respectively [17]. We use the **ADAM** solver [27] with Î²1 = 0 and Î²2 = 0.999. All the experiments are conducted on an NVIDIA DGX1 with 8 32GB V100 GPUs. We use synchronized BatchNorm, i.e., these statistics are collected from all the GPUs.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade9.PNG?raw=1' width = '800' ></p>
<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade10.PNG?raw=1' width = '800' ></p>

COCO-stuff, ADE20K, Cityscapes datasetìœ¼ë¡œ í•™ìŠµì„ ì‹œì¼°ì„ ë•Œ, ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ë¹„êµí•´ë´ë„ SPADEê°€ ì¢‹ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade11.PNG?raw=1' width = '600' ></p>

Amazon Mechanical Turk(AMT, ì‚¬ëŒì´ ì§ì ‘ test)ë¡œ testë¥¼ í•´ë´ë„ SPADEê°€ ì¢‹ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade12.PNG?raw=1' width = '600' ></p>

pix2pixì™€ ê°™ì€ ë‹¤ë¥¸ architectureì— SPADEë¥¼ ì‚¬ìš©í•´ë´ë„ SPADEë¥¼ ì“´ê²Œ ì¢‹ë‹¤.

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/spade13.PNG?raw=1' width = '800' ></p>

random noiseë¥¼ ë°”ê¿”ë³´ë‹ˆ ì´ë¯¸ì§€ styleì´ ë³€í–ˆë‹¤. multi-model synthesisê°€ ì˜ëœë‹¤. 

## 5. Conclusions

> â­ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **Sp**atially-**A**daptive **(DE)**normalizatoinì„ ì œì•ˆí–ˆë‹¤. ì´ë¥¼ í†µí•´ normalization layerì—ì„œ affine ë³€í™˜ì„ í•  ë•Œ semantic ì •ë³´ë¥¼ ì˜ í™œìš©í•˜ë„ë¡ í•  ìˆ˜ ìˆì—ˆê³ , semantic imageë¡œë¶€í„° í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ í•©ì„±ì´ ê°€ëŠ¥í•´ì¡Œë‹¤.
> 
> ë˜í•œ, multi-model synthesis ë¿ë§Œ ì•„ë‹ˆë¼ guided image synthesisê°€ ê°€ëŠ¥í•´ì¡Œë‹¤.


---
**Reference**
- Naver AI LAB ìµœìœ¤ì œ ì—°êµ¬ì›ë‹˜ ë°œí‘œìë£Œ
- [https://paperswithcode.com/method/conditional-instance-normalization#](https://paperswithcode.com/method/conditional-instance-normalization#) 