---
title: "[Paper Review] StyleGAN2-ADA #02: Training Generative Adversarial Networks with Limited Data ì½”ë“œ ë¦¬ë·°"
excerpt: " "


categories:
 - GAN
tags:
  - deeplearning
  - ai
  - GAN
  - vision
search: true

# ëª©ì°¨
toc: true  
toc_sticky: true 

use_math: true
---


<p align='right'> 
 <a href='https://github.com/NVlabs/stylegan2-ada-pytorch' role='button' target='_blank'> <img class='notebook-badge-image' src='/assets/badges/github.svg' alt='View On GitHub'> </a> 
</p>


> âœğŸ» ìµœê·¼ì—ëŠ” ì´ë¯¸ ìˆëŠ” ëª¨ë¸(`pretrained model`)ì„ ì˜ `fine tuning`í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ê²°ê³¼ë¥¼ ë‚´ëŠ” ì—°êµ¬ê°€ ëŒ€ì„¸ì´ë‹¤. (FreezeD, GANSpace, StyleCLIP ë“±ë“±) 
> 
> **StyleGAN2-ADA**ë„ ì´ëŸ¬í•œ íë¦„ì—ì„œ ë‚˜ì˜¨ ì—°êµ¬ë¡œ, loss functionì´ë‚˜ networkì˜ architectureë¥¼ ê±´ë“¤ì´ì§€ ì•Šê³  ì´ë¯¸ í•™ìŠµì´ ëœ GANì„ `finetuning`í•˜ê±°ë‚˜ trainingê³¼ì •ì—ì„œ `scratch`ë¥¼ ë‚´ëŠ” ì‹ìœ¼ë¡œ í•™ìŠµì„ í•œë‹¤. ë˜í•œ, ì ì€ ë°ì´í„°ë¡œ í•™ìŠµì„ í•´ë„ discriminatorê°€ overfitting ë˜ì§€ ì•Šë„ë¡  `Adaptive Discriminator Augmentation Mechanism`ì„ ì œì•ˆí•˜ì˜€ë‹¤.
> 
> â­ ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” StyleGAN2-ADAì˜ [Official Code](https://github.com/NVlabs/stylegan2-ada-pytorch)ë¥¼ ì‚´í´ë³¸ë‹¤.

- Paper : [Training Generative Adversarial Networks with Limited Data](https://arxiv.org/abs/2006.06676) (NeurlPS 2020 /Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila)

- ğŸ˜ StyleGAN Posting
    - [`[Paper Review] StyleGAN2-ADA #01: Training Generative Adversarial Networks with Limited Data ë…¼ë¬¸ ë¶„ì„`](https://happy-jihye.github.io/gan/gan-19/)
    - [`[Paper Review] StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks ë…¼ë¬¸ ë¶„ì„`](https://happy-jihye.github.io/gan/gan-6/)
    - [`[Paper Review] StyleGAN2 : Analyzing and Improving the Image Quality of StyleGAN ë…¼ë¬¸ ë¶„ì„`](https://happy-jihye.github.io/gan/gan-7/)

- [GAN-Zoos! (GAN í¬ìŠ¤íŒ… ëª¨ìŒì§‘)](https://happy-jihye.github.io/gan/)

---



## Generation Images

### generator.py

- <span style='background-color: #E5EBF7;'> Generate curated MetFaces images without truncation (Fig.10 left) </span>
  
    ```bash
    $ python generate.py --outdir=out --trunc=1 --seeds=85,265,297,849 \
        --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl
    ```

    truncation ì—†ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì˜€ë‹¤. truncation metricì€ immediate latent space $W$ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ë§Œì„ catchí•˜ëŠ” metricì´ë‹¤. ì´ metricì„ ì‚¬ìš©í•˜ë©´ ë‹¤ì–‘ì„±ì€ ë–¨ì–´ì§€ì§€ë§Œ, qualityê°€ ë†’ì€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

    | seed 85  | seed 297  |  seed 849  |
    | ---- |  ---- | ---- |
    | <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-ge1.png?raw=1' width = '700' >     |  <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-ge3.png?raw=1' width = '700' >     | <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-ge4.png?raw=1' width = '700' >     |



- <span style='background-color: #E5EBF7;'> Generate uncurated MetFaces images with truncation (Fig.12 upper left) </span>
    
    ```bash
    $ python generate.py --outdir=out --trunc=0.7 --seeds=600-605 \
        --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl
    ```

- <span style='background-color: #E5EBF7;'> Generate class conditional CIFAR-10 images (Fig.17 left, Car) </span>

  - stylegan2-adaì—ì„œëŠ” conditional generationë„ ê°€ëŠ¥í•˜ë‹¤. (stylegan2ëŠ” x)
  - class labelì„ ë˜ë‹¤ë¥¸ mapping networkì— ë„£ì–´ embedding í•œ í›„ì— ê·¸ embeddingì„ $w$ì™€ concateí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ëœë‹¤.

  ```bash
  $ python generate.py --outdir=out --seeds=0-35 --class=1 \
      --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl
  ```

---


- `Generator.py` Code
  - pickle fileì€ ì„¸ê°€ì§€ì˜ network, `G`, `D`, `G_ema`ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤. 
    - `G_ema`ëŠ” Generator weightì˜ í‰ê· ì„ exponential movingí•œ ê²ƒìœ¼ë¡œ, EMA(Exponential Moving Average)ì˜ ë°©ì‹ì„ í™œìš©í•˜ë©´ GANì„ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.

<script src="https://gist.github.com/happy-jihye/b9849c7432375bb2595b436fa375c760.js"></script>

### style_mixing.py

- <span style='background-color: #E5EBF7;'> Style mixing example </span>

    ```bash
    $ python style_mixing.py --outdir=out --rows=85,100,75,458,1500 --cols=55,821,1789,293 \
        --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl
    ```

- Result

<p align='center'><img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-style_mixing.png?raw=1' width = '700' ></p>

- `style_mixing.py` Code


<script src="https://gist.github.com/happy-jihye/0d6da98c7e79aadbe5dc681109903879.js"></script>


---
## Projecting images to latent space

### Projector.py 

`projector.py` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ì´ë¯¸ì§€ì˜ latent vectorë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.

```bash
$ python projector.py --outdir=out --target=~/mytargetimg.png \
    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl
```

- `projector.py` Code

<script src="https://gist.github.com/happy-jihye/1b62d46fededfd0cf8df305f3093faa2.js"></script>

ìœ„ì—ì„œ ìƒì„±í•œ latent vectorë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ë„ ìˆë‹¤.

```bash
$ python generate.py --outdir=out --projected-w=out/projected_w.npz \
    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl
```

|                         target image                         |                        Projection image                        |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-target.png?raw=1' width = '700' > | <img src='https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/gan/stylegan2-ada-proj.png?raw=1' width = '700' > |

## Training new networks

```bash
# Train with custom dataset using 1 GPU.
# dry-run : ì¤‘ê°„ì— errorê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ìš©ë„
$ python train.py --outdir=~/training-runs --data=~/mydataset.zip --gpus=1 --dry-run
$ python train.py --outdir=~/training-runs --data=~/mydataset.zip --gpus=1

# Train class-conditional CIFAR-10 using 2 GPUs.
$ python train.py --outdir=~/training-runs --data=~/datasets/cifar10.zip \\
    --gpus=2 --cfg=cifar --cond=1

# Reproduce original StyleGAN2 config F.
$ python train.py --outdir=~/training-runs --data=~/datasets/ffhq.zip \\
    --gpus=8 --cfg=stylegan2 --mirror=1 --aug=noaug

# Transfer learn MetFaces from FFHQ using 4 GPUs.
$ python train.py --outdir=~/training-runs --data=~/datasets/metfaces.zip \\
    --gpus=4 --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10
```

```
Base configs (--cfg):
    auto       Automatically select reasonable defaults based on resolution
                and GPU count. Good starting point for new datasets.
    stylegan2  Reproduce results for StyleGAN2 config F at 1024x1024.
    paper256   Reproduce results for FFHQ and LSUN Cat at 256x256.
    paper512   Reproduce results for BreCaHAD and AFHQ at 512x512.
    paper1024  Reproduce results for MetFaces at 1024x1024.
    cifar      Reproduce results for CIFAR-10 at 32x32.


Transfer learning source networks (--resume):
    ffhq256        FFHQ trained at 256x256 resolution.
    ffhq512        FFHQ trained at 512x512 resolution.
    ffhq1024       FFHQ trained at 1024x1024 resolution.
    celebahq256    CelebA-HQ trained at 256x256 resolution.
    lsundog256     LSUN Dog trained at 256x256 resolution.
    <PATH or URL>  Custom network pickle.
```

### train.py

- `train.py`ì˜ `main` function

<script src="https://gist.github.com/happy-jihye/8725dbd531d3812d58963150a9fbfd58.js"></script>

- `setup_training_loop_kwargs` : `train.py`ì—ì„œ ì—¬ëŸ¬ parameterë“¤ì„ ì •ì˜í•˜ëŠ” íŒŒíŠ¸

<script src="https://gist.github.com/happy-jihye/51e1d6069b5f35890599d766e006df03.js"></script>

main í•¨ìˆ˜ì—ì„œëŠ” `subprocess_fn`í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œë‹¤. `subprocess_fn` í•¨ìˆ˜ì—ì„œ gpuì˜ ê°œìˆ˜ì— ë§ê²Œ ì„¸íŒ…ì„ ì¡°ì •í•œ í›„, `training_loop`í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ í•™ìŠµì„ ë³¸ê²©ì ìœ¼ë¡œ ì‹œì‘ !

<script src="https://gist.github.com/happy-jihye/fdff76e0c080b52de3a002ec4d3a2eb9.js"></script>

### training_loop.py

<script src="https://gist.github.com/happy-jihye/d2e5db5b821143bb1ddb870be8102d1e.js"></script>

### network.py
<script src="https://gist.github.com/happy-jihye/1105130adae43ad198848a4342349c0f.js"></script>