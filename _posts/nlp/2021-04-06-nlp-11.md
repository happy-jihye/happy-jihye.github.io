---
title: "[Paper Review] ELmo: Deep contextualized word representations 논문 분석"

excerpt: " "

categories: 
  - nlp
tags: 
  - deeplearning
  - ai
  - nlp
  - transformer

search: true

# 목차
toc: true  
toc_sticky: true 

---


> 이번 포스팅에서는 Transformer의 architeture를 효율적으로 만든 Reformer(2020)에 대해 살펴본다.

- Paper : [Deep contextualized word representations](https://arxiv.org/abs/1802.05365)
          (2018 / Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer)


## 1. Introduction


## 3. ELMo : Embedding from Language Models
### 3.1 Bidirectional langauge models

[Semi-supervised sequence tagging with bidirectional language models](https://arxiv.org/abs/1705.00108)